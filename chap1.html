<!DOCTYPE html>
<html lang="en">
<!-- Produced from a LaTeX source file.  Note that the production is done -->
<!-- by a very rough-and-ready (and buggy) script, so the HTML and other  -->
<!-- code is quite ugly!  Later versions should be better.                -->
<head>
    <meta charset="utf-8">
    <meta name="citation_title" content="Neural Networks and Deep Learning">
    <meta name="citation_author" content="Nielsen, Michael A.">
    <meta name="citation_publication_date" content="2015">
    <meta name="citation_fulltext_html_url" content="http://neuralnetworksanddeeplearning.com">
    <meta name="citation_publisher" content="Determination Press">
    <meta name="citation_fulltext_world_readable" content="">
    <link rel="icon" href="nnadl_favicon.ICO" />
    <title>Neural networks and deep learning</title>
    <script src="assets/jquery.min.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$']]},
        "HTML-CSS": 
          {scale: 92},
        TeX: { equationNumbers: { autoNumber: "AMS" }}});
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>


    <link href="assets/style.css" rel="stylesheet">
    <link href="assets/pygments.css" rel="stylesheet">
    <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.2/themes/smoothness/jquery-ui.css">

<style>
/* Adapted from */
/* https://groups.google.com/d/msg/mathjax-users/jqQxrmeG48o/oAaivLgLN90J, */
/* by David Cervone */

@font-face {
    font-family: 'MJX_Math';
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); /* IE9 Compat Modes */
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot?iefix') format('eot'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff')  format('woff'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf')  format('opentype'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/svg/MathJax_Math-Italic.svg#MathJax_Math-Italic') format('svg');
}

@font-face {
    font-family: 'MJX_Main';
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); /* IE9 Compat Modes */
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot?iefix') format('eot'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff')  format('woff'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf')  format('opentype'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/svg/MathJax_Main-Regular.svg#MathJax_Main-Regular') format('svg');
}
</style>

  </head>
  <body>
    <div class="header">
      <h1 class="chapter_number">
        <a href="">Cap√≠tulo 1</a>
      </h1>
  <h1 class="chapter_title">
    <a href="">Usando redes neurais para reconhecer digitos manuscritos</a></h1></div><div class="section"><div id="toc"> 
<p class="toc_title"><a href="index.html">Neural Networks and Deep Learning</a></p><p class="toc_not_mainchapter"><a href="about.html">What this book is about</a></p><p class="toc_not_mainchapter"><a href="exercises_and_problems.html">On the exercises and problems</a></p><p class='toc_mainchapter'><a id="toc_using_neural_nets_to_recognize_handwritten_digits_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_using_neural_nets_to_recognize_handwritten_digits" src="images/arrow.png" width="15px"></a><a href="chap1.html">Using neural nets to recognize handwritten digits</a><div id="toc_using_neural_nets_to_recognize_handwritten_digits" style="display: none;"><p class="toc_section"><ul><a href="chap1.html#perceptrons"><li>Perceptrons</li></a><a href="chap1.html#sigmoid_neurons"><li>Sigmoid neurons</li></a><a href="chap1.html#the_architecture_of_neural_networks"><li>The architecture of neural networks</li></a><a href="chap1.html#a_simple_network_to_classify_handwritten_digits"><li>A simple network to classify handwritten digits</li></a><a href="chap1.html#learning_with_gradient_descent"><li>Learning with gradient descent</li></a><a href="chap1.html#implementing_our_network_to_classify_digits"><li>Implementing our network to classify digits</li></a><a href="chap1.html#toward_deep_learning"><li>Toward deep learning</li></a></ul></p></div>
<script>
$('#toc_using_neural_nets_to_recognize_handwritten_digits_reveal').click(function() { 
   var src = $('#toc_img_using_neural_nets_to_recognize_handwritten_digits').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow.png');
   };
   $('#toc_using_neural_nets_to_recognize_handwritten_digits').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_how_the_backpropagation_algorithm_works_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_how_the_backpropagation_algorithm_works" src="images/arrow.png" width="15px"></a><a href="chap2.html">How the backpropagation algorithm works</a><div id="toc_how_the_backpropagation_algorithm_works" style="display: none;"><p class="toc_section"><ul><a href="chap2.html#warm_up_a_fast_matrix-based_approach_to_computing_the_output
_from_a_neural_network"><li>Warm up: a fast matrix-based approach to computing the output
  from a neural network</li></a><a href="chap2.html#the_two_assumptions_we_need_about_the_cost_function"><li>The two assumptions we need about the cost function</li></a><a href="chap2.html#the_hadamard_product_$s_\odot_t$"><li>The Hadamard product, $s \odot t$</li></a><a href="chap2.html#the_four_fundamental_equations_behind_backpropagation"><li>The four fundamental equations behind backpropagation</li></a><a href="chap2.html#proof_of_the_four_fundamental_equations_(optional)"><li>Proof of the four fundamental equations (optional)</li></a><a href="chap2.html#the_backpropagation_algorithm"><li>The backpropagation algorithm</li></a><a href="chap2.html#the_code_for_backpropagation"><li>The code for backpropagation</li></a><a href="chap2.html#in_what_sense_is_backpropagation_a_fast_algorithm"><li>In what sense is backpropagation a fast algorithm?</li></a><a href="chap2.html#backpropagation_the_big_picture"><li>Backpropagation: the big picture</li></a></ul></p></div>
<script>
$('#toc_how_the_backpropagation_algorithm_works_reveal').click(function() { 
   var src = $('#toc_img_how_the_backpropagation_algorithm_works').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow.png');
   };
   $('#toc_how_the_backpropagation_algorithm_works').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_improving_the_way_neural_networks_learn_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_improving_the_way_neural_networks_learn" src="images/arrow.png" width="15px"></a><a href="chap3.html">Improving the way neural networks learn</a><div id="toc_improving_the_way_neural_networks_learn" style="display: none;"><p class="toc_section"><ul><a href="chap3.html#the_cross-entropy_cost_function"><li>The cross-entropy cost function</li></a><a href="chap3.html#overfitting_and_regularization"><li>Overfitting and regularization</li></a><a href="chap3.html#weight_initialization"><li>Weight initialization</li></a><a href="chap3.html#handwriting_recognition_revisited_the_code"><li>Handwriting recognition revisited: the code</li></a><a href="chap3.html#how_to_choose_a_neural_network's_hyper-parameters"><li>How to choose a neural network's hyper-parameters?</li></a><a href="chap3.html#other_techniques"><li>Other techniques</li></a></ul></p></div>
<script>
$('#toc_improving_the_way_neural_networks_learn_reveal').click(function() { 
   var src = $('#toc_img_improving_the_way_neural_networks_learn').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow.png');
   };
   $('#toc_improving_the_way_neural_networks_learn').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_a_visual_proof_that_neural_nets_can_compute_any_function" src="images/arrow.png" width="15px"></a><a href="chap4.html">A visual proof that neural nets can compute any function</a><div id="toc_a_visual_proof_that_neural_nets_can_compute_any_function" style="display: none;"><p class="toc_section"><ul><a href="chap4.html#two_caveats"><li>Two caveats</li></a><a href="chap4.html#universality_with_one_input_and_one_output"><li>Universality with one input and one output</li></a><a href="chap4.html#many_input_variables"><li>Many input variables</li></a><a href="chap4.html#extension_beyond_sigmoid_neurons"><li>Extension beyond sigmoid neurons</li></a><a href="chap4.html#fixing_up_the_step_functions"><li>Fixing up the step functions</li></a><a href="chap4.html#conclusion"><li>Conclusion</li></a></ul></p></div>
<script>
$('#toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal').click(function() { 
   var src = $('#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow.png');
   };
   $('#toc_a_visual_proof_that_neural_nets_can_compute_any_function').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_why_are_deep_neural_networks_hard_to_train_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_why_are_deep_neural_networks_hard_to_train" src="images/arrow.png" width="15px"></a><a href="chap5.html">Why are deep neural networks hard to train?</a><div id="toc_why_are_deep_neural_networks_hard_to_train" style="display: none;"><p class="toc_section"><ul><a href="chap5.html#the_vanishing_gradient_problem"><li>The vanishing gradient problem</li></a><a href="chap5.html#what's_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets"><li>What's causing the vanishing gradient problem?  Unstable gradients in deep neural nets</li></a><a href="chap5.html#unstable_gradients_in_more_complex_networks"><li>Unstable gradients in more complex networks</li></a><a href="chap5.html#other_obstacles_to_deep_learning"><li>Other obstacles to deep learning</li></a></ul></p></div>
<script>
$('#toc_why_are_deep_neural_networks_hard_to_train_reveal').click(function() { 
   var src = $('#toc_img_why_are_deep_neural_networks_hard_to_train').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow.png');
   };
   $('#toc_why_are_deep_neural_networks_hard_to_train').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_deep_learning_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_deep_learning" src="images/arrow.png" width="15px"></a><a href="chap6.html">Deep learning</a><div id="toc_deep_learning" style="display: none;"><p class="toc_section"><ul><a href="chap6.html#introducing_convolutional_networks"><li>Introducing convolutional networks</li></a><a href="chap6.html#convolutional_neural_networks_in_practice"><li>Convolutional neural networks in practice</li></a><a href="chap6.html#the_code_for_our_convolutional_networks"><li>The code for our convolutional networks</li></a><a href="chap6.html#recent_progress_in_image_recognition"><li>Recent progress in image recognition</li></a><a href="chap6.html#other_approaches_to_deep_neural_nets"><li>Other approaches to deep neural nets</li></a><a href="chap6.html#on_the_future_of_neural_networks"><li>On the future of neural networks</li></a></ul></p></div>
<script>
$('#toc_deep_learning_reveal').click(function() { 
   var src = $('#toc_img_deep_learning').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_deep_learning").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_deep_learning").attr('src', 'images/arrow.png');
   };
   $('#toc_deep_learning').toggle('fast', function() {});  
});</script><p class="toc_not_mainchapter"><a href="sai.html">Appendix: Is there a <em>simple</em> algorithm for intelligence?</a></p><p class="toc_not_mainchapter"><a href="acknowledgements.html">Acknowledgements</a></p><p class="toc_not_mainchapter"><a href="faq.html">Frequently Asked Questions</a></p>
<hr>
<p class="sidebar"> If you benefit from the book, please make a small
donation.  I suggest $5, but you can choose the amount.</p>

<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick">
<input type="hidden" name="hosted_button_id" value="5K9YAHR4X84RN">
<input type="image" src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif" border="0" name="submit" alt="PayPal - The safer, easier way to pay online!">
<img alt="" border="0" src="https://www.paypalobjects.com/en_US/i/scr/pixel.gif" width="1" height="1">
</form>

<p class="sidebar">Alternately, you can make a donation by sending me
Bitcoin, at address <span style="font-size: 0.7em">1Kd6tXH5SDAmiFb49J9hknG5pqj7KStSAx</span></p>

<!--
<hr>

<p class="sidebar"> If you benefit from the book, please make a small
donation.  I suggest $3, but you can choose the amount.</p>

<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick">
<input type="hidden" name="encrypted" value="-----BEGIN PKCS7-----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-----END PKCS7-----
">
<input type="image" src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif" border="0" name="submit" alt="PayPal - The safer, easier way to pay online!">
<img alt="" border="0" src="https://www.paypalobjects.com/en_US/i/scr/pixel.gif" width="1" height="1">
</form>

-->

<hr>
<span class="sidebar_title">Sponsors</span>
<br/>

<a href="https://lambdalabs.com/?utm_source=neuralnetworksdeeplearning&utm_medium=banner&utm_campaign=blogin&utm_content=rbannerimg">
  <img src="assets/lambda.png" width="200px" style="padding: 3px 0px 0px 10px; border-style: none;">
</a>
<br>
<div style="line-height: 1.2; padding-bottom: 12px; font-size: 0.8;">
  <a href="https://lambdalabs.com/?utm_source=neuralnetworksdeeplearning&utm_medium=banner&utm_campaign=blogin&utm_content=rtext">Deep Learning Workstations, Servers, and Laptops</a>
</div>

<a href='http://gsquaredcapital.com/'><img src='assets/gsquared.png' width='200px' style="padding: 5px 0px 10px 10px; border-style: none;"></a>

<a href='http://www.tineye.com'><img src='assets/tineye.png' width='200px'
style="padding: 0px 0px 10px 8px; border-style: none;"></a>

<a href='http://www.visionsmarts.com'><img
src='assets/visionsmarts.png' width='210px' style="padding: 0px 0px
0px 0px; border-style: none;"></a> <br/> 

<p class="sidebar">Thanks to all the <a
href="supporters.html">supporters</a> who made the book possible, with
especial thanks to Pavel Dudrenov.  Thanks also to all the
contributors to the <a href="bugfinder.html">Bugfinder Hall of
Fame</a>.  </p>

<hr>
<span class="sidebar_title">Resources</span>

<p class="sidebar"><a href="https://twitter.com/michael_nielsen">Michael Nielsen on Twitter</a></p>

<p class="sidebar"><a href="faq.html">Book FAQ</a></p>

<p class="sidebar">
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning">Code repository</a></p>

<p class="sidebar">
<a href="http://eepurl.com/0Xxjb">Michael Nielsen's project announcement mailing list</a>
</p>

<p class="sidebar"> <a href="http://www.deeplearningbook.org/">Deep Learning</a>, book by Ian
Goodfellow, Yoshua Bengio, and Aaron Courville</p>

<p class="sidebar"><a href="http://cognitivemedium.com">cognitivemedium.com</a></p>

<hr>
<a href="http://michaelnielsen.org"><img src="assets/Michael_Nielsen_Web_Small.jpg" width="160px" style="border-style: none;"/></a>

<p class="sidebar">
By <a href="http://michaelnielsen.org">Michael Nielsen</a> / Dec 2019
</p>
</div>
</p>
<p>
  O sistema visual humano √© uma das maravilhas do mundo. 
  Considere a seguinte sequ√™ncia de digitos manuscritos:
<a name="complete_zero"></a>
</p>
<p>
  <center>
    <img src="images/digits.png" width="160px">
  </center>
 </p>
<p>
  A maioria das pessoas reconhece sem esfor√ßo esses digitos como sendo 504192.
  Mas talvez "sem esfor√ßo" n√£o seja a melhor maneira de descrever esse processo.
   Em cada hemisf√©rio do seu c√©rebro, humanos tem 
  um cortex prim√°rio visual, tamb√©m conhecido como V1, contendo 140 milh√µes de neur√¥nios,
  com dezenas de bilh√µes de conex√µes entre eles. E a vis√£o humana n√£o envolve apenas V1,
  mas uma s√©rie de cortex visuais - V2, V3, V4 e V5 - que fazem um processamento de imagem
  progressivamente mais complexo. N√≥s carregamos em nossas cabe√ßas um supercomputador, 
  que foi condicionado pela evolu√ß√£o ao longo de milh√µes de anos, e se tornou absurdamente
  adaptado em entender o mundo visual. Reconhecer digitos manuscritos n√£o √© f√°cil. A quest√£o 
  √© que n√≥s humanos somos t√£o incr√≠velmente bons em fazer isso que boa parte desse trabalho √© feito
  inconscientemente. E por conta disso n√≥s n√£o apreciamos o qu√£o dif√≠cil √© o problema que nosso
  sistema visual tem que resolver. 
</p>
<p>
  A dificuldade de reconhecimento de padr√µes visuais se torna aparente quando voc√™ tenta escrever
  um programa de computador que seja capaz de reconhecer digitos como esses acima. Algo que parece 
  f√°cil quando n√≥s mesmos fazemos de repente se torna extremamente dif√≠cil. Intui√ß√µes simples sobre 
  como n√≥s reconhecemos formas - "um 9 tem uma volta no topo, e uma linha vertical em baixo a direita" - 
  se mostram n√£o t√£o simples de serem expressas em um algoritmo. Quando se tenta fazer essas 
  regras de forma precisa, voc√™ rapidamente se perde em um mar de exce√ß√µes e casos especiais.
</p>
<p></p>
<p>
  Redes Neurais abordam o problema de uma forma diferente. A ideia √© de pegar um grande n√∫mero de 
  d√≠gitos escritos h√° m√£o, conhecidos como exemplos de treino,
</p>
<p><center><img src="images/mnist_100_digits.png" width="440px"></center>
</p>
<p>
  e ent√£o desenvolver um sistema que consiga aprender a partir desses exemplos de treino. Em outras
  palavras, a rede neural usa os exemplos para automaticamente definir regras para o reconhecimento
  de d√≠gitos manuscritos. Al√©m disso, se aumentarmos o n√∫mero de exemplos de treino, a rede neural
  consegue aprender mais sobre d√≠gitos manuscritos, e ent√£o melhoras sua precis√£o. Foram mostrados 
  100 d√≠gitos de treino acima, talvez n√≥s poderiamos construir um reconhecedor de d√≠gitos manuscritos
  ainda melhor se estivessemos usando milhares o at√© mesmo milh√µes ou bilh√µes de exemplos de treino.
</p>
<p>
  Nesse cap√≠tulo n√≥s iremos escrever um programa de computador implementando uma rede neural que 
  reconhece d√≠gitos manuscritos. O programa tem apenas 74 linhas, e n√£o usa nenhuma biblioteca
  especial para redes neurais. Mas esse pequeno programa pode reconhecer d√≠gitos manuscritos com 
  uma precis√£o de 96%, sem interven√ß√£o humana. Al√©m disso, em cap√≠tulos posteriores n√≥s iremos
  desenvolver ideias que podem melhorar a precis√£o desse programa para n√≠veis acima de 99%. Na verdade, 
  as melhores redes neurais comerciais s√£o agora t√£o boas que elas s√£o usadas em bancos para processar
  cheques, e servi√ßos postais para reconhecer endere√ßos.
</p>
<p>
  N√≥s iremos focar em reconhecimento de manuscritos porque √© um problema prot√≥tipo excelente para aprender
  redes neurais no geral. Como prot√≥tipo ele √© perfeito: √© desafiador - como j√° vimos n√£o √© algo simples
  reconhecer digitos manuscritos - mas tamb√©m n√£o √© dif√≠cil ao ponto de demandar uma solu√ß√£o extremamente
  complicada, ou um poder computacional gigantesco. Al√©m disso, √© uma √≥tima forma de desenvolver t√©cnicas
  mais avan√ßadas como deep learning. Portanto, ao longo desse livro n√≥s iremos retornar v√°rias vezes para 
  o problema de reconhecimento de d√≠gitos manuscritos. Em cap√≠tulos mais avan√ßados iremos discutir como esssas
  ideias podem ser aplicadas em outros problemas como vis√£o computacional, processamento de fala
  e texto, entre outros dom√≠nios.
</p>
<p>
  Se o ponto desse cap√≠tulo fosse apenas escrever um programa de computador para reconhecer digitos manuscritos
  esse capitulo seria muito menor, n√£o √© mesmo? Mas ao longo do caminho n√≥s iremos desenvolver v√°rias ideias 
  chave sobre redes neurais, inclusive dois tipos importantes de neur√¥nios artificiais (o perceptron e o 
  neur√¥nio sigmoid), e tamb√©m o algoritmo de aprendizado padr√£o para redes neurais, conhecido como 
  gradiente stoc√°stico descedente (soa complicado mas n√£o √©, confia no pai). Ao longo do livro, eu irei focar em explicar o 
  <em>porqu√™</em>  das coisas serem feitas do jeito que s√£o, e em construir sua intui√ß√£o em redes neurais. 
  Para abordar tudo isso dessa forma mais did√°tica e profunda √© necess√°rio uma discuss√£o mais longa do que se 
  fosse apresentado apenas as mec√¢nicas b√°sicas de como tudo acontece, mas vale a pena se levarmos em conta o 
  entendimento profundo que esse tipo de abordagem ir√° trazer para voc√™. At√© o final desse cap√≠tulo voc√™ estar√° na posi√ß√£o 
  de entender o que deep learning √©, e porque isso √© t√£o importante.
</p>
<p>
  <h3>
    <a name="perceptrons"></a>
    <a href="#perceptrons">Perceptrons</a>
  </h3>
</p>
<p>
  O que √© uma rede neural? Para come√ßar, eu irei explicar um tipo de neur√¥nio artificial chamado 
  <em>perceptron</em>. Perceptrons foram 
  <a href="http://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ">
    desenvolvidos</a>
  nos anos 50 e 60 pelo cientista 
  <a href="http://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</a>, inspirado por 
  <a href="http://scholar.google.ca/scholar?cluster=4035975255085082870">trabalhos anteriores</a> 
  de  
  <a href="http://en.wikipedia.org/wiki/Warren_McCulloch">Warren McCulloch</a> 
  e  
  <a href="http://en.wikipedia.org/wiki/Walter_Pitts"> WalterPitts</a>. 
  Hoje em dia √© mais comum usar um outro modelo de neur√¥nio artificial - neste livro, e em muitos livros
  modernos sobre redes neurais, o modelo principal usado √© um chamado <em>neur√¥nio sigmoid</em>. N√≥s iremos 
  abordar os neur√¥nios sigmoids em breve. Mas para entender o porqu√™ dos neur√¥nios sigmoids serem definidos
  do jeito que s√£o, vale a pena entender perceptrons antes.
</p>
<p>
  Ent√£o como perceptrons funcionam? Um perceptron recebe v√°rias entradas bin√°rias, $x_1, x_2, \ldots$, e 
  produz uma sa√≠da bin√°ria: 
<center>
<img src="images/tikz0.png"/>
</center>
Esse exemplo mostra um perceptron que recebe tr√™s entradas, $x_1, x_2, x_3$. Em geral ele poderia ter mais 
ou menos entradas. Rosenblatt prop√≥s uma regra simples para calcular a sa√≠da. Ele introduziu <em>pesos</em>
, $w_1,w_2,\ldots$, n√∫meros reais que expressam a import√¢ncia dos respectivos valores de entrada para o 
valor de sa√≠da. A sa√≠da do neur√¥nio, $0$ or $1$, √© determindada se a soma ponderada $\sum_j w_j x_j$ √© menor
ou maior do que um certo <em>valor limite</em>. Assim como os pesos, o limite √© um n√∫mero real que √© 
um parametro do neur√¥nio. Colocando isso em termos mais alg√©bricos:
  <a class="displaced_anchor" name="eqtn1"></a>\begin{eqnarray}
  \mbox{sa√≠da} & = & \left\{ \begin{array}{ll}
      0 & \mbox{if } \sum_j w_j x_j \leq \mbox{valor limite} \\
      1 & \mbox{if } \sum_j w_j x_j > \mbox{ valor limite}
      \end{array} \right.
\tag{1}\end{eqnarray}

  E basicamente √© assim que perceptrons funcionam!
</p>
<p>
  Esse √© o modelo matem√°tico b√°sico. Uma maneira de interpretar o perceptron √© pensar nele como se fosse um
  dispositivo que toma decis√µes atrav√©s da adi√ß√£o de pesos as evid√™ncias que est√£o sendo usadas para realizar
  essa tomada de decis√£o. Deixe-me exemplificar essa ideia. N√£o √© um exemplo muito real√≠stico, mas √© f√°cil de 
  entender, e em breve iremos abordar exemplos mais realistas. Suponha que o fim de semana est√° chegando
  e voc√™ ouviu que vai rolar uma chopada. 
  Voc√™ gosta de chopadas, e est√° tentando decidir entre ir ou n√£o. Estando
  nessa situa√ß√£o talvez voc√™ tenha que tomar essa decis√£o <em>pesando</em> tr√™s fatores:
<ol>
  <li> O clima no dia √© propicio?
  <li> Sua namorada ou namorado vai querer ir com voc√™?
  <li> A chopada √© pr√≥xima de algum transporte p√∫blico?(voc√™ n√£o tem um carro :/)
</ol>
  N√≥s podemos representar esses tr√™s fatores como valores bin√°rios correspondentes $x_1, x_2$, e $x_3$.
  Por exemplo, n√≥s teriamos $x_1 = 1$ se o clima no dia for propicio, e $x_2 = 1$ se seu namorado ou namorada
  quiser ir contigo, e  $x_2 = 0$ se ele ou ela n√£o quiser. E o mesmo acontece com $x_3$ e o transporte p√∫blico.
</p>
<p>
  Agora, suponha que voc√™ goste muito de dan√ßar funk nas chopadas, tanto que voc√™ estaria feliz em ir mesmo se 
  sua namorada(o) n√£o esteja interessada(o) ou se chegar no local seja dif√≠cil.
  Mas talvez voc√™ realmente odeie tempo ruim, e voc√™ n√£o iria na chopada se o clima do dia fossse chuvoso por
  exemplo. Voc√™ pode usar perceptrons para modelar esse tipo de tomada de decis√£o. Uma maneira de fazer isso 
  √© escolhendo um peso $w_1 = 6$ para o clima, e $w_2 = 2$ e $w_3 = 2$ para as outras condi√ß√µes. Quanto maior
  o valor de $w_1$ mais importante para voc√™ √© a quest√£o do clima, bem mais importante do que se o seu namorado(a)
  te acompanhar√°, ou se a chopada √© pr√≥xima do tranporte p√∫blico. Agora suponha que o valor limite √© $5$ para o 
  perceptron. Com essas escolhas, o perceptron  implementa o modelo de decis√£o desejado, apresentando como sa√≠da
  $1$ sempre que o clima √© bom, e $0$ sempre que o clima √© ruim. N√£o faz diferen√ßa para a sa√≠da do perceptron
  se o se namorado(a) quer ir, ou se o transporte p√∫blico √© perto.
</p>
<p>
  Variando os pesos e o valor limite n√≥s podemos gerar diferentes modelos de tomada de decis√£o. Por exemplo,
  suponha que n√≥s escolhamos um valor limite de $3$. Ent√£o o percepron iria decidir que voc√™ deveria ir a 
  chopada sempre que o tempo estivesse bom <em>ou</em> quando ambos a chopada estivesse perto do transporte
  p√∫blico <em>e</em> sua namorada(o) esteja disposta(o) a ir com voc√™. Em outras palavras, ele seria um modelo
  de tomada de decis√£o diferente. Abaixar o valor limite significa que voc√™ est√° mais disposto a ir a chopada 
</p>
<p>
  Obviamente, o perceptron n√£o √© um modelo humano completo de tomada de decis√£o! Mas o que o exemplo illustra
  √© como um perceptron pode pesar diferentes tipos de evid√™ncia com o objetivo de tomar decis√µes. E levando tudo
  isso em conta √© plaus√≠vel considerar que uma rede complexa de perceptrons poderia tomar decis√µes que poderiam
  ser consideradas complexas:
<center>
<img src="images/tikz1.png"/>
</center>
Nessa rede, a primeira coluna de perceptrons - o que chamamos de a primeira <em>camada</em> de perceptrons -
est√° fazendo tr√™s decis√µes bem simples, ao multiplicar pesos aos valores de entrada. E quanto ao a segunda 
camada de perceptrons? Cada um desses perceptrons da segunda camada est√° multiplicando pesos aos valores dos
neur√¥nios das camadas anteriores e tomando decis√µes a partir das decis√µes dos neur√¥nios da camada anterior.
Dessa maneira cada camada pode um perceptron na segunda camada pode tomar uma decis√£o mais complexa e mais
abstrata do que o neur√¥nio da camada anterior. E decis√µes ainda mais complexas podem ser feitas por um perceptron
da terceira camada. Assim, uma rede de perceptrons de v√°rias camadas pode realizar tomadas de decis√µes complexas
</p>
<p>
  A prop√≥sito, quando se define perceptrons, cada perceptron tem apenas um √∫nico valor de sa√≠da. Na rede 
  acima os perceptrons parecem ter multiplos valores de saida. Na verdade eles tem apenas uma √∫nica sa√≠da.
  As v√°rias setas saindo dos perceptrons s√£o apenas para indicar que essa sa√≠da do perceptron √© usada como 
  entrada para v√°rios outros perceptrons da camada seguinte. E menos desajeitado do que desenhar uma √∫nica
  linha que posteriormente se divide em v√°rias setas n√£o √© mesmo?
</p>
<p>
  Vamos simplificar o modo como descrevemos perceptrons. A condi√ß√£o $\sum_j w_j x_j > \mbox{threshold}$
  √© complicacada, √© n√≥s podemos fazer duas mudan√ßas na nota√ß√£o para simplifica-la. A primeira mudan√ßa seria
  escrever $\sum_j w_j x_j$ como um produto escalar, $w \cdot x \equiv \sum_j w_j x_j$, onde $w$ e $x$ s√£o 
  vetores que tem como componentes os pesos e valores de entrada respectivamente. A segunda mudan√ßa √© mover 
  o valor limite - em ingl√™s <em>threshold</em> - para o outro lado da desigualdade, e substituir ele por 
  um valor que √© chamado o <em>bias</em> -  tend√™ncia - de um perceptron $b \equiv-\mbox{threshold}$. 
  usando o bias env√©s do valor limite, a regra do perceptron pode se reescrita: 
<a class="displaced_anchor" name="eqtn2"></a>
\begin{eqnarray}
  \mbox{output} = \left\{ 
    \begin{array}{ll} 
      0 & \mbox{if } w\cdot x + b \leq 0 \\
      1 & \mbox{if } w\cdot x + b > 0
    \end{array}
  \right.
\tag{2}\end{eqnarray} Voc√™ pode interpretar o bias como sendo uma medida de o qu√£o f√°cil √© para que o valor de s√°ida de um determinado
perceptron seja $1$. Ou para colocar em termos mais biol√≥gicos, o bias √© a medida de o qu√£o f√°cil √© para um 
perceptron <em>disparar</em>. Para um perceptron com um bias muito grande, √© extremamente para que a sa√≠da desse
perceptron seja $1$. Mas para um perceptron com um bias muito negativo, √© mais dif√≠cil para o perceptron ter
$1$ como seu valor de sa√≠da. Obviamente, a introdu√ß√£o do bias √© apenas uma pequena mudan√ßa na forma como 
descrevemos perceptrons, mas n√≥s veremos mais tarde que essa pequena mudan√ßa leva para v√°rias simplifica√ß√µes 
de nota√ß√£o. Por causa disso, no resto do livro n√£o usaremos o valor limite, sempre usaremos o bias.
</p>
<p>
  Eu descrevi perceptrons como um metodo de ponderar evidencias para tomar decis√µes. Outra maneira de de utilizar
  perceptrons √© para computar fun√ß√µes l√≥gicas fundamentais para a computa√ß√£o, fun√ß√µes como <CODE>AND</CODE>,
  <CODE>OR</CODE>, e <CODE>NAND</CODE>. Por exemplo, suponha que temos um perceptrons com dois valores de entrada, cada um com peso $-2$, e um bias global de $3$. Esse √© o nosso percepton: 
<center>
<img src="images/tikz2.png"/>
</center>
  √â possivel ver que o valor de entrada $00$ produz uma sa√≠da $1$, desde que $(-2)*0+(-2)*0+3 = 3$ √© positivo.
  Aqui eu introduzi o s√≠mbolo $*$ para tornar a multiplica√ß√£o explicita. Calculos similares mostram que o para 
  valores de entrada $01$ e $10$ produzem a sa√≠da $1$. Mas a entrada $11$ produz a sa√≠da $0$, desde que $(-2)
  *1 +(-2)*1+3 = -1$ seja negativo. E assim nosso percetron implementa um porta l√≥gica <CODE>NAND</CODE>!!
</p>

<p>
  <a name="universality"></a>
</p>
<p>
  O exemplo <CODE>NAND</CODE> nos mostra que podemos usar percetrons para calcular fun√ß√µes l√≥gicas simples. 
  Na verdade, n√≥s podemos usar redes de perceptrons para calcular <em>qualquer</em> fun√ß√£o l√≥gica.
  O porque disso √© que a porta l√≥gica <CODE>NAND</CODE> √© universal para a computa√ß√£o, isso siginifica que,
  n√≥s podemos construir qualquer computa√ß√£o apenas com portas l√≥gicas<CODE>NAND</CODE>. Por exemplo, n√≥s 
  podemos usar portas l√≥gicas <CODE>NAND</CODE> para construir um circuito que adiciona dois bits, $x_1$ e
  $x_2$. Isso requer calcular uma soma <em>bitwise</em>, $x_1 \oplus x_2$, e tamb√©m carregar o bit de valor
  $1$ quando ambos $x_1$ e $x_2$ s√£o $1$, i.e., o bit carregado √© apenas o produto de $x_1 x_2$: 
<center>
 <img src="images/tikz3.png"/>
</center> 
  Para conseguir a rede de perceptrons equivalente a esse circuito n√≥s substituimos todos as portas <CODE>NAND</CODE>
  por perceptrons com duas entradas, cada uma com um peso $-2$, e um bias global $3$. Essa √© a rede resultante.
  Note que eu movi um pouco o perceptron correspondente a porta <CODE>NAND</CODE> do canto inferior direito 
  apenas para tornar mais f√°cil desenhar as setas no diagrama:
<center>
 <img src="images/tikz4.png"/>
</center>
  Um aspecto not√°vel dessa rede de perceptron √© que a sa√≠da do perceptron mais a esquerda √© usada duas vezes
  como entrada do √∫ltimo perceptron de baixo. Quando eu defini o modelo de perceptron eu n√£o disse se esse tipo 
  de dupla entrada era permitida. Na verdade, isso n√£o importa tanto. Se n√≥s n√£o queremos permitir esse tipo de
  coisa, √© poss√≠vel unir as duas linhas em uma √∫nica conex√£o com um peso -4 env√©s de ter duas conex√µes com peso
  -2 (Se voc√™ n√£o acha isso √≥bvio, sugiro que voc√™ pare e prove para si mesmo que esses dois casos s√£o equivalentes).
  Com essa mudan√ßa, a rede fica como na imagem abaixo, com todos os pesos n√£o marcados iguais a -2, e todos 
  os biases iguais 3, e apenas um peso como -4:
<center>
 <img src="images/tikz5.png"/>
</center>
  At√© agora eu tenho desenhado as entradas $x_1$ e $x_2$ como vari√°veis flutuando a esquerda da rede de 
  perceptrons. Na verdade, √© convencional desenhar uma camada extra de perceptrons <em>- a camada de entrada </em>
  - para codificar as entradas: 
<center>
 <img src="images/tikz6.png"/>
</center>
  Essa nota√ß√£o para perceptrons de entrada, que tem uma sa√≠da, mas n√£o tem uma entrada,
<center>
<img src="images/tikz7.png"/>
</center>
  √© uma abrevia√ß√£o. N√£o significa exatamente que o perceptron n√£o tem entradas. Para enxergar isso, suponha que
  tiv√©ssemos um perceptron sem entradas. Nesse caso a media ponderada $\sum_j w_j x_j$ seria sempre zero, e portanto 
  a saida do perceptron seria $1$ se $b > 0$ e seria $0$ se $b \leq 0$. Isso significa que, o perceptron iria 
  simplesmente exibir como saida um valor fixo e n√£o o valor desejado(que seria $x_1$ no exemplo acima). √â melhor pensar nas entradas dos perceptrons como n√£o sendo perceptrons, mas sim como sendo unidades especiais que s√£o
  definidas pela saida dos valores desejados,$x_1, x_2,\ldots$.
</p>
<p>
  O exemplo da adi√ß√£o demonstra como uma rede de perceptrons pode simular um circuito contendo v√°rias portas
  <CODE>NAND</CODE>. E como portas <CODE>NAND</CODE> s√£o universais na computa√ß√£o, portanto perceptrons tamb√©m
  s√£o universais para computa√ß√£o.
</p>
<p>
  A universalidade computacional dos perceptrons, ao mesmo tempo, empolga e desaponta. √â empolgante pois 
  mostra que perceptrons s√£o t√£o poderosos quanto qualquer dispositivo computacional. Mas desaponta no sentido
  de parecer que perceptrons s√£o apenas um novo tipo de porta <CODE>NAND</CODE>.
</p>
<p>
  No entanto, a situa√ß√£o √© melhor do que parece. Acontece que n√≥s podemos inventar <em>algoritimos de aprendizado</em>
  que podem automaticamente mudar os pesos e biases da rede artificial de neur√¥nios. Essa mudan√ßa dos pesos e biases
  acontede em resposta a estimulos externos, sem a interven√ß√£o direta de um programador. Esses algoritimos de aprendizado
  nos permitem usar neur√¥nios artificiais de um jeito que √© radicalmente diferente do uso convencional de portas l√≥gicas.
  Env√©s de explicitamente montar um circuito de portas <CODE>NAND</CODE> e outras portas l√≥gicas, nossa rede neural
  pode simplesmente aprender a resolver problemas, em alguns casos problemas que seriam extremamente dif√≠cil de diretamente
  desenvolver um circuito convencional para resolver.
</p>
<p>
  <h3>
    <a name="sigmoid_neurons"></a>
    <a href="#sigmoid_neurons">Sigmoid neurons</a>
  </h3>
</p>
<p>
  Aprender algoritimos soa aterorizante. Mas n√≥s podemos inventar tais algoritmos para uma rede neural?
  Suponha que n√≥s temos uma rede de perceptrons que gostariamos de usar para resolver um problema. Por
  exemplo, as entradas da rede poderiam ser dados de pixels de um digito manuscrito scanneado. E n√≥s 
  queremos que essa rede aprenda os pesos e biases de forma que a sa√≠da da rede classifique corretamente
  o digito. Para vermos como esse aprendizado funcionaria, suponha que fizessemos uma pequena altera√ß√£o
  em algum peso (ou bias) da rede. O que n√≥s gostariamos √© que essa pequena mudan√ßa no peso cause apenas 
  uma pequena mudan√ßa correspondente na sa√≠da da rede. Como iremos ver mais pra frente, essa propriedade
  √© o que tornar√° o aprendizado poss√≠vel. Esquematicamente, isso √© o que queremos (obviamente essa rede √© 
  muito simples para fazer reconhecimento de manuscritos!):  
</p>
<p>
  <center>
    <img src="images/tikz8.png"/>
  </center>
    <h6><i>Uma pequena mudan√ßa em qualquer peso (ou bias) causa uma pequena mudan√ßa na sa√≠da</i></h6>
</p>
<p>
  Se uma pequena mudan√ßa em um peso (ou bias) causa uma pequena mudan√ßa na sa√≠da, ent√£o n√≥s podemos usar esse
  fato para modificar os pesos e biases para fazer nossa rede se comportar do jeito que queremos. Por exemplo,  
  suponha que a rede classifique erradamente uma imagem de um "8" quando na verdade deveria ser um "9". E ent√£o
  n√≥s repetimos isso, mudando os pesos e biases de novo e de novo para produzir uma saida cada vez melhor. E ent√£o
  essa rede estaria aprendendo.
</p>
<p>
  O problema √© que isso n√£o √© o que acontece quando nossa rede √© formada por perceptrons. Na verdade, uma pequena
  mudan√ßa nos pesos e biases de um perceptron da rede poderia causar uma mudan√ßa dr√°stica na saida desse perceptron,
  mudando a sa√≠da de $0$ para $1$ apenas com uma pequena altera√ß√£o. Essa mudan√ßa dr√°stica, em um √∫nico perceptron,
  poderia causar uma completa mudan√ßa no comportamento da nossa rede. Considerando nosso √∫ltimo exemplo, 
  mesmo que seja poss√≠vel alterar os pesos de modo que a rede classifique de forma correta a imagem de um "9",
  por conta das mudan√ßas feitas na rede, a classifica√ß√£o de todos os outros d√≠gitos acaba sendo comprometida.    
  Isso torna dif√≠cil mudar gradualmente os valores dos pesos e biases de modo a se aproximar do 
  comportamento desejado. Talvez exista um jeito de contornar esse problema. Mas n√£o √© imediatamente √≥bvio.
</p>
<p>
  N√≥s podemos contornar esse problema introduzindo um novo tipo de neur√¥nio artificial chamado neur√¥nio <em>sigmoid</em>.
  Neur√¥nios Sigmoid s√£o similares aos perceptrons, mas modificados para que pequenas mudan√ßas nos pesos e bias causem  
  apenas uma pequena mudan√ßa na sa√≠da. Esse √© o fato crucial que permite que uma rede de neur√¥nios sigmoid aprendam.
</p>
<p>
  Certo, Deixe-me descrever o neur√¥nio sigmoid. N√≥s iremos represent√°-lo da mesma maneira que representamos
  perceptrons:
<center>
<img src="images/tikz9.png"/>
</center>
Assim como o perceptron, o neur√¥nio sigmoid tem entradas, $x_1, x_2, \ldots$. Mas env√©s de ser apenas $0$ ou $1$
essas entradas podem assumir valores <em>entre</em> $0$ e $1$. Ent√£o, por exemplo, $0.638\ldots$ √© uma entrada v√°lida
para o neur√¥nio sigmoid. E assim como o perceptron, o neur√¥nio sigmoid tem pesos para cada entrada,$w_1, w_2,
\ldots$ e um bias global, $b$. Mas a sa√≠da n√£o √© apenas $0$ ou $1$. A sa√≠da de um neur√¥nio sigmoid seria 
$\sigma(w \cdot x+b)$, onde $\sigma$ √© chamado de <em>fun√ß√£o sigmoid</em>*
<span class="marginnote">
*ali√°s, $\sigma$ √© tamb√©m chamado de <em>fun√ß√£o log√≠stica</em>, e essa nova classe de neur√¥nios √© chamada de 
<em>neur√¥nios log√≠sticos</em>. √â √∫til lembrar dessas terminologias, j√° que esses termos s√£o usados por grande 
parte das pessoas trabalhando com redes neurais. No entanto, n√≥s iremos usar a terminologia sigmoid.
</span>, ela √© definida do seguinte modo:

<a class="displaced_anchor" name="eqtn3"></a>\begin{eqnarray} 
  \sigma(z) \equiv \frac{1}{1+e^{-z}}.
\tag{3}\end{eqnarray}
Tornando ess defini√ß√£o um pouco mais expl√≠cita, a sa√≠da do neur√¥nio sigmoid com entradas $x_1,x_2,\ldots$, pesos
$w_1,w_2,\ldots$, e bias $b$ √©
<a class="displaced_anchor" name="eqtn4"></a>\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
\tag{4}\end{eqnarray}
</p>
<p>
  A primeira vista, neur√¥nios sigmoid parecem ser bem diferentes dos perceptrons. A forma alg√©brica da fun√ß√£o
  sigmoid parece meio opaca e proibitiva se voc√™ n√£o est√° familiarizado com ela. No entanto, existem v√°rias
  similaridades entre perceptrons e neur√¥nio sigmoid, e a forma alg√©brica da fun√ß√£o sigmoid √© muito mais um
  detalhe t√©cnico do que uma barreira para entender o conceito.
</p>
 <p>
   Para entender a similaridade com o perceptron, suponha  que $z\equiv w \cdot x + b$ √© um n√∫mero positivo grande.
   Ent√£o $e^{-z}\approx 0$ e portanto $\sigma(z) \approx 1$. Em outras palavras, quando $z = w\cdot x+b$ √© grande e
   positivo, a sa√≠da do neur√¥nio sigmoid √© aproximadamente $1$, ou seja, aproximadamente o que n√≥s teriamos caso fosse 
   um perceptron. Agora suponha que $z = w \cdot x+b$ √© bem negativo. Portanto $e^{-z} \rightarrow \infty$ e $\sigma(z) \approx 0$. 
   Ent√£o quando $z = w \cdot x +b$ √© muito negativo, o comportamento do neur√¥nio sigmoid tamb√©m se aproxima ao de um 
   perceptron. Apenas quando $w \cdot x+b$ √© um tamanho entre $0$ e $1 o neur√¥nio sigmoid se comporta diferente
   de um perceptron.
 </p>
 <p>
   E quanto a forma alg√©brica de $\sigma$? Como n√≥s podemos entender isso? No fim das contas a exata forma de $\sigma$
   n√£o √© t√£o importante - o que realmente importa √© o formato da fun√ß√£o quando desenhado no gr√°fico. O formato √© o 
   seguinte:
</p>
<p>
<div id="sigmoid_graph"><a name="sigmoid_graph"></a></div>
<script src="http://d3js.org/d3.v3.min.js"></script>
<script>
function s(x) {return 1/(1+Math.exp(-x));}
var m = [40, 120, 50, 120];
var height = 290 - m[0] - m[2];
var width = 600 - m[1] - m[3];
var xmin = -5;
var xmax = 5;
var sample = 400;
var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
var data = d3.range(sample).map(function(d){ return {
        x: x1(d), 
        y: s(x1(d))}; 
    });
var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
var y = d3.scale.linear()
                .domain([0, 1])
                .range([height, 0]);
var line = d3.svg.line()
    .x(function(d) { return x(d.x); })
    .y(function(d) { return y(d.y); })
var graph = d3.select("#sigmoid_graph")
    .append("svg")
    .attr("width", width + m[1] + m[3])
    .attr("height", height + m[0] + m[2])
    .append("g")
    .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
var xAxis = d3.svg.axis()
                  .scale(x)
                  .tickValues(d3.range(-4, 5, 1))
                  .orient("bottom")
graph.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0, " + height + ")")
    .call(xAxis);
var yAxis = d3.svg.axis()
                  .scale(y)
                  .tickValues(d3.range(0, 1.01, 0.2))
                  .orient("left")
                  .ticks(5)
graph.append("g")
    .attr("class", "y axis")
    .call(yAxis);
graph.append("path").attr("d", line(data));
graph.append("text")
     .attr("class", "x label")
     .attr("text-anchor", "end")
     .attr("x", width/2)
     .attr("y", height+35)
     .text("z");
graph.append("text")
        .attr("x", (width / 2))             
        .attr("y", -10)
        .attr("text-anchor", "middle")  
        .style("font-size", "16px") 
        .text("sigmoid function");
</script>
</p><p>Esse formato √© basicamente um formato mais suave de uma fun√ß√£o de degrau:</p><p>
<div id="step_graph"></div>
<script>
function s(x) {return x < 0 ? 0 : 1;}
var m = [40, 120, 50, 120];
var height = 290 - m[0] - m[2];
var width = 600 - m[1] - m[3];
var xmin = -5;
var xmax = 5;
var sample = 400;
var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
var data = d3.range(sample).map(function(d){ return {
        x: x1(d), 
        y: s(x1(d))}; 
    });
var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
var y = d3.scale.linear()
                .domain([0,1])
                .range([height, 0]);
var line = d3.svg.line()
    .x(function(d) { return x(d.x); })
    .y(function(d) { return y(d.y); })
var graph = d3.select("#step_graph")
    .append("svg")
    .attr("width", width + m[1] + m[3])
    .attr("height", height + m[0] + m[2])
    .append("g")
    .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
var xAxis = d3.svg.axis()
                  .scale(x)
                  .tickValues(d3.range(-4, 5, 1))
                  .orient("bottom")
graph.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0, " + height + ")")
    .call(xAxis);
var yAxis = d3.svg.axis()
                  .scale(y)
                  .tickValues(d3.range(0, 1.01, 0.2))
                  .orient("left")
                  .ticks(5)
graph.append("g")
    .attr("class", "y axis")
    .call(yAxis);
graph.append("path").attr("d", line(data));
graph.append("text")
     .attr("class", "x label")
     .attr("text-anchor", "end")
     .attr("x", width/2)
     .attr("y", height+35)
     .text("z");
graph.append("text")
        .attr("x", (width / 2))             
        .attr("y", -10)
        .attr("text-anchor", "middle")  
        .style("font-size", "16px") 
        .text("step function");
</script>
</p>
<p>
  Se $\sigma$ fosse realmente uma fun√ß√£o de degrau, ent√£o o neur√¥nio sigmoid seria um perceptron, j√° que a 
  sa√≠da seria $1$ ou $0$ dependendo se $w\cdot x+b$ <em>fosse</em> positivo ou negativo* 
<span class="marginnote">
  *Na verdade, quando $w \cdot x +b = 0$ o perceptron tem como sa√≠da $0$, enquanto a fun√ß√£o degrau tem como sa√≠da $1$.
  Portanto, caso fossemos abordar de forma mais rigorosa, a fun√ß√£o degrau teria que ser modificada nesse ponto.
  Mas acho que voc√™ entendeu a ideia.
</span>.  
  Usando a fun√ß√£o $\sigma$ n√≥s temos, como j√° citado acima, um perceptron mais suave. De fato, essa suavidade da 
  fun√ß√£o $\sigma$ √© um fato crucial, e n√£o sua forma detalhada. A suavidade de $\sigma$ significa que pequenas mudan√ßas
  $\Delta w_j$ nos pesos e $\Delta b$ no bias ir√£o produzir uma pequena mudan√ßa $\Delta \mbox{output}$ na sa√≠da do neur√¥nio.
  Ali√°s, n√≥s podemos aproximar $\Delta \mbox{output}$ para  
<a class="displaced_anchor" name="eqtn5"></a>\begin{eqnarray} 
  \Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
  \Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b,
\tag{5}\end{eqnarray}

  Onde a soma √© de todos os pesos, $w_j$, e  $\partial \,\mbox{output} / \partial w_j$ e $\partial \, \mbox{output} /\partial
  b$ denota a derivada parcial da sa√≠da $\mbox{output}$ com respeito a $w_j$ e $b$, respectivamente. N√£o entre
  em p√¢nico se voc√™ n√£o est√° familiarizado com derivadas parciais! A express√£o acima parece complicada, com as 
  derivadas parciais, no entanto essa express√£o est√° dizendo algo bastante simples: $\Delta\mbox{output}$ √© uma
  <em>fun√ß√£o linear</em> das mudan√ßas $\Delta w_j$ e $\Delta w_j$ nos pesos e bias. Essa linearidade torna mais
  f√°cil escolher as pequenas mudan√ßas nos pesos e biases que causam as mudan√ßas desejadas na sa√≠da. Portanto, mesmo
  os neur√¥nios sigmoid tendo um comportamento muito parecido com perceptrons, eles conseguem tornar o trabalho de
  descobrir como as mudan√ßas nos pesos e biases est√£o influenciando a sa√≠da muito mais f√°cil.
</p>

<p>
  Se √© o formato de $\sigma$ que realmente importa, e n√£o √© exatamente sua forma, ent√£o porque usar essa forma
  em particular para $\sigma$ na equa√ß√£o 
   <span id="margin_301539119283_reveal" class="equation_link">(3)
</span>
<span id="margin_301539119283" class="marginequation" style="display: none;">
  <a href="chap1.html#eqtn3" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
    \begin{eqnarray} 
  \sigma(z) \equiv \frac{1}{1+e^{-z}} \nonumber\end{eqnarray}</a></span>
  <script>$('#margin_301539119283_reveal').click(function() {$('#margin_301539119283').toggle('slow', function() {});});
  </script>? Na verdade, no decorrer do livro n√≥s vamos ocasionalmente considerar neur√¥nios onde a sa√≠da √©
$f(w \cdot x + b)$ para alguma outra <em>fun√ß√£o de ativa√ß√£o</em> $f(\cdot)$. O principal aspecto que muda ao usar
uma fun√ß√£o de ativa√ß√£o diferente √© que os valores em particular das equa√ß√µes diferenciais 
 <span id="margin_244684310360_reveal" class="equation_link">(5)</span><span id="margin_244684310360" class="marginequation" style="display: none;"><a href="chap1.html#eqtn5" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
  \Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b \nonumber\end{eqnarray}</a></span><script>$('#margin_244684310360_reveal').click(function() {$('#margin_244684310360').toggle('slow', function() {});});</script>
  mudam. Acontece que n√≥s calculamos as derivadas parciais depois, usando $\sigma$ n√≥s vamos simplificar a algebra,
  pois exponenciais tem lindas caracter√≠sticas quando diferenciadas. Nesse caso, $\sigma$ √© vastamente usada em 
  trabalhos de rede neural, e √© a fun√ß√£o de ativa√ß√£o que mais iremos usar nesse livro.
</p>
<p>
  Como n√≥s devemos interpretar a sa√≠da de um neur√¥nio sigmoid? Obviamente, uma grande diferen√ßa entre perceptrons
  e sigmoids √© que neur√¥nios sigmoids n√£o tem como sa√≠da apenas $0$ e $1$. Eles podem ter como sa√≠da qualquer n√∫mero
  real entre $0$ e $1$, portanto valores como $0.173\ldots$ e $0.689\ldots$ s√£o valores de sa√≠da leg√≠tmos.
  Essaa caracter√≠stica √© bem √∫til. por exemplo, se n√≥s queremos usar o valor de sa√≠da para representar a intensidade
  m√©dia dos pixels de uma imagem de entrada para uma rede neural. Mas as vezes pode ser inc√¥modo. Suponha que 
  n√≥s queremos que a sa√≠da da rede indique se "a a imagem de entrada √© um 9" ou "se a imagem de entrada n√£o √© um 9". 
  Obviamente, seria bem mais f√°cil fazer isso se a sa√≠da fosse apenas $0$ e $1$, como √© em um perceptron. Mas em pr√°tica
  n√≥s podemos estabelecer uma conven√ß√£o para lidar com isso, por exemplo, se decidirmos interpretar qualquer sa√≠da que seja
  ao menos $0.5$ como indicando um "9", e qualquer sa√≠da menor que $0.5$ como indicando "n√£o √© um 9". Eu sempre
  irei dizer quando estivermos usando conven√ß√µes assim para n√£o causar nenhuma confus√£o.
</p>
<p>
<h4><a name="exercises_191892"></a><a href="#exercises_191892">Exerc√≠cios</a></h4><ul>
<li>
  <strong>Neur√¥nios sigmoid simulando perceptrons, parte I</strong> $\mbox{}$ <br/>
  Suponha que pegamos todos os pesos e biases de uma rede de perceptrons, multiplicamos por uma constante
  positiva, $c > 0$. Mostre que o comportamento da rede n√£o ir√° mudar.
</p>
<p>
  <li><strong>Neur√¥nios sigmoid simulando perceptrons, parte II<</strong> $\mbox{}$
  <br/>
  Suponha que n√≥s temos o mesmo context do problema anterior - uma rede de perceptrons. Suponha tamb√©m que 
  a entrada geral da rede de perceptrons j√° foi escolhida. N√≥s n√£o iremos precisar do valor de entrada em si, 
  n√≥s iremos apenas precisar que a entrada esteja fixada. Suponha que os pesos e biases s√£o valores tais que
  $w \cdot x + b \neq 0$ para uma entrada $x$ para qualquer neur√¥nio em particular. Agora substitua todos os
  perceptrons da rede por neur√¥nios sigmoid, e multiplique os pesos e biases por uma constante positiva $c > 0$.  
  Mostre que no limite $c \rightarrow \infty$ o comportamento da rede de neur√¥nios sigmoid √© o mesmo da rede
  de perceptrons. Como isso poderia falhar quando $w \cdot x + b = 0$ para um dos perceptrons?
  </ul>
</p>
<p>
  <h3>
    <a name="the_architecture_of_neural_networks"></a><a href="#the_architecture_of_neural_networks">A arquitetura de redes neurais</a>
  </h3>
</p>
<p>
  Nessa pr√≥xima sess√£o eu irei introduzir uma rede neural que classifica digitos manuscritos. Em prepara√ß√£o para 
  isso, ajuda se n√≥s olharmos um pouco da terminologia que permite nomear difetentes partes de uma rede. Suponha
  que temos a rede:
<center>
<img src="images/tikz10.png"/>
</center>
  Como mencionado anteriormente, a camada mais a esquerda dessa rede √© chamada de camada de entrada, e os neur√¥nios
  pertencentes a essa camada s√£o chamados de <em>neur√¥nios de entrada</em>. A camada mais a direita ou <em>camada
  de sa√≠da</em> cont√©m os <em>neur√¥nios de sa√≠da</em>, ou, nesse caso, um √∫nico neur√¥nio de sa√≠da. A camada do meio
  √© chamada <em>camada escondida</em>, j√° que os neur√¥nios dessa camada n√£o s√£o nem de entrada ou sa√≠da. O termo
  "escondida" talvez soe um pouco misterioso - a primeira vez que eu escutei esse termo eu pensei que tivesse 
  algo profundamente filos√≥fico ou matem√°tico escondido nesses neur√¥nios - mas na real n√£o significa nada al√©m de
  "n√£o √© nem entrada nem sa√≠da". A rede acima tem apenas uma camada escondida, mas em algumas redes n√≥s temos multiplas
  camadas escondidas. Por exemplo, a seguinte rede de quatro camadas tem duas camadas escondidas:
<center>
<img src="images/tikz11.png"/>
</center>
  Um pouco confuso, e por raz√µes hist√≥ricas, essas redes de m√∫ltiplas camadas s√£o chamadas <em>multilayer perceptrons</em>
  ou <em>perceptrons de m√∫ltiplas camadas</em> para abreviar <em>MLPs</em>, apesar de elas serem feitas de neur√¥nios
  sigmoid, e n√£o perceptrons. Eu n√£o irei usar a terminologia das MLPs nesse livro, pois eu penso que √© confuso,
  mas eu gostaria de alertar voc√™ da exist√™ncia dessa terminologia.
</p>
<p>
  O design das camadas de entrada e sa√≠da das redes √© na maioria das vezes bem direta. Por exemplo, suponha que
  n√≥s estamos tentando determinar se uma imagem manuscrita √© um "9" ou n√£o. O modo mais natural de fazer essa rede
  √© codificar as intensidades dos pixels da imagem para os neur√¥nios de entrada. Se uma imagem tem dimens√µes $64$
  por $64$ e √© preto e branca, ent√£o n√≥s temos $4,096 = 64 \times 64$ neur√¥nios de entrada com intensidades em escalas
  que est√£o entre $0$ e $1$. A camada de sa√≠da ir√° conter apenas um neur√¥nio, com valores de sa√≠da menores do que
  $0.5$ indicando "a imagem de entrada n√£o √© um 9", e valores maiores do que $0.5$ indicando "a imagem de entrada
  √© um 9".
</p>
<p>
</p>
<p>
</p>
<p>
  Enquanto o design das camadas de entrada e de sa√≠da de uma rede neural √© na maioria das vezes bem direta,
  o design das camadas escondidas - <i>hidden layers</i> - por sua vez, tem aspectos que podem ser considerados 
  art√≠sticos. Em particular, n√£o √© poss√≠vel resumir o processo de fazer o design de hidden layers com uma simples
  regra ou m√©todo. Env√©s disso, pesquisadores de redes neurais desenvolveram diversos designs para as camadas escondidas,
  de modo que se possa conseguir o comportamento desejado para sua rede. Por exemplo, esses designs podem ser usados
  para determinar como decidir-se quanto a rela√ß√£o entre o tempo de treino de uma determinada rede e seu n√∫mero de camadas.
  N√≥s iremos encontrar v√°rios desses designs ao longo desse livro.
</p>

<p>
  At√© agora, n√≥s temos discutido redes neurais onde a sa√≠da de uma camada √© usada serve como entrada da pr√≥xima camada.
  Essas redes s√£o chamadas de <em>feedforward neural networks</em> ou <em>redes neurais feedfoward</em>. Isso significa
  que n√£o a loop na rede - a informa√ß√£o √© sempre passada para frente, nunca para tr√°s. Se n√≥s tiv√©ssemos loops,
  n√≥s acabar√≠amos em situa√ß√µes onde a entrada da fun√ß√£o $\sigma$ depende da sa√≠da. E isso √© d√≠ficil de se lidar,
  portanto n√≥s n√£o permitimos a exist√™ncia desses loops.
</p>
<p>
  No entanto, existem outros modelos de redes de neur√¥nios artificiais onde loops de feedback s√£o poss√≠veis.
  Esses modelos s√£o chamados 
<a href="http://en.wikipedia.org/wiki/Recurrent_neural_network">
  redes neurais recorentes
  </a>. 
  A ideia desses modelos √© ter neur√¥nios que disparam em uma dura√ß√£o limitada de tempo, antes de ficarem em 
  repouso. Esse disparo pode estimular outros neur√¥nios, que talvez disparem tamb√©m um pouco depois, tamb√©m por
  um tempo limitado. Isso faz ainda mais neur√¥nios dispararem, e ent√£o com o tempo n√≥s temos uma rea√ß√£o em cadeia
  de neur√¥nios disparando. Loops n√£o causam problemas em modelos como esse, j√° que a sa√≠da de um neur√¥nio
  s√≥ afeta a sua entrada depois de um tempo, n√£o instantaneamente. 
 </p>
 <p>
 </p>
 <p>
   Redes neurais recorentes tem sido menos influentes que redes feedfoward, em parte porque os algoritimos
   de aprendizado para redes recorentes s√£o menos poderosas. Mas mesmo assim,redes recorentes s√£o extremamente
   interessantes. Elas est√£o muito mais pr√≥ximas do modo como o nosso c√©rebro realmente funciona se comparado
   com redes feedfoward. E em alguns casos, redes recorentes podem resolver de forma mais eficiente alguns 
   problemas do que redes feedfoward. No entanto, para limitar o nosso escopo, nesse livro n√≥s iremos nos
   concentrar nas, amplamente mais utilizadas, redes feedfoward.
</p>
<p>
  <h3>
    <a name="a_simple_network_to_classify_handwritten_digits"></a>
    <a href="#a_simple_network_to_classify_handwritten_digits">
      Uma rede simples para classificar d√≠gitos manuscritos
    </a>
  </h3>
</p>
  <p>
    Tendo definido o que s√£o redes neurais, vamos retornar ao reconhecimento de digitos manuscritos.
    N√≥s podemos dividir o problema de reconhecer digitos em dois sub problemas. Primeiro, precisamos
    quebrar uma imagem contendo multiplos digitos em uma sequencia de imagens separadas contendo, cada
    uma, contendo apenas um d√≠gito. Por exemplo, n√≥s gostariamos de quebrar a imagem 
  </p>
  <p>
    <center>
      <img src="images/digits.png" width="300px">
    </center>
  </p>
  <p>
    em seis imagens separadas, 
  </p>
  <p>
    <center>
      <img src="images/digits_separate.png" width="440px">
    </center> 
  </p>
  <p>
    N√≥s humanos resolvemos esse <em>problema de segmenta√ß√£o</em> com facilidade, mas √© desafiador para
    um programa de computador para quebrar uma imagem assim corretamente. Ap√≥s a imagem ser segmentada,
    o programa ent√£o precisa classificar cada d√≠gito individual. Ent√£o, por exemplo, n√≥s gostariamos que
    o nosso programa fosse capaz de reconhecer o primeiro d√≠gito acima,
  </p>
<p>
  <center>
    <img src="images/mnist_first_digit.png" width="64px">
  </center>
</p>
<p>
  √© um 5.
</p>
<p>
  N√≥s iremos focar em escrever um programa para resolver o segundo problema, que √©, classificar os
  d√≠gitos individuais. N√≥s iremos fazer isso porque o problema de segmenta√ß√£o n√£o √© t√£o dif√≠cil de 
  resolver. Existem v√°rias formas de abordar o problema de segmenta√ß√£o. Uma dessas abordagens √© tentar
  v√°rias diferentes formas de segmentar a imagem, usando um d√≠gito individual para classificar os pontos
  de cada tentativa de segmenta√ß√£o. Uma tentativa de segmenta√ß√£o ganha uma pontua√ß√£o alta se o d√≠gito 
  individual de classificador est√° de acordo com sua classifica√ß√£o em todos os segmentos, e uma pontua√ß√£o
  baixa se o classificador est√° tendo muitos problemas em um ou mais segmentos. A ideia √© se o classificador
  est√° tendo problema em algum lugar, ent√£o √© prov√°vel que esteja tendo esse problema porque a segmenta√ß√£o
  foi escolhida incorretamente. Essa ideia e outras varia√ß√µes podem ser usadas para resolver o problema da
  segmenta√ß√£o de forma satisfat√≥ria. Ent√£o env√©s de se preocupar com a segmenta√ß√£o n√≥s iremos nos preocupar
  com um problema mais interessante e dif√≠cil, chamado, reconhecimento de d√≠gitos manuscr√≠tos individuais.

</p>
<p>
  Para reconhecer um d√≠gito individual n√≥s iremos usar uma rede neural de tr√™s camadas:
</p>
<p>
  <center>
    <img src="images/tikz12.png"/>
  </center>
</p>
<p>
  A camada de entrada da rede cont√©m neur√¥nios codificando os valores de entradas dos pixels de entrada.
  Como discutido na se√ß√£o anterior, nossos dados de treino para a rede consiste de v√°rias imagens de 
  $28$ por $28$ pixels de d√≠gitos manuscritos escaneados, e portanto a camada de entrada cont√©m $784 = 28
  \times 28$ neur√¥nios. Por quest√£o de simplicidade eu omiti grande parte dos $784$ neur√¥nios de entrada no
  diagrama acima. Os pixels de entrada s√£o preto e branco, com o valor $0.0$ representando brancho, e o valor
  de $1.0$ representando preto, e os valores entre, representam os diferentes tons de cinza.
</p>
<p>
  A segunda camada da rede √© uma camada escondida. N√≥s denotamos o n√∫mero de neur√¥nios nessa camada escondida
  por $n$, e n√≥s iremos experimentar com diferentes valores para $n$. O exemplo ilustra uma pequena camada
  escondida, contendo apenas $n = 15$ neur√¥nios.
</p>
<p>
  A camada de sa√≠da da rede cont√©m 10 neur√¥nios. Se o primeiro neur√¥nio dispara, i.e., tem a sa√≠da $\approx 1$,
  ent√£o isso indica que a rede acha que o d√≠gito √© um $0$. Se o segundo neur√¥nio dispara ent√£o isso indica
  que a rede acha que o d√≠gito √© um $1$. E por a√≠ vai. Sendo um pouvo mais preciso, n√≥s numeramos os neur√¥nios de 
  sa√≠da de $0$ a $9$, e vemos qual neur√¥nio tem o maior valor de ativa√ß√£o. Se esse neur√¥nio for o neur√¥nio n√∫mero
  $6$ por exemplo, ent√£o a rede acha que o d√≠gito de entrada √© um $6$. E a mesma coisa vale para os outros neur√¥nios.

</p>
<p>
  Talvez voc√™ esteja se perguntando porque n√≥s usamos $10$ neur√¥nios de sa√≠da. Afinal,o objetivo da rede √© dizer
  que d√≠gito ($0, 1, 2, \ldots, 9$) corresponde a imagem de entrada. Um jeito natural de fazer isso √© usar apenas
  $4$ neur√¥nios de sa√≠da, tratando cada neur√¥nio como se estivesse recebendo um valor bin√°rio, dependendo se a sa√≠da
  do neur√¥nio √© pr√≥xima de $0$ ou de $1$. Quatro neur√¥nios s√£o suficientes para codificar a resposta, j√° que 
  $2^4 = 16$ √© mais do que 10 valores poss√≠veis de entrada de d√≠gitos. Porque usar uma rede que usa $10$ neur√¥nios 
  ent√£o? N√£o seria ineficiente? A justificativa √© emp√≠rica: n√≥s podemos testar ambos os designs, mas acontece que,
  para esse problema em particular, a rede de $10$ neur√¥nios de sa√≠da aprende a reconhecer d√≠gitos melhor do que a
  rede de $4$ d√≠gitos de sa√≠da. Mas isso deixa a d√∫vida, <em>porque</em> usar $10$ neur√¥nios √© melhor. Existe alguma
  heur√≠stica que poderia nos dizer adiantado se n√≥s devemos usar $10$ neur√¥nios de sa√≠da ou $4$?
</p>
<p>
  Para entender o porqu√™ de n√≥s fazermos isso, ajuda pensar sobre o que a rede neural est√° fazendo desde os
  primeiros princ√≠pios. Considere o primeiro caso onde n√≥s usamos $10$ neur√¥nios de sa√≠da. Vamos concentrar
  no primeiro neur√¥nio de sa√≠da, o que est√° tentando decidir se o d√≠gito √© um ou n√£o um $0$. Ele faz isso
  pesando as evid√™ncias fornecidas pela camada escondida de neur√¥nios. E o que esses neur√¥nios escondidos est√£o
  fazendo? Bem, apenas suponha em prol do argumento que que o primeiros neur√¥nio na camada escondida detecta
  se uma imagem √© ou n√£o como essa:
</p>
<p>
  <center>
    <img src="images/mnist_top_left_feature.png" width="130px">
  </center>
</p>
<p>
  Ele faz isso pesando intensamente os pixels de entrada que sobrep√µem com a imagem, e pesando de leve as 
  outras entradas. De maneira similar, vamos supor que em prol do argumento que o segundo, terceiro, e quarto
  neur√¥nio na camada escondida detectam se as seguintes imagens est√£o presentes:
</p>
<p>
  <center>
    <img src="images/mnist_other_features.png" width="424px">
  </center>
</p>
<p>
  Como voc√™ j√° deve ter advinhado, essas quatro imagens juntas formam a imagem do $0$ que n√≥s vimos na linha
  de d√≠gitos mostrado <a href="#complete_zero">anteriormente</a>:
</p>
<p>
  <center>
    <img src="images/mnist_complete_zero.png" width="130px">
  </center>
</p>
<p>
  Portanto, se todos esses quatro neur√¥nios escondidos est√£o disparando ent√£o podemos concluir que o d√≠gito √©
  um $0$. Claro, n√£o s√£o <em>apenas</em> esses tipos de evid√™ncias que n√≥s podemos usar para concluir que
  a imagem √© um $0$ - n√≥s poderiamos classificar esse $0$ de diferentes outras formas (digamos, atrav√©s 
  de tranla√ß√µes das imagens acima, ou leves distor√ß√µes). Mas parece ser mais seguro dizer que ao menos nesse caso
  n√≥s conclu√≠mos que a sa√≠da era um $0$.
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
  Supondo que redes neurais funcionam desse modo, n√≥s podemos dar uma explica√ß√£o plaus√≠vel para o porqu√™ de ser
  melhor ter uma rede com $10$ sa√≠das do que uma com $4$, ent√£o o primeiro neur√¥nio de sa√≠da estaria tentando 
  decidir qual era o bit mais importante do d√≠gito. E n√£o tem jeito f√°cil de relacionar esse d√≠gito mais importante
  com formas simples como as mostradas acima. √â dif√≠cil imaginar que exista alguma boa raz√£o hist√≥rica para que
  as formas que comp√µem o d√≠gito sejam intimamente relacionadas (digamos) ao bit mais significante na sa√≠da. 
</p>
<p>
  Agora, com tudo isso dito, isso tudo √© apenas uma heur√≠stica. Nada diz que essa rede neural de tr√™s camadas
  tem que operar dessa maneira descrita, com os neur√¥nios escondidos (aqueles das camadas entre a sa√≠da e a entrada)
  detectando formas componentes simples. Talvez a algoritimo de aprendizado inteligente ir√° achar alguma atribui√ß√£o
  de pesos que permita n√≥s usarmos apenas $4$ neur√¥nios de sa√≠da. Mas como uma heur√≠stica a maneira de pensar que eu
  descrevi funciona bem, e pode te salvar um bom tempo na hora de fazer o bons designs de rede neurais.
</p>
<p>
  <h4>
    <a name="exercise_513527"></a>
    <a href="#exercise_513527">Exerc√≠cios</a>
  </h4>
  <ul>
    <li>
      Existe uma forma de determinar a representa√ß√£o em bitwise de um d√≠gito atrav√©s da adi√ß√£o de uma camada extra
      na rede de tr√™s camadas cima. A camada extra converte a sa√≠da da camada anterior para uma representa√ß√£o bin√°ria,
      como ilustrado na figura abaixo. Encontre um conjunto de pesos e biases para a nova camada de sa√≠da. Assuma que
      as $3$ primeiras camadas de neur√¥nios s√£o tais que a sa√≠da correta na terceira camada (i.e., a antiga camada de 
      sa√≠da) tem uma ativa√ß√£o de pelo menos $0.99$, e as sa√≠das incorretas tem ativa√ß√£o de menos que $0.01$.
  </ul>
</p>
<p>
  <center>
    <img src="images/tikz13.png"/>
  </center>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
  <h3>
    <a name="learning_with_gradient_descent">
    </a>
    <a href="#learning_with_gradient_descent">
      Learning with gradient descent
    </a>
  </h3>
</p>
<p>
</p>
<p>
  Agora que n√≥s temos um design para a nossa rede neural, como ela pode aprender a reconhecer d√≠gitos? A primeira
  coisa que n√≥s iremos precisar √© um data set de onde aprender - um data set de treino. N√≥s iremos usar o 
   <a href="http://yann.lecun.com/exdb/mnist/">
    data set MNIST
   </a>, 
  que cont√©m dezenas de milhares de imagens escaneadas de d√≠gitos manuscritos, junto com com suas classifica√ß√µes
  corretas. O nome MNIST vem do fato que um um subset modificado de dois data sets coletados pelo 
  <a href="http://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology">NIST</a>,
  Instituto Nacional de Padr√µes e Tecnologia dos EUA. Aqui est√£o algumas imagens do MNIST:

</p>
<p>
  <center>
    <img src="images/digits_separate.png" width="420px">
  </center> 
</p>
<p>
  Como voc√™ pode ver, esse d√≠gitos s√£o na verdade os mesmos daqueles mostrados <a href="#complete_zero">no come√ßo desse cap√≠tulo</a>
  como um desafio para reconhecer. Claro que, quando estivermos testando nossa rede, n√≥s iremos pedir para ela reconhecer
  d√≠gitos que n√£o est√£o no set de treino!
</p>
 <p>
   O data set MNIST vem em duas partes. A primeira parte cont√©m 60,000 imagens para serem usadas como dados de treino.
   Essas imagens s√£o escaneadas de amostras manuscritas de 250 pessoas, das quais metade s√£o funcion√°rios 
   do Census Federal dos EUA, e a outra metade s√£o estudantes do ensino m√©dio. As imagens s√£o em preto e branco de 
   28 por 28 pixels de tamanho. N√≥s iremos usar os dados de teste para avaliar o qu√£o bem nossa rede neural aprendeu
   a reconhecer d√≠gitos. Para fazer um bom teste de perfomance, os dados de teste foram coletados de pessoas <em>diferentes</em>
   daquelas 250 que forneceram os dados de treino. Isso ajuda a n√≥s dar confian√ßa de que o nosso sistema pode reconhecer
   d√≠gitos de pessoas que ela nunca teve contato com a escrita.
.</p>
<p>
  N√≥s iremos usar a nota√ß√£o $x$ para denotar entrada de teste. Ser√° conveniente considerar cada input de treino $x$ como um vetor de
  dimens√£o $28 \times 28 =784$. Cada entrada no vetor representa o valor cinza para um √∫nico pixel da imagem. N√≥s iremos denotar a sa√≠da
  desejada correspondente por $y = y(x)$, onde $y$ √© um vetor de dimens√£o $10$. Por exemplo, se uma imagem de treino em particular, $x$
  representa um $6$, ent√£o $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$ √© a sa√≠da desejada da rede. Note que, $T$ √© a opera√ß√£o de transposi√ß√£o
  tornando o vetor linha em um vetor coluna.
</p>
<p>
  Oque n√≥s gostariamos √© um algoritmo que nos permita encontrar os pesos e biases de forma que a sa√≠da da nossa rede
  se aproxime de $y(x)$ para todos as entradas de treino $x$. Para quantificar o qu√£o bem n√≥s atingimos esse objetivo
  n√≥s definimos uma <em>fun√ß√£o custo</em>* 
  <span class="marginnote"> 
    *Algumas vezes nos referimos a ela como fun√ß√£o <em>perda</em> ou <em>objetivo</em>. N√≥s usamos o termo fun√ß√£o custo ao 
    longo desse livro, mas voc√™ deveria ter em mente essas outras terminologias, j√° que √© usada com frequ√™ncia em artigos
    de pesquisa e outras disscu√ß√µes relacionadas a redes neurais. 
  </span>: 
<a class="displaced_anchor" name="eqtn6"></a>\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2.
\tag{6}\end{eqnarray}
Nesta equa√ß√£o, $w$ denota a cole√ß√£o de todos os pesos na rede, $b$ todos os biases, $n$ √© o n√∫mero total de entradas de
treino, $a$ √© o vetor de sa√≠das da rede quando $x$ √© a entrada, e a soma √© sobre todos as entradas de treino, $x$. Claro,
a sa√≠da $a$ depende de $x$, $w$ e $b$, mas para manter a nota√ß√£o simples eu n√£o explicitamente indiquei essa depend√™ncia.
A nota√ß√£o $\| v \|$ apenas denota o tamanho usual da fun√ß√£o para um determinado vetor $v$. N√≥s iremos chamar $C$ de fun√ß√£o
de custo <em>quadr√°tica</em>; tamb√©m √© conhecida como o<em>erro m√©dio ao quadrado</em> ou apenas <em>MSE(mean squared error)</em>.
Inspecionando a forma da fun√ß√£o de custo quadr√°tica, n√≥s vemos que $C(w, b)$ √© n√£o negativo, j√° que todo termo da soma √© n√£o 
negativo. Al√©m disso, o custo $C(w, b)$ se torna menor, i.e., $C(w, b) \approx 0$, exatamente quando $y(x)$ √© aproximadamente
igual a sa√≠da, $a$, para todos os valores de entrada, $x$. Ent√£o nosso algoritmo de treino faz um bom trabalho se ele consegue
achar os pesos e biases de modo que $C(w,b) \appox 0$. Em contraste, ele n√£o est√° fazendo um bom trabalho se $C(w, b)$ √© grande
- isso significaria que $y(x)$ n√£o est√° pr√≥ximo da sa√≠da $a$ para uma grande parte das entradas. Ent√£o o objetivo do nosso algoritmo
de treino ser√° minimizar a fun√ß√£o custo $C(w, b)$ como um fun√ß√£o em termos dos pesos e biases. Em outras palavras, n√≥s queremos
achar o conjunto de pesos e biases que fa√ßa a fun√ß√£o custo assumir o menor valor poss√≠vel. N√≥s fazemos isso usando um algoritimo
chamado <em>gradiente descendente</em>.
</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>
<p>
  Porque introduzir a fun√ß√£o quadr√°tica? Afinal, n√£o seria o interesse prim√°rio no n√∫mero de imagens classificadas corretamente
  pela rede? Porque n√£o tentar maximizar esse n√∫mero diretamente, env√©s de minimizar um valor indireto como o custo quadr√°tico?
  O problema com isso √© que o n√∫mero de imagens corretamente classificadas n√£o √© uma fun√ß√£o suave dos pesos e biases da rede. Na
  maioria das vezes, fazer pequenas mudan√ßas nos pesos e biases n√£o ir√° causar nenhuma mudan√ßa no n√∫mero de imagens de treino
  classificadas corretamente. Isso torna dif√≠cil descobrir como as mudan√ßas nos pesos e biases est√£o afetando o desempenho da nossa
  rede, e portanto, fica dif√≠cil descobrir como n√≥s podemos mudar esses pesos e biases de modo que melhore o desenpenho. Usando uma
  fun√ß√£o suave, como a fun√ß√£o custo quadr√°tico, torna-se mais f√°cil o trabalho de descobrir como fazer pequenas mudan√ßas nos pesos 
  e biases para melhorar o custo. Por conta disso que n√≥s focamos primeiramente em minimizar o custo quadr√°tico, e apenas depois n√≥s
  examinamos a precis√£o de classifica√ß√£o.  
</p>
<p></p>
<p>
  Mesmo j√° definido que n√≥s iremos usar uma fun√ß√£o de custo suave, talvez voc√™ ainda se pergunte, porque n√≥s escolhemos a fun√ß√£o quadr√°tica
  usada na equa√ß√£o
<span id="margin_368924667121_reveal" class="equation_link">(6)</span>
<span id="margin_368924667121" class="marginequation" style="display: none;">
  <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
    \begin{eqnarray}  C(w,b) \equiv\frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}
  </a>
</span>
<script>$('#margin_368924667121_reveal').click(function() {$('#margin_368924667121').toggle('slow', function() {});});</script>.  
N√£o seria essa escolha <em>ad hoc</em>? Talvez, se escolhida uma fun√ß√£o custo diferente n√≥s ter√≠amos um conjunto de pesos e biases minimizados
completamente diferente? Essa √© uma preocupa√ß√£o v√°lida, mais tarde no livro iremos revisitar a fun√ß√£o custo, e faremos algumas modifica√ß√µes. 
No entanto, a fun√ß√£o de custo quadr√°tica da equa√ß√£o 
<span id="margin_77007455211_reveal" class="equation_link">
  (6)
</span>
<span id="margin_77007455211" class="marginequation" style="display: none;">
  <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_77007455211_reveal').click(function() {$('#margin_77007455211').toggle('slow', function() {});});</script> 

funciona perfeitamente bem para entender os basicos de aprendizado em uma rede neural, t√£o bem que n√≥s iremos nos ater a ela por enquanto.
</p>
<p>
  Recapitulando, nosso objetivo √© treinar uma rede neural para encontrar os pesos e biases que minimizam a fun√ß√£o de custo quadr√°tico
  $C(w, b)$. Esse √© um problema bem posto, mas existem muitas estruturas que podem causar distra√ß√£o na forma como o problema est√° posto 
  atualmente - a interpreta√ß√£o de $w$ e $b$ como pesos e biases, a fun√ß√£o $\sigma$ sendo utilizada no background, a escolha da arquitetura
  da rede, MNIST, e assim vai. Acontece que n√≥s podemos entender muito apenas ignorando boa parte dessa estrutura, e concentrando na parte
  da minimiza√ß√£o. N√≥s iremos desenvolver uma t√©cnica chamada <em>gradiente descendente</em> que n√≥s podemos usar para resolver esses problemas. 
  Ent√£o iremos voltar para a fun√ß√£o espec√≠fica que queremos minimizar para redes neurais.
</p> 
<p>
  Certo, vamos supor que estamos tentando minimizar uma fun√ß√£o, $C(v)$. Essa poderia ser qualquer fun√ß√£o de valor real de muitas vari√°veis,
  #v = v_1, v_2, \ldots$. Note que eu coloquei a nota√ß√£o de $w$ e $b$ como $v$ para enfatizar que essa poderia ser qualquer fun√ß√£o - n√≥s n√£o
  estamos mais pensando no contexto espec√≠fico de redes neurais dessa vez. Para minimizar $C(v)$ ajuda se imaginarmos $C$ como uma fun√ß√£o de 
  apenas duas vari√°veis, que n√≥s iremos chamar $v_1$ e $v_2$:
</p> 
<p>
  <center>
    <img src="images/valley.png" width="542px">
  </center>
</p>
<p>
  O que n√≥s gostar√≠amos de achar √© onde $C$ atinge seu m√≠nimo global. Agora, para a fun√ß√£o que plotamos acima, n√≥s podemos procurar a olho nu
  o m√≠nimo da fun√ß√£o. Nesse sentido, Talvez eu tenha mostrado essa fun√ß√£o de maneira <em>muito</em> simples! Uma fun√ß√£o geral, $C$, pode ser
  uma fun√ß√£o complicada de muitas vari√°veis, e normalmente n√£o ser√° poss√≠vel apenas achar o m√≠nimo da fun√ß√£o olhando pro gr√°fico a olho nu.  
</p>
<p>
  Uma maneira de abordar esse problema √© usando c√°lculo para tentar achar o m√≠nimo analiticamente. N√≥s poder√≠amos calcular as derivadas e ent√£o
  tentar usar elas para achar os lugares em $C$ que s√£o extremos. Com um pouco e sorte talvez funcione quando $C$ √© uma fun√ß√£o de apenas uma ou 
  v√°rias vari√°veis. Mas ir√° se tornar um pesadelo quando n√≥s temos muitas vari√°veis. E para redes neurais quase sempre n√≥s iremos trabalhar com
  <em>muitas</em> vari√°veis - a maior rede neural tem fun√ß√µes custo que dependem de bilh√µes de pesos e biases. Usando c√°lculo para minimizar essa
  fun√ß√£o simplemente n√£o funcionaria.
</p>
<p>
  (Ap√≥s definido que n√≥s iriamos ganhar entendimento se imaginassemos $C$ como uma fu√ß√£o de apenas duas vari√°veis, eu voltei atr√°s duas vezes
  em dois par√°grafos e disse "ei, mas e se for uma fun√ß√£o de mais de duas vari√°veis?" desculpa por isso. Por favor acredite em mim quando digo 
  que realmente ajuda se n√≥s imaginarmos $C$ como uma fun√ß√£o de duas vari√°veis. S√≥ ocorre que algumas vezes essa abordagem quebra e nos dois 
  √∫ltimos par√°grafos n√≥s estamos lidando com isso. Um bom pensamento matem√°tico muitas vezes envolve trabalhar com v√°rias abordagens intuitivas,
  aprendendo quando √© mais apropriado usar cada abordagem, e quando n√£o √©.)
</p>
<p>
  <a name="gradient_descent"></a>
</p>
<p>
  Certo, ent√£o c√°lculo n√£o funciona. Felizmente, exite outra linda analogia que sugere um algoritimo que funciona muito bem. N√≥s come√ßamos
  pensando na nossa fun√ß√£o como se fosse um vale. Se voc√™ olhar bem um pouco para o plot acima, n√£o deve ser t√£o dif√≠cil. Nossa experi√™ncia
  do dia a dia diz que uma bola vai eventualmente rolar para o fundo de um vale. Ser√° que n√≥s poderiamos usar essa ideia para achar o m√≠nimo da
  fun√ß√£o? N√≥s aleat√≥riamente escolhemos um ponto inicial para uma bola (imagin√°ria), e ent√£o simulamos a movimenta√ß√£o da bola quando ela rola para
  o fundo do vale. N√≥s poderiamos fazer essa simula√ß√£o simplesmente calculando as derivadas (e talvez algumas segundas derivadas) de $C$ - essas 
  derivadas que ir√£o nos dizer tudo que n√≥s precisamos saber sobre a "forma" de um determinado local desse vale, e portanto como nossa bola deve 
  rolar.
</p>
<p>
  Basseado no que eu acabei de escrever, voc√™ deve supor que n√≥s iremos tentar escrever as equa√ß√µes de movimento de uma bola de Newton, considerando
  os efeitos de atrito, gravidade e etc. Na verdade, n√≥s n√£o iremos tomar a analogia da bola rolando t√£o s√©rio assim - n√≥s estamos desenvolvendo um 
  algoritmo para minimizar $C$, e n√£o desenvolvendo uma simula√ß√£o de leis da f√≠sica! A vis√£o da bola rolando √© apenas um meio de estimular a sua 
  imagina√ß√£o, e n√£o limitar o seu pensamento. Ent√£o env√©s de entrar nos detalhes da f√≠sica, vamos simplismente n√≥s perguntar: se n√≥s fossemos deus por
  um dia, e pudessemos fazer nossas pr√≥prias leis da f√≠sica, ditando como a bola iria rolar, que lei ou leis do movimento n√≥s poderiamos pegar que faria
  com que a bola movesse para o fundo do vale?
</p>
<p>
  Para tornar essa pergunta mais precisa, vamos pensar sobre o que acontece quando n√≥s movemos a bola pequenas quantidades $\Delta v_1$ na dire√ß√£o $v_1$,
  e uma pequena quantidade $\Delta v_2$ na dire√ß√£o $v_2$. O c√°lculo nos di\ que $C$ muda da seguinte maneira:
<a class="displaced_anchor" name="eqtn7"></a>\begin{eqnarray} 
  \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
  \frac{\partial C}{\partial v_2} \Delta v_2.
\tag{7}\end{eqnarray}
N√≥s iremos encontrar uma maneria de escolher $\Delta v_1$ e $\Delta v_2$ de forma que fa√ßa $\Delta C$ negativo; i.e., n√≥s iremos escolher eles de forma que a 
bola role para o fundo do vale. Para entender como fazer tal escolha ajuda se definirmos %\Delta v$ como sendo o vetor das mudan√ßas em $v$, $\Delta v \equiv 
(\Delta v_1, \Delta v_2)^T$, onde $T$ novamente √© o operador de transposi√ß√£o, tornando vetores linha em vetores coluna. N√≥s iremos definir tamb√©m o <em>gradiente</em>
de $C$ como sendo um vetor das derivadas parciais, $\left(\frac{\partial C}{\partial v_1}, \frac{\partial C}{\partial v_2}\right)^T$. Denotamos o gradiente como sendo
$\nabla C$, i.e.:
<a class="displaced_anchor" name="eqtn8"></a>\begin{eqnarray} 
  \nabla C \equiv \left( \frac{\partial C}{\partial v_1}, 
  \frac{\partial C}{\partial v_2} \right)^T.
\tag{8}\end{eqnarray}

Daqui a pouco iremos rescrever a mudan√ßa $\Delta C$ em termos de $\Delta v$ e de do gradiente, $\nabla C$. Antes de fazermos isso, eu quero deixar claro uma coisa que as vezes
confunde as pessoas quanto ao gradiente. Quando as pessoas encontram a nota√ß√£o $\nabla C$ pela primeira vez, as pessoas as vezes se preguntam, o que $\nabla$ realmente significa?
Na verdade, √© perfeitamente tranquilo de pensar em $\nabla C$ como sendo um objeto matem√°tico singular - o vetor definido acima - que por acaso est√° sendo escrito usando dois simbolos.

In a moment we'll rewrite the change $\Delta C$ in terms of $\Delta v$
and the gradient, $\nabla C$.  Before getting to that, though, I want
to clarify something that sometimes gets people hung up on the
gradient.  When meeting the $\nabla C$ notation for the first time,
people sometimes wonder how they should think about the $\nabla$
symbol.  What, exactly, does $\nabla$ mean?  In fact, it's perfectly
fine to think of $\nabla C$ as a single mathematical object - the
vector defined above - which happens to be written using two
symbols.  In this point of view, $\nabla$ is just a piece of
notational flag-waving, telling you "hey, $\nabla C$ is a gradient
vector".  There are more advanced points of view where $\nabla$ can
be viewed as an independent mathematical entity in its own right (for
example, as a differential operator), but we won't need such points of
view.</p><p>With these definitions, the expression <span id="margin_60068869945_reveal" class="equation_link">(7)</span><span id="margin_60068869945" class="marginequation" style="display: none;"><a href="chap1.html#eqtn7" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
  \frac{\partial C}{\partial v_2} \Delta v_2 \nonumber\end{eqnarray}</a></span><script>$('#margin_60068869945_reveal').click(function() {$('#margin_60068869945').toggle('slow', function() {});});</script> for
$\Delta C$ can be rewritten as
<a class="displaced_anchor" name="eqtn9"></a>\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v.
\tag{9}\end{eqnarray}
This equation helps explain why $\nabla C$ is called the gradient
vector: $\nabla C$ relates changes in $v$ to changes in $C$, just as
we'd expect something called a gradient to do.  But what's really
exciting about the equation is that it lets us see how to choose
$\Delta v$ so as to make $\Delta C$ negative.  In particular, suppose
we choose
<a class="displaced_anchor" name="eqtn10"></a>\begin{eqnarray} 
  \Delta v = -\eta \nabla C,
\tag{10}\end{eqnarray}
where $\eta$ is a small, positive parameter (known as the
<em>learning rate</em>).
Then Equation <span id="margin_777394057862_reveal" class="equation_link">(9)</span><span id="margin_777394057862" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_777394057862_reveal').click(function() {$('#margin_777394057862').toggle('slow', function() {});});</script> tells us that $\Delta C \approx -\eta
\nabla C \cdot \nabla C = -\eta \|\nabla C\|^2$.  Because $\| \nabla C
\|^2 \geq 0$, this guarantees that $\Delta C \leq 0$, i.e., $C$ will
always decrease, never increase, if we change $v$ according to the
prescription in <span id="margin_387482875009_reveal" class="equation_link">(10)</span><span id="margin_387482875009" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_387482875009_reveal').click(function() {$('#margin_387482875009').toggle('slow', function() {});});</script>.  (Within, of course, the
limits of the approximation in Equation <span id="margin_602571566970_reveal" class="equation_link">(9)</span><span id="margin_602571566970" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_602571566970_reveal').click(function() {$('#margin_602571566970').toggle('slow', function() {});});</script>).  This is
exactly the property we wanted!  And so we'll take
Equation <span id="margin_129183303476_reveal" class="equation_link">(10)</span><span id="margin_129183303476" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_129183303476_reveal').click(function() {$('#margin_129183303476').toggle('slow', function() {});});</script> to define the "law of motion"
for the ball in our gradient descent algorithm.  That is, we'll use
Equation <span id="margin_734088671290_reveal" class="equation_link">(10)</span><span id="margin_734088671290" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_734088671290_reveal').click(function() {$('#margin_734088671290').toggle('slow', function() {});});</script> to compute a value for $\Delta
v$, then move the ball's position $v$ by that amount:
<a class="displaced_anchor" name="eqtn11"></a>\begin{eqnarray}
  v \rightarrow v' = v -\eta \nabla C.
\tag{11}\end{eqnarray}
Then we'll use this update rule again, to make another move.  If we
keep doing this, over and over, we'll keep decreasing $C$ until - we
hope - we reach a global minimum.</p><p>Summing up, the way the gradient descent algorithm works is to
repeatedly compute the gradient $\nabla C$, and then to move in the
<em>opposite</em> direction, "falling down" the slope of the valley.
We can visualize it like this:</p><p><center><img src="images/valley_with_ball.png" width="542px"></center></p><p>Notice that with this rule gradient descent doesn't reproduce real
physical motion.  In real life a ball has momentum, and that momentum
may allow it to roll across the slope, or even (momentarily) roll
uphill.  It's only after the effects of friction set in that the ball
is guaranteed to roll down into the valley.  By contrast, our rule for
choosing $\Delta v$ just says "go down, right now".  That's still a
pretty good rule for finding the minimum!</p><p>To make gradient descent work correctly, we need to choose the
learning rate $\eta$ to be small
enough that Equation <span id="margin_693595312216_reveal" class="equation_link">(9)</span><span id="margin_693595312216" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_693595312216_reveal').click(function() {$('#margin_693595312216').toggle('slow', function() {});});</script> is a good approximation.  If
we don't, we might end up with $\Delta C > 0$, which obviously would
not be good!  At the same time, we don't want $\eta$ to be too small,
since that will make the changes $\Delta v$ tiny, and thus the
gradient descent algorithm will work very slowly.  In practical
implementations, $\eta$ is often varied so that
Equation <span id="margin_763885870077_reveal" class="equation_link">(9)</span><span id="margin_763885870077" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_763885870077_reveal').click(function() {$('#margin_763885870077').toggle('slow', function() {});});</script> remains a good approximation, but the
algorithm isn't too slow.  We'll see later how this
works. </p><p>I've explained gradient descent when $C$ is a function of just two
variables.  But, in fact, everything works just as well even when $C$
is a function of many more variables.  Suppose in particular that $C$
is a function of $m$ variables, $v_1,\ldots,v_m$.  Then the change
$\Delta C$ in $C$ produced by a small change $\Delta v = (\Delta v_1,
\ldots, \Delta v_m)^T$ is
<a class="displaced_anchor" name="eqtn12"></a>\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v,
\tag{12}\end{eqnarray}
where the gradient $\nabla C$ is the vector 
<a class="displaced_anchor" name="eqtn13"></a>\begin{eqnarray}
  \nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \ldots, 
  \frac{\partial C}{\partial v_m}\right)^T.
\tag{13}\end{eqnarray}
Just as for the two variable case, we can
choose
<a class="displaced_anchor" name="eqtn14"></a>\begin{eqnarray}
  \Delta v = -\eta \nabla C,
\tag{14}\end{eqnarray}
and we're guaranteed that our (approximate)
expression <span id="margin_796021234053_reveal" class="equation_link">(12)</span><span id="margin_796021234053" class="marginequation" style="display: none;"><a href="chap1.html#eqtn12" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_796021234053_reveal').click(function() {$('#margin_796021234053').toggle('slow', function() {});});</script> for $\Delta C$ will be negative.
This gives us a way of following the gradient to a minimum, even when
$C$ is a function of many variables, by repeatedly applying the update
rule
<a class="displaced_anchor" name="eqtn15"></a>\begin{eqnarray}
  v \rightarrow v' = v-\eta \nabla C.
\tag{15}\end{eqnarray}
You can think of this update rule as <em>defining</em> the gradient
descent algorithm.  It gives us a way of repeatedly changing the
position $v$ in order to find a minimum of the function $C$.  The rule
doesn't always work - several things can go wrong and prevent
gradient descent from finding the global minimum of $C$, a point we'll
return to explore in later chapters.  But, in practice gradient
descent often works extremely well, and in neural networks we'll find
that it's a powerful way of minimizing the cost function, and so
helping the net learn.</p><p></p><p></p><p>Indeed, there's even a sense in which gradient descent is the optimal
strategy for searching for a minimum.  Let's suppose that we're trying
to make a move $\Delta v$ in position so as to decrease $C$ as much as
possible.  This is equivalent to minimizing $\Delta C \approx \nabla C
\cdot \Delta v$.  We'll constrain the size of the move so that $\|
\Delta v \| = \epsilon$ for some small fixed $\epsilon > 0$.  In other
words, we want a move that is a small step of a fixed size, and we're
trying to find the movement direction which decreases $C$ as much as
possible.  It can be proved that the choice of $\Delta v$ which
minimizes $\nabla C \cdot \Delta v$ is $\Delta v = - \eta \nabla C$,
where $\eta = \epsilon / \|\nabla C\|$ is determined by the size
constraint $\|\Delta v\| = \epsilon$.  So gradient descent can be
viewed as a way of taking small steps in the direction which does the
most to immediately decrease $C$.</p><p><h4><a name="exercises_647181"></a><a href="#exercises_647181">Exercises</a></h4><ul>
<li> Prove the assertion of the last paragraph.  <em>Hint:</em> If
    you're not already familiar with the
    <a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Cauchy-Schwarz
      inequality</a>, you may find it helpful to familiarize yourself
    with it.</p><p><li> I explained gradient descent when $C$ is a function of two
  variables, and when it's a function of more than two variables.
  What happens when $C$ is a function of just one variable?  Can you
  provide a geometric interpretation of what gradient descent is doing
  in the one-dimensional case?
</ul></p><p></p><p>People have investigated many variations of gradient descent,
including variations that more closely mimic a real physical ball.
These ball-mimicking variations have some advantages, but also have a
major disadvantage: it turns out to be necessary to compute second
partial derivatives of $C$, and this can be quite costly.  To see why
it's costly, suppose we want to compute all the second partial
derivatives $\partial^2 C/ \partial v_j \partial v_k$.  If there are a
million such $v_j$ variables then we'd need to compute something like
a trillion (i.e., a million squared) second partial
derivatives*<span class="marginnote">
*Actually, more like half a trillion, since
  $\partial^2 C/ \partial v_j \partial v_k = \partial^2 C/ \partial
  v_k \partial v_j$.  Still, you get the point.</span>!  That's going to be
computationally costly.  With that said, there are tricks for avoiding
this kind of problem, and finding alternatives to gradient descent is
an active area of investigation.  But in this book we'll use gradient
descent (and variations) as our main approach to learning in neural
networks.</p><p>How can we apply gradient descent to learn in a neural network?  The
idea is to use gradient descent to find the weights $w_k$ and biases
$b_l$ which minimize the cost in
Equation <span id="margin_552678515184_reveal" class="equation_link">(6)</span><span id="margin_552678515184" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_552678515184_reveal').click(function() {$('#margin_552678515184').toggle('slow', function() {});});</script>.  To see how this works, let's
restate the gradient descent update rule, with the weights and biases
replacing the variables $v_j$.  In other words, our "position" now
has components $w_k$ and $b_l$, and the gradient vector $\nabla C$ has
corresponding components $\partial C / \partial w_k$ and $\partial C
/ \partial b_l$.  Writing out the gradient descent update rule in
terms of components, we have
<a class="displaced_anchor" name="eqtn16"></a><a class="displaced_anchor" name="eqtn17"></a>\begin{eqnarray}
  w_k & \rightarrow & w_k' = w_k-\eta \frac{\partial C}{\partial w_k} \tag{16}\\
  b_l & \rightarrow & b_l' = b_l-\eta \frac{\partial C}{\partial b_l}.
\tag{17}\end{eqnarray}
By repeatedly applying this update rule we can "roll down the hill",
and hopefully find a minimum of the cost function.  In other words,
this is a rule which can be used to learn in a neural network.</p><p>There are a number of challenges in applying the gradient descent
rule.  We'll look into those in depth in later chapters.  But for now
I just want to mention one problem.  To understand what the problem
is, let's look back at the quadratic cost in
Equation <span id="margin_636312544623_reveal" class="equation_link">(6)</span><span id="margin_636312544623" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_636312544623_reveal').click(function() {$('#margin_636312544623').toggle('slow', function() {});});</script>.  Notice that this cost
function has the form $C = \frac{1}{n} \sum_x C_x$, that is, it's an
average over costs $C_x \equiv \frac{\|y(x)-a\|^2}{2}$ for individual
training examples.  In practice, to compute the gradient $\nabla C$ we
need to compute the gradients $\nabla C_x$ separately for each
training input, $x$, and then average them, $\nabla C = \frac{1}{n}
\sum_x \nabla C_x$.  Unfortunately, when the number of training inputs
is very large this can take a long time, and learning thus occurs
slowly.</p><p>An idea called <em>stochastic gradient descent</em> can be used to speed
up learning.  The idea is to estimate the gradient $\nabla C$ by
computing $\nabla C_x$ for a small sample of randomly chosen training
inputs.  By averaging over this small sample it turns out that we can
quickly get a good estimate of the true gradient $\nabla C$, and this
helps speed up gradient descent, and thus learning.</p><p>To make these ideas more precise, stochastic gradient descent works by
randomly picking out a small number $m$ of randomly chosen training
inputs.  We'll label those random training inputs $X_1, X_2, \ldots,
X_m$, and refer to them as a <em>mini-batch</em>.  Provided the sample
size $m$ is large enough we expect that the average value of the
$\nabla C_{X_j}$ will be roughly equal to the average over all $\nabla
C_x$, that is,
<a class="displaced_anchor" name="eqtn18"></a>\begin{eqnarray}
  \frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_x \nabla C_x}{n} = \nabla C,
\tag{18}\end{eqnarray}
where the second sum is over the entire set of training data.
Swapping sides we get
<a class="displaced_anchor" name="eqtn19"></a>\begin{eqnarray}
  \nabla C \approx \frac{1}{m} \sum_{j=1}^m \nabla C_{X_{j}},
\tag{19}\end{eqnarray}
confirming that we can estimate the overall gradient by computing
gradients just for the randomly chosen mini-batch. </p><p>To connect this explicitly to learning in neural networks, suppose
$w_k$ and $b_l$ denote the weights and biases in our neural network.
Then stochastic gradient descent works by picking out a randomly
chosen mini-batch of training inputs, and training with those,
<a class="displaced_anchor" name="eqtn20"></a><a class="displaced_anchor" name="eqtn21"></a>\begin{eqnarray} 
  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial w_k} \tag{20}\\
  
  b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial b_l},
\tag{21}\end{eqnarray}
where the sums are over all the training examples $X_j$ in the current
mini-batch.  Then we pick out another randomly chosen mini-batch and
train with those.  And so on, until we've exhausted the training
inputs, which is said to complete an
<em>epoch</em> of training.  At that point
we start over with a new training epoch.</p><p>Incidentally, it's worth noting that conventions vary about scaling of
the cost function and of mini-batch updates to the weights and biases.
In Equation <span id="margin_28961100271_reveal" class="equation_link">(6)</span><span id="margin_28961100271" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_28961100271_reveal').click(function() {$('#margin_28961100271').toggle('slow', function() {});});</script> we scaled the overall cost
function by a factor $\frac{1}{n}$.  People sometimes omit the
$\frac{1}{n}$, summing over the costs of individual training examples
instead of averaging.  This is particularly useful when the total
number of training examples isn't known in advance.  This can occur if
more training data is being generated in real time, for instance.
And, in a similar way, the mini-batch update rules <span id="margin_38667351831_reveal" class="equation_link">(20)</span><span id="margin_38667351831" class="marginequation" style="display: none;"><a href="chap1.html#eqtn20" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial w_k}  \nonumber\end{eqnarray}</a></span><script>$('#margin_38667351831_reveal').click(function() {$('#margin_38667351831').toggle('slow', function() {});});</script>
and <span id="margin_667554963539_reveal" class="equation_link">(21)</span><span id="margin_667554963539" class="marginequation" style="display: none;"><a href="chap1.html#eqtn21" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  
  b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial b_l} \nonumber\end{eqnarray}</a></span><script>$('#margin_667554963539_reveal').click(function() {$('#margin_667554963539').toggle('slow', function() {});});</script> sometimes omit the $\frac{1}{m}$ term out the
front of the sums.  Conceptually this makes little difference, since
it's equivalent to rescaling the learning rate $\eta$.  But when doing
detailed comparisons of different work it's worth watching out for.</p><p>We can think of stochastic gradient descent as being like political
polling: it's much easier to sample a small mini-batch than it is to
apply gradient descent to the full batch, just as carrying out a poll
is easier than running a full election.  For example, if we have a
training set of size $n = 60,000$, as in MNIST, and choose a
mini-batch size of (say) $m = 10$, this means we'll get a factor of
$6,000$ speedup in estimating the gradient!  Of course, the estimate
won't be perfect - there will be statistical fluctuations - but it
doesn't need to be perfect: all we really care about is moving in a
general direction that will help decrease $C$, and that means we don't
need an exact computation of the gradient.  In practice, stochastic
gradient descent is a commonly used and powerful technique for
learning in neural networks, and it's the basis for most of the
learning techniques we'll develop in this book.</p><p></p><p></p><p></p><p></p><p></p><p><h4><a name="exercise_263792"></a><a href="#exercise_263792">Exercise</a></h4><ul>
<li> An extreme version of gradient descent is to use a mini-batch
  size of just 1.  That is, given a training input, $x$, we update our
  weights and biases according to the rules $w_k \rightarrow w_k' =
  w_k - \eta \partial C_x / \partial w_k$ and $b_l \rightarrow b_l' =
  b_l - \eta \partial C_x / \partial b_l$.  Then we choose another
  training input, and update the weights and biases again.  And so on,
  repeatedly.  This procedure is known as <em>online</em>,
  <em>on-line</em>, or <em>incremental</em> learning.  In online learning,
  a neural network learns from just one training input at a time (just
  as human beings do).  Name one advantage and one disadvantage of
  online learning, compared to stochastic gradient descent with a
  mini-batch size of, say, $20$.
</ul></p><p>Let me conclude this section by discussing a point that sometimes bugs
people new to gradient descent.  In neural networks the cost $C$ is,
of course, a function of many variables - all the weights and biases
- and so in some sense defines a surface in a very high-dimensional
space.  Some people get hung up thinking: "Hey, I have to be able to
visualize all these extra dimensions".  And they may start to worry:
"I can't think in four dimensions, let alone five (or five
million)".  Is there some special ability they're missing, some
ability that "real" supermathematicians have?  Of course, the answer
is no.  Even most professional mathematicians can't visualize four
dimensions especially well, if at all.  The trick they use, instead,
is to develop other ways of representing what's going on.  That's
exactly what we did above: we used an algebraic (rather than visual)
representation of $\Delta C$ to figure out how to move so as to
decrease $C$.  People who are good at thinking in high dimensions have
a mental library containing many different techniques along these
lines; our algebraic trick is just one example.  Those techniques may
not have the simplicity we're accustomed to when visualizing three
dimensions, but once you build up a library of such techniques, you
can get pretty good at thinking in high dimensions.  I won't go into
more detail here, but if you're interested then you may enjoy reading
<a href="http://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking">this
  discussion</a> of some of the techniques professional mathematicians
use to think in high dimensions.  While some of the techniques
discussed are quite complex, much of the best content is intuitive and
accessible, and could be mastered by anyone.</p><p></p><p>
<h3><a name="implementing_our_network_to_classify_digits"></a><a href="#implementing_our_network_to_classify_digits">Implementing our network to classify digits</a></h3></p><p>Alright, let's write a program that learns how to recognize
handwritten digits, using stochastic gradient descent and the MNIST
training data.  We'll do this with a short Python (2.7) program, just
74 lines of code!  The first thing we need is to get the MNIST data.
If you're a <tt>git</tt> user then you can obtain the data by cloning
the code repository for this book,</p><p><div class="highlight"><pre><span></span>git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git
</pre></div>
</p><p>If you don't use <tt>git</tt> then you can download the data and code
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip">here</a>.</p><p>Incidentally, when I described the MNIST data earlier, I said it was
split into 60,000 training images, and 10,000 test images.  That's the
official MNIST description.  Actually, we're going to split the data a
little differently.  We'll leave the test images as is, but split the
60,000-image MNIST training set into two parts: a set of 50,000
images, which we'll use to train our neural network, and a separate
10,000 image <em>validation set</em>.  We won't
use the validation data in this chapter, but later in the book we'll
find it useful in figuring out how to set certain
<em>hyper-parameters</em> of the neural network - things like the
learning rate, and so on, which aren't directly selected by our
learning algorithm.  Although the validation data isn't part of the
original MNIST specification, many people use MNIST in this fashion,
and the use of validation data is common in neural networks.  When I
refer to the "MNIST training data" from now on, I'll be referring to
our 50,000 image data set, not the original 60,000 image data
set*<span class="marginnote">
*As noted earlier, the MNIST data set is based on two data
  sets collected by NIST, the United States' National Institute of
  Standards and Technology.  To construct MNIST the NIST data sets
  were stripped down and put into a more convenient format by Yann
  LeCun, Corinna Cortes, and Christopher J. C. Burges.  See
  <a href="http://yann.lecun.com/exdb/mnist/">this link</a> for more
  details.  The data set in my repository is in a form that makes it
  easy to load and manipulate the MNIST data in Python.  I obtained
  this particular form of the data from the LISA machine learning
  laboratory at the University of Montreal
  (<a href="http://www.deeplearning.net/tutorial/gettingstarted.html">link</a>).</span>.</p><p></p><p>Apart from the MNIST data we also need a Python library called
<a href="http://numpy.org">Numpy</a>, for doing fast linear algebra.  If you
don't already have Numpy installed, you can get it
<a href="http://www.scipy.org/install.html">here</a>.</p><p>Let me explain the core features of the neural networks code, before
giving a full listing, below.  The centerpiece is a <tt>Network</tt>
class, which we use to represent a neural network.  Here's the code we
use to initialize a <tt>Network</tt> object:</p><p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> 
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
</pre></div>
</p><p>In this code, the list <tt>sizes</tt> contains the number of neurons in
the respective layers.  So, for example, if we want to create a
<tt>Network</tt> object with 2 neurons in the first layer, 3 neurons in
the second layer, and 1 neuron in the final layer, we'd do this with
the code:
<div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

<a name="weight_initialization"></a> The biases
and weights in the <tt>Network</tt> object are all initialized randomly,
using the Numpy <tt>np.random.randn</tt> function to generate Gaussian
distributions with mean $0$ and standard deviation $1$.  This random
initialization gives our stochastic gradient descent algorithm a place
to start from.  In later chapters we'll find better ways of
initializing the weights and biases, but this will do for now.  Note
that the <tt>Network</tt> initialization code assumes that the first
layer of neurons is an input layer, and omits to set any biases for
those neurons, since biases are only ever used in computing the
outputs from later layers.</p><p>Note also that the biases and weights are stored as lists of Numpy
matrices.  So, for example <tt>net.weights[1]</tt> is a Numpy matrix
storing the weights connecting the second and third layers of neurons.
(It's not the first and second layers, since Python's list indexing
starts at <tt>0</tt>.)  Since <tt>net.weights[1]</tt> is rather verbose,
let's just denote that matrix $w$.  It's a matrix such that $w_{jk}$
is the weight for the connection between the $k^{\rm th}$ neuron in the
second layer, and the $j^{\rm th}$ neuron in the third layer.  This ordering
of the $j$ and $k$ indices may seem strange - surely it'd make more
sense to swap the $j$ and $k$ indices around?  The big advantage of
using this ordering is that it means that the vector of activations of
the third layer of neurons is:
<a class="displaced_anchor" name="eqtn22"></a>\begin{eqnarray} 
  a' = \sigma(w a + b).
\tag{22}\end{eqnarray}
There's quite a bit going on in this equation, so let's unpack it
piece by piece.  $a$ is the vector of activations of the second layer
of neurons. To obtain $a'$ we multiply $a$ by the weight matrix $w$,
and add the vector $b$ of biases.  We then apply the function $\sigma$
elementwise to every entry in the vector $w a +b$.  (This is called
<em>vectorizing</em> the function
$\sigma$.) It's easy to verify that
Equation <span id="margin_469346701810_reveal" class="equation_link">(22)</span><span id="margin_469346701810" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_469346701810_reveal').click(function() {$('#margin_469346701810').toggle('slow', function() {});});</script> gives the same result as our
earlier rule, Equation <span id="margin_803037168757_reveal" class="equation_link">(4)</span><span id="margin_803037168757" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_803037168757_reveal').click(function() {$('#margin_803037168757').toggle('slow', function() {});});</script>, for
computing the output of a sigmoid neuron.</p><p><h4><a name="exercise_717502"></a><a href="#exercise_717502">Exercise</a></h4><ul>
<li> Write out Equation <span id="margin_585248828587_reveal" class="equation_link">(22)</span><span id="margin_585248828587" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_585248828587_reveal').click(function() {$('#margin_585248828587').toggle('slow', function() {});});</script> in component
  form, and verify that it gives the same result as the
  rule <span id="margin_208193369319_reveal" class="equation_link">(4)</span><span id="margin_208193369319" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_208193369319_reveal').click(function() {$('#margin_208193369319').toggle('slow', function() {});});</script> for computing the output
  of a sigmoid neuron.
</ul></p><p>With all this in mind, it's easy to write code computing the output
from a <tt>Network</tt> instance.  We begin by defining the sigmoid
function:
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>

Note that when the input <tt>z</tt> is a vector or Numpy array, Numpy
automatically applies the function <tt>sigmoid</tt> elementwise, that
is, in vectorized form.</p><p>We then add a <tt>feedforward</tt> method to the <tt>Network</tt> class,
which, given an input <tt>a</tt> for the network, returns the
corresponding output*<span class="marginnote">
*It is assumed that the input <tt>a</tt> is
  an <tt>(n, 1)</tt> Numpy ndarray, not a <tt>(n,)</tt> vector.  Here,
  <tt>n</tt> is the number of inputs to the network.  If you try to use
  an <tt>(n,)</tt> vector as input you'll get strange results.  Although
  using an <tt>(n,)</tt> vector appears the more natural choice, using
  an <tt>(n, 1)</tt> ndarray makes it particularly easy to modify the
  code to feedforward multiple inputs at once, and that is sometimes
  convenient. </span>.  All the method does is applies
Equation <span id="margin_436898280460_reveal" class="equation_link">(22)</span><span id="margin_436898280460" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_436898280460_reveal').click(function() {$('#margin_436898280460').toggle('slow', function() {});});</script> for each layer:
<div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if &quot;a&quot; is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>
</pre></div>
</p><p>Of course, the main thing we want our <tt>Network</tt> objects to do is
to learn.  To that end we'll give them an <tt>SGD</tt> method which
implements stochastic gradient descent.  Here's the code.  It's a
little mysterious in a few places, but I'll break it down below, after
the listing.</p><p><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The &quot;training_data&quot; is a list of tuples</span>
<span class="sd">        &quot;(x, y)&quot; representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If &quot;test_data&quot; is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
</pre></div>
</p><p>The <tt>training_data</tt> is a list of tuples <tt>(x, y)</tt>
representing the training inputs and corresponding desired outputs.
The variables <tt>epochs</tt> and <tt>mini_batch_size</tt> are what you'd
expect - the number of epochs to train for, and the size of the
mini-batches to use when sampling.  <tt>eta</tt> is the learning rate,
$\eta$.  If the optional argument <tt>test_data</tt> is supplied, then
the program will evaluate the network after each epoch of training,
and print out partial progress.  This is useful for tracking progress,
but slows things down substantially.</p><p>The code works as follows.  In each epoch, it starts by randomly
shuffling the training data, and then partitions it into mini-batches
of the appropriate size.  This is an easy way of sampling randomly
from the training data.  Then for each <tt>mini_batch</tt> we apply a
single step of gradient descent.  This is done by the code
<tt>self.update_mini_batch(mini_batch, eta)</tt>, which updates the
network weights and biases according to a single iteration of gradient
descent, using just the training data in <tt>mini_batch</tt>.  Here's
the code for the <tt>update_mini_batch</tt> method:
<div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The &quot;mini_batch&quot; is a list of tuples &quot;(x, y)&quot;, and &quot;eta&quot;</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span> 
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span> 
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>
</pre></div>

Most of the work is done by the line
<div class="highlight"><pre><span></span>            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

This invokes something called the <em>backpropagation</em> algorithm,
which is a fast way of computing the gradient of the cost function.
So <tt>update_mini_batch</tt> works simply by computing these gradients
for every training example in the <tt>mini_batch</tt>, and then updating
<tt>self.weights</tt> and <tt>self.biases</tt> appropriately.</p><p>I'm not going to show the code for <tt>self.backprop</tt> right now.
We'll study how backpropagation works in the next chapter, including
the code for <tt>self.backprop</tt>.  For now, just assume that it
behaves as claimed, returning the appropriate gradient for the cost
associated to the training example <tt>x</tt>.</p><p>Let's look at the full program, including the documentation strings,
which I omitted above.  Apart from <tt>self.backprop</tt> the program is
self-explanatory - all the heavy lifting is done in <tt>self.SGD</tt>
and <tt>self.update_mini_batch</tt>, which we've already discussed.  The
<tt>self.backprop</tt> method makes use of a few extra functions to help
in computing the gradient, namely <tt>sigmoid_prime</tt>, which computes
the derivative of the $\sigma$ function, and
<tt>self.cost_derivative</tt>, which I won't describe here.  You can get
the gist of these (and perhaps the details) just by looking at the
code and documentation strings.  We'll look at them in detail in the
next chapter. 
Note that while the program appears lengthy, much of the code is
documentation strings intended to make the code easy to understand.
In fact, the program contains just 74 lines of non-whitespace,
non-comment code.  All the code may be found on GitHub
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py">here</a>.</p><p></p><p><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">network.py</span>
<span class="sd">~~~~~~~~~~</span>

<span class="sd">A module to implement the stochastic gradient descent learning</span>
<span class="sd">algorithm for a feedforward neural network.  Gradients are calculated</span>
<span class="sd">using backpropagation.  Note that I have focused on making the code</span>
<span class="sd">simple, easily readable, and easily modifiable.  It is not optimized,</span>
<span class="sd">and omits many desirable features.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">#### Libraries</span>
<span class="c1"># Standard library</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The list ``sizes`` contains the number of neurons in the</span>
<span class="sd">        respective layers of the network.  For example, if the list</span>
<span class="sd">        was [2, 3, 1] then it would be a three-layer network, with the</span>
<span class="sd">        first layer containing 2 neurons, the second layer 3 neurons,</span>
<span class="sd">        and the third layer 1 neuron.  The biases and weights for the</span>
<span class="sd">        network are initialized randomly, using a Gaussian</span>
<span class="sd">        distribution with mean 0, and variance 1.  Note that the first</span>
<span class="sd">        layer is assumed to be an input layer, and by convention we</span>
<span class="sd">        won&#39;t set any biases for those neurons, since biases are only</span>
<span class="sd">        ever used in computing the outputs from later layers.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>

    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if ``a`` is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>

    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The ``training_data`` is a list of tuples</span>
<span class="sd">        ``(x, y)`` representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If ``test_data`` is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a tuple ``(nabla_b, nabla_w)`` representing the</span>
<span class="sd">        gradient for the cost function C_x.  ``nabla_b`` and</span>
<span class="sd">        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar</span>
<span class="sd">        to ``self.biases`` and ``self.weights``.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="c1"># feedforward</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="c1"># list to store all the activations, layer by layer</span>
        <span class="n">zs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list to store all the z vectors, layer by layer</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
            <span class="n">zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="c1"># backward pass</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_derivative</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> \
            <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="c1"># Note that the variable l in the loop below is used a little</span>
        <span class="c1"># differently to the notation in Chapter 2 of the book.  Here,</span>
        <span class="c1"># l = 1 means the last layer of neurons, l = 2 is the</span>
        <span class="c1"># second-last layer, and so on.  It&#39;s a renumbering of the</span>
        <span class="c1"># scheme in the book, used here to take advantage of the fact</span>
        <span class="c1"># that Python can use negative indices in lists.</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span>
            <span class="n">sp</span> <span class="o">=</span> <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">sp</span>
            <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
            <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the number of test inputs for which the neural</span>
<span class="sd">        network outputs the correct result. Note that the neural</span>
<span class="sd">        network&#39;s output is assumed to be the index of whichever</span>
<span class="sd">        neuron in the final layer has the highest activation.&quot;&quot;&quot;</span>
        <span class="n">test_results</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">y</span><span class="p">)</span>
                        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cost_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_activations</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the vector of partial derivatives \partial C_x /</span>
<span class="sd">        \partial a for the output activations.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">output_activations</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>

<span class="c1">#### Miscellaneous functions</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Derivative of the sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</p><p>How well does the program recognize handwritten digits?  Well, let's
start by loading in the MNIST data.  I'll do this using a little
helper program, <tt>mnist_loader.py</tt>, to be described below.  We
execute the following commands in a Python shell,</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">mnist_loader</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> \
<span class="o">...</span> <span class="n">mnist_loader</span><span class="o">.</span><span class="n">load_data_wrapper</span><span class="p">()</span>
</pre></div>
</p><p>Of course, this could also be done in a separate Python program, but
if you're following along it's probably easiest to do in a Python
shell.  </p><p>After loading the MNIST data, we'll set up a <tt>Network</tt> with $30$
hidden neurons.  We do this after importing the Python program listed
above, which is named <tt>network</tt>,</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">network</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</p><p>Finally, we'll use stochastic gradient descent to learn from the MNIST
<tt>training_data</tt> over 30 epochs, with a mini-batch size of 10, and a
learning rate of $\eta = 3.0$, </p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Note that if you're running the code as you read along, it will take
some time to execute - for a typical machine (as of 2015) it will
likely take a few minutes to run.  I suggest you set things running,
continue to read, and periodically check the output from the code.  If
you're in a rush you can speed things up by decreasing the number of
epochs, by decreasing the number of hidden neurons, or by using only
part of the training data.  Note that production code would be much,
much faster: these Python scripts are intended to help you understand
how neural nets work, not to be high-performance code!  And, of
course, once we've trained a network it can be run very quickly
indeed, on almost any computing platform. For example, once we've
learned a good set of weights and biases for a network, it can easily
be ported to run in Javascript in a web browser, or as a native app on
a mobile device.  In any case, here is a partial transcript of the
output of one training run of the neural network.  The transcript
shows the number of test images correctly recognized by the neural
network after each epoch of training.  As you can see, after just a
single epoch this has reached 9,129 out of 10,000, and the number
continues to grow,</p><p><div class="highlight"><pre><span></span>Epoch 0: 9129 / 10000
Epoch 1: 9295 / 10000
Epoch 2: 9348 / 10000
...
Epoch 27: 9528 / 10000
Epoch 28: 9542 / 10000
Epoch 29: 9534 / 10000
</pre></div>
</p><p>That is, the trained network gives us a classification rate of about
$95$ percent - $95.42$ percent at its peak ("Epoch 28")!  That's
quite encouraging as a first attempt.  I should warn you, however,
that if you run the code then your results are not necessarily going
to be quite the same as mine, since we'll be initializing our network
using (different) random weights and biases.  To generate results in
this chapter I've taken best-of-three runs.</p><p>Let's rerun the above experiment, changing the number of hidden
neurons to $100$.  As was the case earlier, if you're running the code
as you read along, you should be warned that it takes quite a while to
execute (on my machine this experiment takes tens of seconds for each
training epoch), so it's wise to continue reading in parallel while
the code executes.</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Sure enough, this improves the results to $96.59$ percent.  At least
in this case, using more hidden neurons helps us get better
results*<span class="marginnote">
*Reader feedback indicates quite some variation in
  results for this experiment, and some training runs give results
  quite a bit worse.  Using the techniques introduced in chapter 3
  will greatly reduce the variation in performance across different
  training runs for our networks.</span>.</p><p>Of course, to obtain these accuracies I had to make specific choices
for the number of epochs of training, the mini-batch size, and the
learning rate, $\eta$.  As I mentioned above, these are known as
hyper-parameters for our neural network, in order to distinguish them
from the parameters (weights and biases) learnt by our learning
algorithm.  If we choose our hyper-parameters poorly, we can get bad
results.  Suppose, for example, that we'd chosen the learning rate to
be $\eta = 0.001$,</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>The results are much less encouraging,
<div class="highlight"><pre><span></span>Epoch 0: 1139 / 10000
Epoch 1: 1136 / 10000
Epoch 2: 1135 / 10000
...
Epoch 27: 2101 / 10000
Epoch 28: 2123 / 10000
Epoch 29: 2142 / 10000
</pre></div>

However, you can see that the performance of the network is getting
slowly better over time.  That suggests increasing the learning rate,
say to $\eta = 0.01$.  If we do that, we get better results, which
suggests increasing the learning rate again.  (If making a change
improves things, try doing more!)  If we do that several times over,
we'll end up with a learning rate of something like $\eta = 1.0$ (and
perhaps fine tune to $3.0$), which is close to our earlier
experiments.  So even though we initially made a poor choice of
hyper-parameters, we at least got enough information to help us
improve our choice of hyper-parameters.</p><p>In general, debugging a neural network can be challenging.  This is
especially true when the initial choice of hyper-parameters produces
results no better than random noise.  Suppose we try the successful 30
hidden neuron network architecture from earlier, but with the learning
rate changed to $\eta = 100.0$:
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>

At this point we've actually gone too far, and the learning rate is
too high:
<div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="o">...</span>
<span class="n">Epoch</span> <span class="mi">27</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">28</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">29</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
</pre></div>

Now imagine that we were coming to this problem for the first time.
Of course, we <em>know</em> from our earlier experiments that the right
thing to do is to decrease the learning rate.  But if we were coming
to this problem for the first time then there wouldn't be much in the
output to guide us on what to do.  We might worry not only about the
learning rate, but about every other aspect of our neural network.  We
might wonder if we've initialized the weights and biases in a way that
makes it hard for the network to learn?  Or maybe we don't have enough
training data to get meaningful learning?  Perhaps we haven't run for
enough epochs?  Or maybe it's impossible for a neural network with
this architecture to learn to recognize handwritten digits?  Maybe the
learning rate is too <em>low</em>?  Or, maybe, the learning rate is too
high?  When you're coming to a problem for the first time, you're not
always sure.</p><p>The lesson to take away from this is that debugging a neural network
is not trivial, and, just as for ordinary programming, there is an art
to it.  You need to learn that art of debugging in order to get good
results from neural networks.  More generally, we need to develop
heuristics for choosing good hyper-parameters and a good architecture.
We'll discuss all these at length through the book, including how I
chose the hyper-parameters above.</p><p>
<h4><a name="exercise_420023"></a><a href="#exercise_420023">Exercise</a></h4><ul></p><p><li> Try creating a network with just two layers - an input and an
  output layer, no hidden layer - with 784 and 10 neurons,
  respectively.  Train the network using stochastic gradient descent.
  What classification accuracy can you achieve?
</ul></p><p></p><p>Earlier, I skipped over the details of how the MNIST data is loaded.
It's pretty straightforward.  For completeness, here's the code.  The
data structures used to store the MNIST data are described in the
documentation strings - it's straightforward stuff, tuples and lists
of Numpy <tt>ndarray</tt> objects (think of them as vectors if you're
not familiar with <tt>ndarray</tt>s):</p><p><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">mnist_loader</span>
<span class="sd">~~~~~~~~~~~~</span>

<span class="sd">A library to load the MNIST image data.  For details of the data</span>
<span class="sd">structures that are returned, see the doc strings for ``load_data``</span>
<span class="sd">and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the</span>
<span class="sd">function usually called by our neural network code.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">#### Libraries</span>
<span class="c1"># Standard library</span>
<span class="kn">import</span> <span class="nn">cPickle</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="c1"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,</span>
<span class="sd">    the validation data, and the test data.</span>

<span class="sd">    The ``training_data`` is returned as a tuple with two entries.</span>
<span class="sd">    The first entry contains the actual training images.  This is a</span>
<span class="sd">    numpy ndarray with 50,000 entries.  Each entry is, in turn, a</span>
<span class="sd">    numpy ndarray with 784 values, representing the 28 * 28 = 784</span>
<span class="sd">    pixels in a single MNIST image.</span>

<span class="sd">    The second entry in the ``training_data`` tuple is a numpy ndarray</span>
<span class="sd">    containing 50,000 entries.  Those entries are just the digit</span>
<span class="sd">    values (0...9) for the corresponding images contained in the first</span>
<span class="sd">    entry of the tuple.</span>

<span class="sd">    The ``validation_data`` and ``test_data`` are similar, except</span>
<span class="sd">    each contains only 10,000 images.</span>

<span class="sd">    This is a nice data format, but for use in neural networks it&#39;s</span>
<span class="sd">    helpful to modify the format of the ``training_data`` a little.</span>
<span class="sd">    That&#39;s done in the wrapper function ``load_data_wrapper()``, see</span>
<span class="sd">    below.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;../data/mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,</span>
<span class="sd">    test_data)``. Based on ``load_data``, but the format is more</span>
<span class="sd">    convenient for use in our implementation of neural networks.</span>

<span class="sd">    In particular, ``training_data`` is a list containing 50,000</span>
<span class="sd">    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray</span>
<span class="sd">    containing the input image.  ``y`` is a 10-dimensional</span>
<span class="sd">    numpy.ndarray representing the unit vector corresponding to the</span>
<span class="sd">    correct digit for ``x``.</span>

<span class="sd">    ``validation_data`` and ``test_data`` are lists containing 10,000</span>
<span class="sd">    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional</span>
<span class="sd">    numpy.ndarry containing the input image, and ``y`` is the</span>
<span class="sd">    corresponding classification, i.e., the digit values (integers)</span>
<span class="sd">    corresponding to ``x``.</span>

<span class="sd">    Obviously, this means we&#39;re using slightly different formats for</span>
<span class="sd">    the training data and the validation / test data.  These formats</span>
<span class="sd">    turn out to be the most convenient for use in our neural network</span>
<span class="sd">    code.&quot;&quot;&quot;</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>
    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth</span>
<span class="sd">    position and zeroes elsewhere.  This is used to convert a digit</span>
<span class="sd">    (0...9) into a corresponding desired output from the neural</span>
<span class="sd">    network.&quot;&quot;&quot;</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>
</pre></div>
</p><p>I said above that our program gets pretty good results.  What does
that mean?  Good compared to what?  It's informative to have some
simple (non-neural-network) baseline tests to compare against, to
understand what it means to perform well.  The simplest baseline of
all, of course, is to randomly guess the digit.  That'll be right
about ten percent of the time.  We're doing much better than that!</p><p>What about a less trivial baseline?  Let's try an extremely simple
idea: we'll look at how <em>dark</em> an image is.  For instance, an
image of a $2$ will typically be quite a bit darker than an image of a
$1$, just because more pixels are blackened out, as the following
examples illustrate:</p><p><center><img src="images/mnist_2_and_1.png" width="256px"></center></p><p>This suggests using the training data to compute average darknesses
for each digit, $0, 1, 2,\ldots, 9$.  When presented with a new image,
we compute how dark the image is, and then guess that it's whichever
digit has the closest average darkness.  This is a simple procedure,
and is easy to code up, so I won't explicitly write out the code -
if you're interested it's in the
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py">GitHub
  repository</a>.  But it's a big improvement over random guessing,
getting $2,225$ of the $10,000$ test images correct, i.e., $22.25$
percent accuracy.</p><p><a name="SVM"></a></p><p>It's not difficult to find other ideas which achieve accuracies in the
$20$ to $50$ percent range.  If you work a bit harder you can get up
over $50$ percent.  But to get much higher accuracies it helps to use
established machine learning algorithms.  Let's try using one of the
best known algorithms, the <em>support vector
  machine</em>
or <em>SVM</em>.  If you're not
familiar with SVMs, not to worry, we're not going to need to
understand the details of how SVMs work.  Instead, we'll use a Python
library called
<a href="http://scikit-learn.org/stable/">scikit-learn</a>,
which provides a simple Python interface to a fast C-based library for
SVMs known as
<a href="http://www.csie.ntu.edu.tw/&#126;cjlin/libsvm/">LIBSVM</a>.</p><p>If we run scikit-learn's SVM classifier using the default settings,
then it gets 9,435 of 10,000 test images correct.  (The code is
available
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py">here</a>.)
That's a big improvement over our naive approach of classifying an
image based on how dark it is.  Indeed, it means that the SVM is
performing roughly as well as our neural networks, just a little
worse.  In later chapters we'll introduce new techniques that enable
us to improve our neural networks so that they perform much better
than the SVM.</p><p>That's not the end of the story, however.  The 9,435 of 10,000 result
is for scikit-learn's default settings for SVMs.  SVMs have a number
of tunable parameters, and it's possible to search for parameters
which improve this out-of-the-box performance.  I won't explicitly do
this search, but instead refer you to
<a href="http://peekaboo-vision.blogspot.de/2010/09/mnist-for-ever.html">this
  blog post</a> by <a href="http://peekaboo-vision.blogspot.ca/">Andreas
  Mueller</a> if you'd like to know more.  Mueller shows that with some
work optimizing the SVM's parameters it's possible to get the
performance up above 98.5 percent accuracy.  In other words, a
well-tuned SVM only makes an error on about one digit in 70.  That's
pretty good!  Can neural networks do better?</p><p>In fact, they can.  At present, well-designed neural networks
outperform every other technique for solving MNIST, including SVMs.
The current (2013) record is classifying 9,979 of 10,000 images
correctly.  This was done by <a href="http://www.cs.nyu.edu/&#126;wanli/">Li
  Wan</a>, <a href="http://www.matthewzeiler.com/">Matthew Zeiler</a>, Sixin
Zhang, <a href="http://yann.lecun.com/">Yann LeCun</a>, and
<a href="http://cs.nyu.edu/&#126;fergus/pmwiki/pmwiki.php">Rob Fergus</a>.
We'll see most of the techniques they used later in the book.  At that
level the performance is close to human-equivalent, and is arguably
better, since quite a few of the MNIST images are difficult even for
humans to recognize with confidence, for example:</p><p><center><img src="images/mnist_really_bad_images.png" width="560px"></center></p><p>I trust you'll agree that those are tough to classify!  With images
like these in the MNIST data set it's remarkable that neural networks
can accurately classify all but 21 of the 10,000 test images.
Usually, when programming we believe that solving a complicated
problem like recognizing the MNIST digits requires a sophisticated
algorithm.  But even the neural networks in the Wan <em>et al</em> paper
just mentioned involve quite simple algorithms, variations on the
algorithm we've seen in this chapter.  All the complexity is learned,
automatically, from the training data. In some sense, the moral of
both our results and those in more sophisticated papers, is that for
some problems:
<center>
  sophisticated algorithm $\leq$ simple learning algorithm + good
  training data.
</center></p><p><h3><a name="toward_deep_learning"></a><a href="#toward_deep_learning">Toward deep learning</a></h3></p><p>While our neural network gives impressive performance, that
performance is somewhat mysterious.  The weights and biases in the
network were discovered automatically.  And that means we don't
immediately have an explanation of how the network does what it does.
Can we find some way to understand the principles by which our network
is classifying handwritten digits?  And, given such principles, can we
do better?</p><p>To put these questions more starkly, suppose that a few decades hence
neural networks lead to artificial intelligence (AI).  Will we
understand how such intelligent networks work?  Perhaps the networks
will be opaque to us, with weights and biases we don't understand,
because they've been learned automatically.  In the early days of AI
research people hoped that the effort to build an AI would also help
us understand the principles behind intelligence and, maybe, the
functioning of the human brain.  But perhaps the outcome will be that
we end up understanding neither the brain nor how artificial
intelligence works!</p><p>To address these questions, let's think back to the interpretation of
artificial neurons that I gave at the start of the chapter, as a means
of weighing evidence.  Suppose we want to determine whether an image
shows a human face or not:</p><p> </p><p>  <span class="marginnote">Credits: 1. <a
  href="http://commons.wikimedia.org/wiki/User:ST">Ester Inbar</a>. 2.
  Unknown. 3. NASA, ESA, G. Illingworth, D. Magee, and P. Oesch
  (University of California, Santa Cruz), R. Bouwens (Leiden
  University), and the HUDF09 Team.  Click on the images for more
  details.</span></p><p>  <a
  href="http://commons.wikimedia.org/wiki/File:Kangaroo_ST_03.JPG"><img
  src="images/Kangaroo.JPG" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:Albert_Einstein_at_the_age_of_three_(1882).jpg"><img
  src="images/Einstein_crop.jpg" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:The_Hubble_eXtreme_Deep_Field.jpg"><img
  src="images/hubble.jpg" height="190px"/></a> </p><p>We could attack this problem the same way we attacked handwriting
recognition - by using the pixels in the image as input to a neural
network, with the output from the network a single neuron indicating
either "Yes, it's a face" or "No, it's not a face".</p><p>Let's suppose we do this, but that we're not using a learning
algorithm.  Instead, we're going to try to design a network by hand,
choosing appropriate weights and biases.  How might we go about it?
Forgetting neural networks entirely for the moment, a heuristic we
could use is to decompose the problem into sub-problems: does the
image have an eye in the top left?  Does it have an eye in the top
right?  Does it have a nose in the middle?  Does it have a mouth in
the bottom middle?  Is there hair on top?  And so on.</p><p>If the answers to several of these questions are "yes", or even just
"probably yes", then we'd conclude that the image is likely to be a
face.  Conversely, if the answers to most of the questions are "no",
then the image probably isn't a face.</p><p>Of course, this is just a rough heuristic, and it suffers from many
deficiencies.  Maybe the person is bald, so they have no hair.  Maybe
we can only see part of the face, or the face is at an angle, so some
of the facial features are obscured.  Still, the heuristic suggests
that if we can solve the sub-problems using neural networks, then
perhaps we can build a neural network for face-detection, by combining
the networks for the sub-problems.  Here's a possible architecture,
with rectangles denoting the sub-networks.  Note that this isn't
intended as a realistic approach to solving the face-detection
problem; rather, it's to help us build intuition about how networks
function.  Here's the architecture:</p><p><center>
<img src="images/tikz14.png"/>
</center></p><p>It's also plausible that the sub-networks can be decomposed.  Suppose
we're considering the question: "Is there an eye in the top left?"
This can be decomposed into questions such as: "Is there an
eyebrow?"; "Are there eyelashes?"; "Is there an iris?"; and so
on.  Of course, these questions should really include positional
information, as well - "Is the eyebrow in the top left, and above
the iris?", that kind of thing - but let's keep it simple.  The
network to answer the question "Is there an eye in the top left?"
can now be decomposed:</p><p><center>
<img src="images/tikz15.png"/>
</center></p><p>Those questions too can be broken down, further and further through
multiple layers.  Ultimately, we'll be working with sub-networks that
answer questions so simple they can easily be answered at the level of
single pixels.  Those questions might, for example, be about the
presence or absence of very simple shapes at particular points in the
image.  Such questions can be answered by single neurons connected to
the raw pixels in the image.</p><p>The end result is a network which breaks down a very complicated
question - does this image show a face or not - into very simple
questions answerable at the level of single pixels.  It does this
through a series of many layers, with early layers answering very
simple and specific questions about the input image, and later layers
building up a hierarchy of ever more complex and abstract concepts.
Networks with this kind of many-layer structure - two or more hidden
layers - are called <em>deep neural networks</em>.</p><p></p><p></p><p>
Of course, I haven't said how to do this recursive decomposition into
sub-networks.  It certainly isn't practical to hand-design the weights
and biases in the network.  Instead, we'd like to use learning
algorithms so that the network can automatically learn the weights and
biases - and thus, the hierarchy of concepts - from training data.
Researchers in the 1980s and 1990s tried using stochastic gradient
descent and backpropagation to train deep networks.  Unfortunately,
except for a few special architectures, they didn't have much luck.
The networks would learn, but very slowly, and in practice often too
slowly to be useful.</p><p>Since 2006, a set of techniques has been developed that enable
learning in deep neural nets.  These deep learning techniques are
based on stochastic gradient descent and backpropagation, but also
introduce new ideas.  These techniques have enabled much deeper (and
larger) networks to be trained - people now routinely train networks
with 5 to 10 hidden layers.  And, it turns out that these perform far
better on many problems than shallow neural networks, i.e., networks
with just a single hidden layer.  The reason, of course, is the
ability of deep nets to build up a complex hierarchy of concepts.
It's a bit like the way conventional programming languages use modular
design and ideas about abstraction to enable the creation of complex
computer programs.  Comparing a deep network to a shallow network is a
bit like comparing a programming language with the ability to make
function calls to a stripped down language with no ability to make
such calls.  Abstraction takes a different form in neural networks
than it does in conventional programming, but it's just as important.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>
</div><div class="footer"> <span class="left_footer"> In academic work,
please cite this book as: Michael A. Nielsen, "Neural Networks and
Deep Learning", Determination Press, 2015

<br/>
<br/>

This work is licensed under a <a rel="license"
href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"
style="color: #eee;">Creative Commons Attribution-NonCommercial 3.0
Unported License</a>.  This means you're free to copy, share, and
build on this book, but not to sell it.  If you're interested in
commercial use, please <a
href="mailto:mn@michaelnielsen.org">contact me</a>.
</span>
<span class="right_footer">
Last update: Thu Dec 26 15:26:33 2019
<br/>
<br/>
<br/>
<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"><img alt="Creative Commons Licence" style="border-width:0" src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a>
</span>
</div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44208967-1', 'neuralnetworksanddeeplearning.com');
  ga('send', 'pageview');

</script>
</body>
</html>