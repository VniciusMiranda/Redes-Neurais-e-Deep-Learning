<!DOCTYPE html>
<html lang="en">
<!-- Produced from a LaTeX source file.  Note that the production is done -->
<!-- by a very rough-and-ready (and buggy) script, so the HTML and other  -->
<!-- code is quite ugly!  Later versions should be better.                -->
<head>
    <meta charset="utf-8">
    <meta name="citation_title" content="Neural Networks and Deep Learning">
    <meta name="citation_author" content="Nielsen, Michael A.">
    <meta name="citation_publication_date" content="2015">
    <meta name="citation_fulltext_html_url" content="http://neuralnetworksanddeeplearning.com">
    <meta name="citation_publisher" content="Determination Press">
    <meta name="citation_fulltext_world_readable" content="">
    <link rel="icon" href="nnadl_favicon.ICO" />
    <title>Neural networks and deep learning</title>
    <script src="assets/jquery.min.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$']]},
        "HTML-CSS": 
          {scale: 92},
        TeX: { equationNumbers: { autoNumber: "AMS" }}});
    </script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>


    <link href="assets/style.css" rel="stylesheet">
    <link href="assets/pygments.css" rel="stylesheet">
    <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.2/themes/smoothness/jquery-ui.css">

<style>
/* Adapted from */
/* https://groups.google.com/d/msg/mathjax-users/jqQxrmeG48o/oAaivLgLN90J, */
/* by David Cervone */

@font-face {
    font-family: 'MJX_Math';
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); /* IE9 Compat Modes */
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot?iefix') format('eot'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff')  format('woff'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf')  format('opentype'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/svg/MathJax_Math-Italic.svg#MathJax_Math-Italic') format('svg');
}

@font-face {
    font-family: 'MJX_Main';
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); /* IE9 Compat Modes */
    src: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot?iefix') format('eot'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff')  format('woff'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf')  format('opentype'),
    url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/fonts/HTML-CSS/TeX/svg/MathJax_Main-Regular.svg#MathJax_Main-Regular') format('svg');
}
</style>

  </head>
  <body>
    <div class="header">
      <h1 class="chapter_number">
        <a href="">Capítulo 1</a>
      </h1>
  <h1 class="chapter_title">
    <a href="">Usando redes neurais para reconhecer digitos manuscritos</a></h1></div><div class="section"><div id="toc"> 
<p class="toc_title"><a href="index.html">Neural Networks and Deep Learning</a></p><p class="toc_not_mainchapter"><a href="about.html">What this book is about</a></p><p class="toc_not_mainchapter"><a href="exercises_and_problems.html">On the exercises and problems</a></p><p class='toc_mainchapter'><a id="toc_using_neural_nets_to_recognize_handwritten_digits_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_using_neural_nets_to_recognize_handwritten_digits" src="images/arrow.png" width="15px"></a><a href="chap1.html">Using neural nets to recognize handwritten digits</a><div id="toc_using_neural_nets_to_recognize_handwritten_digits" style="display: none;"><p class="toc_section"><ul><a href="chap1.html#perceptrons"><li>Perceptrons</li></a><a href="chap1.html#sigmoid_neurons"><li>Sigmoid neurons</li></a><a href="chap1.html#the_architecture_of_neural_networks"><li>The architecture of neural networks</li></a><a href="chap1.html#a_simple_network_to_classify_handwritten_digits"><li>A simple network to classify handwritten digits</li></a><a href="chap1.html#learning_with_gradient_descent"><li>Learning with gradient descent</li></a><a href="chap1.html#implementing_our_network_to_classify_digits"><li>Implementing our network to classify digits</li></a><a href="chap1.html#toward_deep_learning"><li>Toward deep learning</li></a></ul></p></div>
<script>
$('#toc_using_neural_nets_to_recognize_handwritten_digits_reveal').click(function() { 
   var src = $('#toc_img_using_neural_nets_to_recognize_handwritten_digits').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_using_neural_nets_to_recognize_handwritten_digits").attr('src', 'images/arrow.png');
   };
   $('#toc_using_neural_nets_to_recognize_handwritten_digits').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_how_the_backpropagation_algorithm_works_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_how_the_backpropagation_algorithm_works" src="images/arrow.png" width="15px"></a><a href="chap2.html">How the backpropagation algorithm works</a><div id="toc_how_the_backpropagation_algorithm_works" style="display: none;"><p class="toc_section"><ul><a href="chap2.html#warm_up_a_fast_matrix-based_approach_to_computing_the_output
_from_a_neural_network"><li>Warm up: a fast matrix-based approach to computing the output
  from a neural network</li></a><a href="chap2.html#the_two_assumptions_we_need_about_the_cost_function"><li>The two assumptions we need about the cost function</li></a><a href="chap2.html#the_hadamard_product_$s_\odot_t$"><li>The Hadamard product, $s \odot t$</li></a><a href="chap2.html#the_four_fundamental_equations_behind_backpropagation"><li>The four fundamental equations behind backpropagation</li></a><a href="chap2.html#proof_of_the_four_fundamental_equations_(optional)"><li>Proof of the four fundamental equations (optional)</li></a><a href="chap2.html#the_backpropagation_algorithm"><li>The backpropagation algorithm</li></a><a href="chap2.html#the_code_for_backpropagation"><li>The code for backpropagation</li></a><a href="chap2.html#in_what_sense_is_backpropagation_a_fast_algorithm"><li>In what sense is backpropagation a fast algorithm?</li></a><a href="chap2.html#backpropagation_the_big_picture"><li>Backpropagation: the big picture</li></a></ul></p></div>
<script>
$('#toc_how_the_backpropagation_algorithm_works_reveal').click(function() { 
   var src = $('#toc_img_how_the_backpropagation_algorithm_works').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_how_the_backpropagation_algorithm_works").attr('src', 'images/arrow.png');
   };
   $('#toc_how_the_backpropagation_algorithm_works').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_improving_the_way_neural_networks_learn_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_improving_the_way_neural_networks_learn" src="images/arrow.png" width="15px"></a><a href="chap3.html">Improving the way neural networks learn</a><div id="toc_improving_the_way_neural_networks_learn" style="display: none;"><p class="toc_section"><ul><a href="chap3.html#the_cross-entropy_cost_function"><li>The cross-entropy cost function</li></a><a href="chap3.html#overfitting_and_regularization"><li>Overfitting and regularization</li></a><a href="chap3.html#weight_initialization"><li>Weight initialization</li></a><a href="chap3.html#handwriting_recognition_revisited_the_code"><li>Handwriting recognition revisited: the code</li></a><a href="chap3.html#how_to_choose_a_neural_network's_hyper-parameters"><li>How to choose a neural network's hyper-parameters?</li></a><a href="chap3.html#other_techniques"><li>Other techniques</li></a></ul></p></div>
<script>
$('#toc_improving_the_way_neural_networks_learn_reveal').click(function() { 
   var src = $('#toc_img_improving_the_way_neural_networks_learn').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_improving_the_way_neural_networks_learn").attr('src', 'images/arrow.png');
   };
   $('#toc_improving_the_way_neural_networks_learn').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_a_visual_proof_that_neural_nets_can_compute_any_function" src="images/arrow.png" width="15px"></a><a href="chap4.html">A visual proof that neural nets can compute any function</a><div id="toc_a_visual_proof_that_neural_nets_can_compute_any_function" style="display: none;"><p class="toc_section"><ul><a href="chap4.html#two_caveats"><li>Two caveats</li></a><a href="chap4.html#universality_with_one_input_and_one_output"><li>Universality with one input and one output</li></a><a href="chap4.html#many_input_variables"><li>Many input variables</li></a><a href="chap4.html#extension_beyond_sigmoid_neurons"><li>Extension beyond sigmoid neurons</li></a><a href="chap4.html#fixing_up_the_step_functions"><li>Fixing up the step functions</li></a><a href="chap4.html#conclusion"><li>Conclusion</li></a></ul></p></div>
<script>
$('#toc_a_visual_proof_that_neural_nets_can_compute_any_function_reveal').click(function() { 
   var src = $('#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_a_visual_proof_that_neural_nets_can_compute_any_function").attr('src', 'images/arrow.png');
   };
   $('#toc_a_visual_proof_that_neural_nets_can_compute_any_function').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_why_are_deep_neural_networks_hard_to_train_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_why_are_deep_neural_networks_hard_to_train" src="images/arrow.png" width="15px"></a><a href="chap5.html">Why are deep neural networks hard to train?</a><div id="toc_why_are_deep_neural_networks_hard_to_train" style="display: none;"><p class="toc_section"><ul><a href="chap5.html#the_vanishing_gradient_problem"><li>The vanishing gradient problem</li></a><a href="chap5.html#what's_causing_the_vanishing_gradient_problem_unstable_gradients_in_deep_neural_nets"><li>What's causing the vanishing gradient problem?  Unstable gradients in deep neural nets</li></a><a href="chap5.html#unstable_gradients_in_more_complex_networks"><li>Unstable gradients in more complex networks</li></a><a href="chap5.html#other_obstacles_to_deep_learning"><li>Other obstacles to deep learning</li></a></ul></p></div>
<script>
$('#toc_why_are_deep_neural_networks_hard_to_train_reveal').click(function() { 
   var src = $('#toc_img_why_are_deep_neural_networks_hard_to_train').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_why_are_deep_neural_networks_hard_to_train").attr('src', 'images/arrow.png');
   };
   $('#toc_why_are_deep_neural_networks_hard_to_train').toggle('fast', function() {});  
});</script><p class='toc_mainchapter'><a id="toc_deep_learning_reveal" class="toc_reveal" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';"><img id="toc_img_deep_learning" src="images/arrow.png" width="15px"></a><a href="chap6.html">Deep learning</a><div id="toc_deep_learning" style="display: none;"><p class="toc_section"><ul><a href="chap6.html#introducing_convolutional_networks"><li>Introducing convolutional networks</li></a><a href="chap6.html#convolutional_neural_networks_in_practice"><li>Convolutional neural networks in practice</li></a><a href="chap6.html#the_code_for_our_convolutional_networks"><li>The code for our convolutional networks</li></a><a href="chap6.html#recent_progress_in_image_recognition"><li>Recent progress in image recognition</li></a><a href="chap6.html#other_approaches_to_deep_neural_nets"><li>Other approaches to deep neural nets</li></a><a href="chap6.html#on_the_future_of_neural_networks"><li>On the future of neural networks</li></a></ul></p></div>
<script>
$('#toc_deep_learning_reveal').click(function() { 
   var src = $('#toc_img_deep_learning').attr('src');
   if(src == 'images/arrow.png') {
     $("#toc_img_deep_learning").attr('src', 'images/arrow_down.png');
   } else {
     $("#toc_img_deep_learning").attr('src', 'images/arrow.png');
   };
   $('#toc_deep_learning').toggle('fast', function() {});  
});</script><p class="toc_not_mainchapter"><a href="sai.html">Appendix: Is there a <em>simple</em> algorithm for intelligence?</a></p><p class="toc_not_mainchapter"><a href="acknowledgements.html">Acknowledgements</a></p><p class="toc_not_mainchapter"><a href="faq.html">Frequently Asked Questions</a></p>
<hr>
<p class="sidebar"> If you benefit from the book, please make a small
donation.  I suggest $5, but you can choose the amount.</p>

<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick">
<input type="hidden" name="hosted_button_id" value="5K9YAHR4X84RN">
<input type="image" src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif" border="0" name="submit" alt="PayPal - The safer, easier way to pay online!">
<img alt="" border="0" src="https://www.paypalobjects.com/en_US/i/scr/pixel.gif" width="1" height="1">
</form>

<p class="sidebar">Alternately, you can make a donation by sending me
Bitcoin, at address <span style="font-size: 0.7em">1Kd6tXH5SDAmiFb49J9hknG5pqj7KStSAx</span></p>

<!--
<hr>

<p class="sidebar"> If you benefit from the book, please make a small
donation.  I suggest $3, but you can choose the amount.</p>

<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick">
<input type="hidden" name="encrypted" value="-----BEGIN PKCS7-----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-----END PKCS7-----
">
<input type="image" src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif" border="0" name="submit" alt="PayPal - The safer, easier way to pay online!">
<img alt="" border="0" src="https://www.paypalobjects.com/en_US/i/scr/pixel.gif" width="1" height="1">
</form>

-->

<hr>
<span class="sidebar_title">Sponsors</span>
<br/>

<a href="https://lambdalabs.com/?utm_source=neuralnetworksdeeplearning&utm_medium=banner&utm_campaign=blogin&utm_content=rbannerimg">
  <img src="assets/lambda.png" width="200px" style="padding: 3px 0px 0px 10px; border-style: none;">
</a>
<br>
<div style="line-height: 1.2; padding-bottom: 12px; font-size: 0.8;">
  <a href="https://lambdalabs.com/?utm_source=neuralnetworksdeeplearning&utm_medium=banner&utm_campaign=blogin&utm_content=rtext">Deep Learning Workstations, Servers, and Laptops</a>
</div>

<a href='http://gsquaredcapital.com/'><img src='assets/gsquared.png' width='200px' style="padding: 5px 0px 10px 10px; border-style: none;"></a>

<a href='http://www.tineye.com'><img src='assets/tineye.png' width='200px'
style="padding: 0px 0px 10px 8px; border-style: none;"></a>

<a href='http://www.visionsmarts.com'><img
src='assets/visionsmarts.png' width='210px' style="padding: 0px 0px
0px 0px; border-style: none;"></a> <br/> 

<p class="sidebar">Thanks to all the <a
href="supporters.html">supporters</a> who made the book possible, with
especial thanks to Pavel Dudrenov.  Thanks also to all the
contributors to the <a href="bugfinder.html">Bugfinder Hall of
Fame</a>.  </p>

<hr>
<span class="sidebar_title">Resources</span>

<p class="sidebar"><a href="https://twitter.com/michael_nielsen">Michael Nielsen on Twitter</a></p>

<p class="sidebar"><a href="faq.html">Book FAQ</a></p>

<p class="sidebar">
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning">Code repository</a></p>

<p class="sidebar">
<a href="http://eepurl.com/0Xxjb">Michael Nielsen's project announcement mailing list</a>
</p>

<p class="sidebar"> <a href="http://www.deeplearningbook.org/">Deep Learning</a>, book by Ian
Goodfellow, Yoshua Bengio, and Aaron Courville</p>

<p class="sidebar"><a href="http://cognitivemedium.com">cognitivemedium.com</a></p>

<hr>
<a href="http://michaelnielsen.org"><img src="assets/Michael_Nielsen_Web_Small.jpg" width="160px" style="border-style: none;"/></a>

<p class="sidebar">
By <a href="http://michaelnielsen.org">Michael Nielsen</a> / Dec 2019
</p>
</div>
</p>
<p>
  O sistema visual humano é uma das maravilhas do mundo. 
  Considere a seguinte sequência de digitos manuscritos:
<a name="complete_zero"></a>
</p>
<p>
  <center>
    <img src="images/digits.png" width="160px">
  </center>
 </p>
<p>
  A maioria das pessoas reconhece sem esforço esses digitos como sendo 504192.
  Mas talvez "sem esforço" não seja a melhor maneira de descrever esse processo.
   Em cada hemisfério do seu cérebro, humanos tem 
  um cortex primário visual, também conhecido como V1, contendo 140 milhões de neurônios,
  com dezenas de bilhões de conexões entre eles. E a visão humana não envolve apenas V1,
  mas uma série de cortex visuais - V2, V3, V4 e V5 - que fazem um processamento de imagem
  progressivamente mais complexo. Nós carregamos em nossas cabeças um supercomputador, 
  que foi condicionado pela evolução ao longo de milhões de anos, e se tornou absurdamente
  adaptado em entender o mundo visual. Reconhecer digitos manuscritos não é fácil. A questão 
  é que nós humanos somos tão incrívelmente bons em fazer isso que boa parte desse trabalho é feito
  inconscientemente. E por conta disso nós não apreciamos o quão difícil é o problema que nosso
  sistema visual tem que resolver. 
</p>
<p>
  A dificuldade de reconhecimento de padrões visuais se torna aparente quando você tenta escrever
  um programa de computador que seja capaz de reconhecer digitos como esses acima. Algo que parece 
  fácil quando nós mesmos fazemos de repente se torna extremamente difícil. Intuições simples sobre 
  como nós reconhecemos formas - "um 9 tem uma volta no topo, e uma linha vertical em baixo a direita" - 
  se mostram não tão simples de serem expressas em um algoritmo. Quando se tenta fazer essas 
  regras de forma precisa, você rapidamente se perde em um mar de exceções e casos especiais.
</p>
<p></p>
<p>
  Redes Neurais abordam o problema de uma forma diferente. A ideia é de pegar um grande número de 
  dígitos escritos há mão, conhecidos como exemplos de treino,
</p>
<p><center><img src="images/mnist_100_digits.png" width="440px"></center>
</p>
<p>
  e então desenvolver um sistema que consiga aprender a partir desses exemplos de treino. Em outras
  palavras, a rede neural usa os exemplos para automaticamente definir regras para o reconhecimento
  de dígitos manuscritos. Além disso, se aumentarmos o número de exemplos de treino, a rede neural
  consegue aprender mais sobre dígitos manuscritos, e então melhoras sua precisão. Foram mostrados 
  100 dígitos de treino acima, talvez nós poderiamos construir um reconhecedor de dígitos manuscritos
  ainda melhor se estivessemos usando milhares o até mesmo milhões ou bilhões de exemplos de treino.
</p>
<p>
  Nesse capítulo nós iremos escrever um programa de computador implementando uma rede neural que 
  reconhece dígitos manuscritos. O programa tem apenas 74 linhas, e não usa nenhuma biblioteca
  especial para redes neurais. Mas esse pequeno programa pode reconhecer dígitos manuscritos com 
  uma precisão de 96%, sem intervenção humana. Além disso, em capítulos posteriores nós iremos
  desenvolver ideias que podem melhorar a precisão desse programa para níveis acima de 99%. Na verdade, 
  as melhores redes neurais comerciais são agora tão boas que elas são usadas em bancos para processar
  cheques, e serviços postais para reconhecer endereços.
</p>
<p>
  Nós iremos focar em reconhecimento de manuscritos porque é um problema protótipo excelente para aprender
  redes neurais no geral. Como protótipo ele é perfeito: é desafiador - como já vimos não é algo simples
  reconhecer digitos manuscritos - mas também não é difícil ao ponto de demandar uma solução extremamente
  complicada, ou um poder computacional gigantesco. Além disso, é uma ótima forma de desenvolver técnicas
  mais avançadas como deep learning. Portanto, ao longo desse livro nós iremos retornar várias vezes para 
  o problema de reconhecimento de dígitos manuscritos. Em capítulos mais avançados iremos discutir como esssas
  ideias podem ser aplicadas em outros problemas como visão computacional, processamento de fala
  e texto, entre outros domínios.
</p>
<p>
  Se o ponto desse capítulo fosse apenas escrever um programa de computador para reconhecer digitos manuscritos
  esse capitulo seria muito menor, não é mesmo? Mas ao longo do caminho nós iremos desenvolver várias ideias 
  chave sobre redes neurais, inclusive dois tipos importantes de neurônios artificiais (o perceptron e o 
  neurônio sigmoid), e também o algoritmo de aprendizado padrão para redes neurais, conhecido como 
  gradiente stocástico descedente (soa complicado mas não é, confia no pai). Ao longo do livro, eu irei focar em explicar o 
  <em>porquê</em>  das coisas serem feitas do jeito que são, e em construir sua intuição em redes neurais. 
  Para abordar tudo isso dessa forma mais didática e profunda é necessário uma discussão mais longa do que se 
  fosse apresentado apenas as mecânicas básicas de como tudo acontece, mas vale a pena se levarmos em conta o 
  entendimento profundo que esse tipo de abordagem irá trazer para você. Até o final desse capítulo você estará na posição 
  de entender o que deep learning é, e porque isso é tão importante.
</p>
<p>
  <h3>
    <a name="perceptrons"></a>
    <a href="#perceptrons">Perceptrons</a>
  </h3>
</p>
<p>
  O que é uma rede neural? Para começar, eu irei explicar um tipo de neurônio artificial chamado 
  <em>perceptron</em>. Perceptrons foram 
  <a href="http://books.google.ca/books/about/Principles_of_neurodynamics.html?id=7FhRAAAAMAAJ">
    desenvolvidos</a>
  nos anos 50 e 60 pelo cientista 
  <a href="http://en.wikipedia.org/wiki/Frank_Rosenblatt">Frank Rosenblatt</a>, inspirado por 
  <a href="http://scholar.google.ca/scholar?cluster=4035975255085082870">trabalhos anteriores</a> 
  de  
  <a href="http://en.wikipedia.org/wiki/Warren_McCulloch">Warren McCulloch</a> 
  e  
  <a href="http://en.wikipedia.org/wiki/Walter_Pitts"> WalterPitts</a>. 
  Hoje em dia é mais comum usar um outro modelo de neurônio artificial - neste livro, e em muitos livros
  modernos sobre redes neurais, o modelo principal usado é um chamado <em>neurônio sigmoid</em>. Nós iremos 
  abordar os neurônios sigmoids em breve. Mas para entender o porquê dos neurônios sigmoids serem definidos
  do jeito que são, vale a pena entender perceptrons antes.
</p>
<p>
  Então como perceptrons funcionam? Um perceptron recebe várias entradas binárias, $x_1, x_2, \ldots$, e 
  produz uma saída binária: 
<center>
<img src="images/tikz0.png"/>
</center>
Esse exemplo mostra um perceptron que recebe três entradas, $x_1, x_2, x_3$. Em geral ele poderia ter mais 
ou menos entradas. Rosenblatt propós uma regra simples para calcular a saída. Ele introduziu <em>pesos</em>
, $w_1,w_2,\ldots$, números reais que expressam a importância dos respectivos valores de entrada para o 
valor de saída. A saída do neurônio, $0$ or $1$, é determindada se a soma ponderada $\sum_j w_j x_j$ é menor
ou maior do que um certo <em>valor limite</em>. Assim como os pesos, o limite é um número real que é 
um parametro do neurônio. Colocando isso em termos mais algébricos:
  <a class="displaced_anchor" name="eqtn1"></a>\begin{eqnarray}
  \mbox{saída} & = & \left\{ \begin{array}{ll}
      0 & \mbox{if } \sum_j w_j x_j \leq \mbox{valor limite} \\
      1 & \mbox{if } \sum_j w_j x_j > \mbox{ valor limite}
      \end{array} \right.
\tag{1}\end{eqnarray}

  E basicamente é assim que perceptrons funcionam!
</p>
<p>
  Esse é o modelo matemático básico. Uma maneira de interpretar o perceptron é pensar nele como se fosse um
  dispositivo que toma decisões através da adição de pesos as evidências que estão sendo usadas para realizar
  essa tomada de decisão. Deixe-me exemplificar essa ideia. Não é um exemplo muito realístico, mas é fácil de 
  entender, e em breve iremos abordar exemplos mais realistas. Suponha que o fim de semana está chegando
  e você ouviu que vai rolar uma chopada. 
  Você gosta de chopadas, e está tentando decidir entre ir ou não. Estando
  nessa situação talvez você tenha que tomar essa decisão <em>pesando</em> três fatores:
<ol>
  <li> O clima no dia é propicio?
  <li> Sua namorada ou namorado vai querer ir com você?
  <li> A chopada é próxima de algum transporte público?(você não tem um carro :/)
</ol>
  Nós podemos representar esses três fatores como valores binários correspondentes $x_1, x_2$, e $x_3$.
  Por exemplo, nós teriamos $x_1 = 1$ se o clima no dia for propicio, e $x_2 = 1$ se seu namorado ou namorada
  quiser ir contigo, e  $x_2 = 0$ se ele ou ela não quiser. E o mesmo acontece com $x_3$ e o transporte público.
</p>
<p>
  Agora, suponha que você goste muito de dançar funk nas chopadas, tanto que você estaria feliz em ir mesmo se 
  sua namorada(o) não esteja interessada(o) ou se chegar no local seja difícil.
  Mas talvez você realmente odeie tempo ruim, e você não iria na chopada se o clima do dia fossse chuvoso por
  exemplo. Você pode usar perceptrons para modelar esse tipo de tomada de decisão. Uma maneira de fazer isso 
  é escolhendo um peso $w_1 = 6$ para o clima, e $w_2 = 2$ e $w_3 = 2$ para as outras condições. Quanto maior
  o valor de $w_1$ mais importante para você é a questão do clima, bem mais importante do que se o seu namorado(a)
  te acompanhará, ou se a chopada é próxima do tranporte público. Agora suponha que o valor limite é $5$ para o 
  perceptron. Com essas escolhas, o perceptron  implementa o modelo de decisão desejado, apresentando como saída
  $1$ sempre que o clima é bom, e $0$ sempre que o clima é ruim. Não faz diferença para a saída do perceptron
  se o se namorado(a) quer ir, ou se o transporte público é perto.
</p>
<p>
  Variando os pesos e o valor limite nós podemos gerar diferentes modelos de tomada de decisão. Por exemplo,
  suponha que nós escolhamos um valor limite de $3$. Então o percepron iria decidir que você deveria ir a 
  chopada sempre que o tempo estivesse bom <em>ou</em> quando ambos a chopada estivesse perto do transporte
  público <em>e</em> sua namorada(o) esteja disposta(o) a ir com você. Em outras palavras, ele seria um modelo
  de tomada de decisão diferente. Abaixar o valor limite significa que você está mais disposto a ir a chopada 
</p>
<p>
  Obviamente, o perceptron não é um modelo humano completo de tomada de decisão! Mas o que o exemplo illustra
  é como um perceptron pode pesar diferentes tipos de evidência com o objetivo de tomar decisões. E levando tudo
  isso em conta é plausível considerar que uma rede complexa de perceptrons poderia tomar decisões que poderiam
  ser consideradas complexas:
<center>
<img src="images/tikz1.png"/>
</center>
Nessa rede, a primeira coluna de perceptrons - o que chamamos de a primeira <em>camada</em> de perceptrons -
está fazendo três decisões bem simples, ao multiplicar pesos aos valores de entrada. E quanto ao a segunda 
camada de perceptrons? Cada um desses perceptrons da segunda camada está multiplicando pesos aos valores dos
neurônios das camadas anteriores e tomando decisões a partir das decisões dos neurônios da camada anterior.
Dessa maneira cada camada pode um perceptron na segunda camada pode tomar uma decisão mais complexa e mais
abstrata do que o neurônio da camada anterior. E decisões ainda mais complexas podem ser feitas por um perceptron
da terceira camada. Assim, uma rede de perceptrons de várias camadas pode realizar tomadas de decisões complexas
</p>
<p>
  A propósito, quando se define perceptrons, cada perceptron tem apenas um único valor de saída. Na rede 
  acima os perceptrons parecem ter multiplos valores de saida. Na verdade eles tem apenas uma única saída.
  As várias setas saindo dos perceptrons são apenas para indicar que essa saída do perceptron é usada como 
  entrada para vários outros perceptrons da camada seguinte. E menos desajeitado do que desenhar uma única
  linha que posteriormente se divide em várias setas não é mesmo?
</p>
<p>
  Vamos simplificar o modo como descrevemos perceptrons. A condição $\sum_j w_j x_j > \mbox{threshold}$
  é complicacada, é nós podemos fazer duas mudanças na notação para simplifica-la. A primeira mudança seria
  escrever $\sum_j w_j x_j$ como um produto escalar, $w \cdot x \equiv \sum_j w_j x_j$, onde $w$ e $x$ são 
  vetores que tem como componentes os pesos e valores de entrada respectivamente. A segunda mudança é mover 
  o valor limite - em inglês <em>threshold</em> - para o outro lado da desigualdade, e substituir ele por 
  um valor que é chamado o <em>bias</em> -  tendência - de um perceptron $b \equiv-\mbox{threshold}$. 
  usando o bias envés do valor limite, a regra do perceptron pode se reescrita: 
<a class="displaced_anchor" name="eqtn2"></a>
\begin{eqnarray}
  \mbox{output} = \left\{ 
    \begin{array}{ll} 
      0 & \mbox{if } w\cdot x + b \leq 0 \\
      1 & \mbox{if } w\cdot x + b > 0
    \end{array}
  \right.
\tag{2}\end{eqnarray} Você pode interpretar o bias como sendo uma medida de o quão fácil é para que o valor de sáida de um determinado
perceptron seja $1$. Ou para colocar em termos mais biológicos, o bias é a medida de o quão fácil é para um 
perceptron <em>disparar</em>. Para um perceptron com um bias muito grande, é extremamente para que a saída desse
perceptron seja $1$. Mas para um perceptron com um bias muito negativo, é mais difícil para o perceptron ter
$1$ como seu valor de saída. Obviamente, a introdução do bias é apenas uma pequena mudança na forma como 
descrevemos perceptrons, mas nós veremos mais tarde que essa pequena mudança leva para várias simplificações 
de notação. Por causa disso, no resto do livro não usaremos o valor limite, sempre usaremos o bias.
</p>
<p>
  Eu descrevi perceptrons como um metodo de ponderar evidencias para tomar decisões. Outra maneira de de utilizar
  perceptrons é para computar funções lógicas fundamentais para a computação, funções como <CODE>AND</CODE>,
  <CODE>OR</CODE>, e <CODE>NAND</CODE>. Por exemplo, suponha que temos um perceptrons com dois valores de entrada, cada um com peso $-2$, e um bias global de $3$. Esse é o nosso percepton: 
<center>
<img src="images/tikz2.png"/>
</center>
  É possivel ver que o valor de entrada $00$ produz uma saída $1$, desde que $(-2)*0+(-2)*0+3 = 3$ é positivo.
  Aqui eu introduzi o símbolo $*$ para tornar a multiplicação explicita. Calculos similares mostram que o para 
  valores de entrada $01$ e $10$ produzem a saída $1$. Mas a entrada $11$ produz a saída $0$, desde que $(-2)
  *1 +(-2)*1+3 = -1$ seja negativo. E assim nosso percetron implementa um porta lógica <CODE>NAND</CODE>!!
</p>

<p>
  <a name="universality"></a>
</p>
<p>
  O exemplo <CODE>NAND</CODE> nos mostra que podemos usar percetrons para calcular funções lógicas simples. 
  Na verdade, nós podemos usar redes de perceptrons para calcular <em>qualquer</em> função lógica.
  O porque disso é que a porta lógica <CODE>NAND</CODE> é universal para a computação, isso siginifica que,
  nós podemos construir qualquer computação apenas com portas lógicas<CODE>NAND</CODE>. Por exemplo, nós 
  podemos usar portas lógicas <CODE>NAND</CODE> para construir um circuito que adiciona dois bits, $x_1$ e
  $x_2$. Isso requer calcular uma soma <em>bitwise</em>, $x_1 \oplus x_2$, e também carregar o bit de valor
  $1$ quando ambos $x_1$ e $x_2$ são $1$, i.e., o bit carregado é apenas o produto de $x_1 x_2$: 
<center>
 <img src="images/tikz3.png"/>
</center> 
  Para conseguir a rede de perceptrons equivalente a esse circuito nós substituimos todos as portas <CODE>NAND</CODE>
  por perceptrons com duas entradas, cada uma com um peso $-2$, e um bias global $3$. Essa é a rede resultante.
  Note que eu movi um pouco o perceptron correspondente a porta <CODE>NAND</CODE> do canto inferior direito 
  apenas para tornar mais fácil desenhar as setas no diagrama:
<center>
 <img src="images/tikz4.png"/>
</center>
  Um aspecto notável dessa rede de perceptron é que a saída do perceptron mais a esquerda é usada duas vezes
  como entrada do último perceptron de baixo. Quando eu defini o modelo de perceptron eu não disse se esse tipo 
  de dupla entrada era permitida. Na verdade, isso não importa tanto. Se nós não queremos permitir esse tipo de
  coisa, é possível unir as duas linhas em uma única conexão com um peso -4 envés de ter duas conexões com peso
  -2 (Se você não acha isso óbvio, sugiro que você pare e prove para si mesmo que esses dois casos são equivalentes).
  Com essa mudança, a rede fica como na imagem abaixo, com todos os pesos não marcados iguais a -2, e todos 
  os biases iguais 3, e apenas um peso como -4:
<center>
 <img src="images/tikz5.png"/>
</center>
  Até agora eu tenho desenhado as entradas $x_1$ e $x_2$ como variáveis flutuando a esquerda da rede de 
  perceptrons. Na verdade, é convencional desenhar uma camada extra de perceptrons <em>- a camada de entrada </em>
  - para codificar as entradas: 
<center>
 <img src="images/tikz6.png"/>
</center>
  Essa notação para perceptrons de entrada, que tem uma saída, mas não tem uma entrada,
<center>
<img src="images/tikz7.png"/>
</center>
  é uma abreviação. Não significa exatamente que o perceptron não tem entradas. Para enxergar isso, suponha que
  tivéssemos um perceptron sem entradas. Nesse caso a media ponderada $\sum_j w_j x_j$ seria sempre zero, e portanto 
  a saida do perceptron seria $1$ se $b > 0$ e seria $0$ se $b \leq 0$. Isso significa que, o perceptron iria 
  simplesmente exibir como saida um valor fixo e não o valor desejado(que seria $x_1$ no exemplo acima). É melhor pensar nas entradas dos perceptrons como não sendo perceptrons, mas sim como sendo unidades especiais que são
  definidas pela saida dos valores desejados,$x_1, x_2,\ldots$.
</p>
<p>
  O exemplo da adição demonstra como uma rede de perceptrons pode simular um circuito contendo várias portas
  <CODE>NAND</CODE>. E como portas <CODE>NAND</CODE> são universais na computação, portanto perceptrons também
  são universais para computação.
</p>
<p>
  A universalidade computacional dos perceptrons, ao mesmo tempo, empolga e desaponta. É empolgante pois 
  mostra que perceptrons são tão poderosos quanto qualquer dispositivo computacional. Mas desaponta no sentido
  de parecer que perceptrons são apenas um novo tipo de porta <CODE>NAND</CODE>.
</p>
<p>
  No entanto, a situação é melhor do que parece. Acontece que nós podemos inventar <em>algoritimos de aprendizado</em>
  que podem automaticamente mudar os pesos e biases da rede artificial de neurônios. Essa mudança dos pesos e biases
  acontede em resposta a estimulos externos, sem a intervenção direta de um programador. Esses algoritimos de aprendizado
  nos permitem usar neurônios artificiais de um jeito que é radicalmente diferente do uso convencional de portas lógicas.
  Envés de explicitamente montar um circuito de portas <CODE>NAND</CODE> e outras portas lógicas, nossa rede neural
  pode simplesmente aprender a resolver problemas, em alguns casos problemas que seriam extremamente difícil de diretamente
  desenvolver um circuito convencional para resolver.
</p>
<p>
  <h3>
    <a name="sigmoid_neurons"></a>
    <a href="#sigmoid_neurons">Sigmoid neurons</a>
  </h3>
</p>
<p>
  Aprender algoritimos soa aterorizante. Mas nós podemos inventar tais algoritmos para uma rede neural?
  Suponha que nós temos uma rede de perceptrons que gostariamos de usar para resolver um problema. Por
  exemplo, as entradas da rede poderiam ser dados de pixels de um digito manuscrito scanneado. E nós 
  queremos que essa rede aprenda os pesos e biases de forma que a saída da rede classifique corretamente
  o digito. Para vermos como esse aprendizado funcionaria, suponha que fizessemos uma pequena alteração
  em algum peso (ou bias) da rede. O que nós gostariamos é que essa pequena mudança no peso cause apenas 
  uma pequena mudança correspondente na saída da rede. Como iremos ver mais pra frente, essa propriedade
  é o que tornará o aprendizado possível. Esquematicamente, isso é o que queremos (obviamente essa rede é 
  muito simples para fazer reconhecimento de manuscritos!):  
</p>
<p>
  <center>
    <img src="images/tikz8.png"/>
  </center>
    <h6><i>Uma pequena mudança em qualquer peso (ou bias) causa uma pequena mudança na saída</i></h6>
</p>
<p>
  Se uma pequena mudança em um peso (ou bias) causa uma pequena mudança na saída, então nós podemos usar esse
  fato para modificar os pesos e biases para fazer nossa rede se comportar do jeito que queremos. Por exemplo,  
  suponha que a rede classifique erradamente uma imagem de um "8" quando na verdade deveria ser um "9". E então
  nós repetimos isso, mudando os pesos e biases de novo e de novo para produzir uma saida cada vez melhor. E então
  essa rede estaria aprendendo.
</p>
<p>
  O problema é que isso não é o que acontece quando nossa rede é formada por perceptrons. Na verdade, uma pequena
  mudança nos pesos e biases de um perceptron da rede poderia causar uma mudança drástica na saida desse perceptron,
  mudando a saída de $0$ para $1$ apenas com uma pequena alteração. Essa mudança drástica, em um único perceptron,
  poderia causar uma completa mudança no comportamento da nossa rede. Considerando nosso último exemplo, 
  mesmo que seja possível alterar os pesos de modo que a rede classifique de forma correta a imagem de um "9",
  por conta das mudanças feitas na rede, a classificação de todos os outros dígitos acaba sendo comprometida.    
  Isso torna difícil mudar gradualmente os valores dos pesos e biases de modo a se aproximar do 
  comportamento desejado. Talvez exista um jeito de contornar esse problema. Mas não é imediatamente óbvio.
</p>
<p>
  Nós podemos contornar esse problema introduzindo um novo tipo de neurônio artificial chamado neurônio <em>sigmoid</em>.
  Neurônios Sigmoid são similares aos perceptrons, mas modificados para que pequenas mudanças nos pesos e bias causem  
  apenas uma pequena mudança na saída. Esse é o fato crucial que permite que uma rede de neurônios sigmoid aprendam.
</p>
<p>
  Certo, Deixe-me descrever o neurônio sigmoid. Nós iremos representá-lo da mesma maneira que representamos
  perceptrons:
<center>
<img src="images/tikz9.png"/>
</center>
Assim como o perceptron, o neurônio sigmoid tem entradas, $x_1, x_2, \ldots$. Mas envés de ser apenas $0$ ou $1$
essas entradas podem assumir valores <em>entre</em> $0$ e $1$. Então, por exemplo, $0.638\ldots$ é uma entrada válida
para o neurônio sigmoid. E assim como o perceptron, o neurônio sigmoid tem pesos para cada entrada,$w_1, w_2,
\ldots$ e um bias global, $b$. Mas a saída não é apenas $0$ ou $1$. A saída de um neurônio sigmoid seria 
$\sigma(w \cdot x+b)$, onde $\sigma$ é chamado de <em>função sigmoid</em>*
<span class="marginnote">
*aliás, $\sigma$ é também chamado de <em>função logística</em>, e essa nova classe de neurônios é chamada de 
<em>neurônios logísticos</em>. É útil lembrar dessas terminologias, já que esses termos são usados por grande 
parte das pessoas trabalhando com redes neurais. No entanto, nós iremos usar a terminologia sigmoid.
</span>, ela é definida do seguinte modo:

<a class="displaced_anchor" name="eqtn3"></a>\begin{eqnarray} 
  \sigma(z) \equiv \frac{1}{1+e^{-z}}.
\tag{3}\end{eqnarray}
Tornando ess definição um pouco mais explícita, a saída do neurônio sigmoid com entradas $x_1,x_2,\ldots$, pesos
$w_1,w_2,\ldots$, e bias $b$ é
<a class="displaced_anchor" name="eqtn4"></a>\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)}.
\tag{4}\end{eqnarray}
</p>
<p>
  A primeira vista, neurônios sigmoid parecem ser bem diferentes dos perceptrons. A forma algébrica da função
  sigmoid parece meio opaca e proibitiva se você não está familiarizado com ela. No entanto, existem várias
  similaridades entre perceptrons e neurônio sigmoid, e a forma algébrica da função sigmoid é muito mais um
  detalhe técnico do que uma barreira para entender o conceito.
</p>
 <p>
   Para entender a similaridade com o perceptron, suponha  que $z\equiv w \cdot x + b$ é um número positivo grande.
   Então $e^{-z}\approx 0$ e portanto $\sigma(z) \approx 1$. Em outras palavras, quando $z = w\cdot x+b$ é grande e
   positivo, a saída do neurônio sigmoid é aproximadamente $1$, ou seja, aproximadamente o que nós teriamos caso fosse 
   um perceptron. Agora suponha que $z = w \cdot x+b$ é bem negativo. Portanto $e^{-z} \rightarrow \infty$ e $\sigma(z) \approx 0$. 
   Então quando $z = w \cdot x +b$ é muito negativo, o comportamento do neurônio sigmoid também se aproxima ao de um 
   perceptron. Apenas quando $w \cdot x+b$ é um tamanho entre $0$ e $1 o neurônio sigmoid se comporta diferente
   de um perceptron.
 </p>
 <p>
   E quanto a forma algébrica de $\sigma$? Como nós podemos entender isso? No fim das contas a exata forma de $\sigma$
   não é tão importante - o que realmente importa é o formato da função quando desenhado no gráfico. O formato é o 
   seguinte:
</p>
<p>
<div id="sigmoid_graph"><a name="sigmoid_graph"></a></div>
<script src="http://d3js.org/d3.v3.min.js"></script>
<script>
function s(x) {return 1/(1+Math.exp(-x));}
var m = [40, 120, 50, 120];
var height = 290 - m[0] - m[2];
var width = 600 - m[1] - m[3];
var xmin = -5;
var xmax = 5;
var sample = 400;
var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
var data = d3.range(sample).map(function(d){ return {
        x: x1(d), 
        y: s(x1(d))}; 
    });
var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
var y = d3.scale.linear()
                .domain([0, 1])
                .range([height, 0]);
var line = d3.svg.line()
    .x(function(d) { return x(d.x); })
    .y(function(d) { return y(d.y); })
var graph = d3.select("#sigmoid_graph")
    .append("svg")
    .attr("width", width + m[1] + m[3])
    .attr("height", height + m[0] + m[2])
    .append("g")
    .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
var xAxis = d3.svg.axis()
                  .scale(x)
                  .tickValues(d3.range(-4, 5, 1))
                  .orient("bottom")
graph.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0, " + height + ")")
    .call(xAxis);
var yAxis = d3.svg.axis()
                  .scale(y)
                  .tickValues(d3.range(0, 1.01, 0.2))
                  .orient("left")
                  .ticks(5)
graph.append("g")
    .attr("class", "y axis")
    .call(yAxis);
graph.append("path").attr("d", line(data));
graph.append("text")
     .attr("class", "x label")
     .attr("text-anchor", "end")
     .attr("x", width/2)
     .attr("y", height+35)
     .text("z");
graph.append("text")
        .attr("x", (width / 2))             
        .attr("y", -10)
        .attr("text-anchor", "middle")  
        .style("font-size", "16px") 
        .text("sigmoid function");
</script>
</p><p>Esse formato é basicamente um formato mais suave de uma função de degrau:</p><p>
<div id="step_graph"></div>
<script>
function s(x) {return x < 0 ? 0 : 1;}
var m = [40, 120, 50, 120];
var height = 290 - m[0] - m[2];
var width = 600 - m[1] - m[3];
var xmin = -5;
var xmax = 5;
var sample = 400;
var x1 = d3.scale.linear().domain([0, sample]).range([xmin, xmax]);
var data = d3.range(sample).map(function(d){ return {
        x: x1(d), 
        y: s(x1(d))}; 
    });
var x = d3.scale.linear().domain([xmin, xmax]).range([0, width]);
var y = d3.scale.linear()
                .domain([0,1])
                .range([height, 0]);
var line = d3.svg.line()
    .x(function(d) { return x(d.x); })
    .y(function(d) { return y(d.y); })
var graph = d3.select("#step_graph")
    .append("svg")
    .attr("width", width + m[1] + m[3])
    .attr("height", height + m[0] + m[2])
    .append("g")
    .attr("transform", "translate(" + m[3] + "," + m[0] + ")");
var xAxis = d3.svg.axis()
                  .scale(x)
                  .tickValues(d3.range(-4, 5, 1))
                  .orient("bottom")
graph.append("g")
    .attr("class", "x axis")
    .attr("transform", "translate(0, " + height + ")")
    .call(xAxis);
var yAxis = d3.svg.axis()
                  .scale(y)
                  .tickValues(d3.range(0, 1.01, 0.2))
                  .orient("left")
                  .ticks(5)
graph.append("g")
    .attr("class", "y axis")
    .call(yAxis);
graph.append("path").attr("d", line(data));
graph.append("text")
     .attr("class", "x label")
     .attr("text-anchor", "end")
     .attr("x", width/2)
     .attr("y", height+35)
     .text("z");
graph.append("text")
        .attr("x", (width / 2))             
        .attr("y", -10)
        .attr("text-anchor", "middle")  
        .style("font-size", "16px") 
        .text("step function");
</script>
</p>
<p>
  Se $\sigma$ fosse realmente uma função de degrau, então o neurônio sigmoid seria um perceptron, já que a 
  saída seria $1$ ou $0$ dependendo se $w\cdot x+b$ <em>fosse</em> positivo ou negativo* 
<span class="marginnote">
  *Na verdade, quando $w \cdot x +b = 0$ o perceptron tem como saída $0$, enquanto a função degrau tem como saída $1$.
  Portanto, caso fossemos abordar de forma mais rigorosa, a função degrau teria que ser modificada nesse ponto.
  Mas acho que você entendeu a ideia.
</span>.  
  Usando a função $\sigma$ nós temos, como já citado acima, um perceptron mais suave. De fato, essa suavidade da 
  função $\sigma$ é um fato crucial, e não sua forma detalhada. A suavidade de $\sigma$ significa que pequenas mudanças
  $\Delta w_j$ nos pesos e $\Delta b$ no bias irão produzir uma pequena mudança $\Delta \mbox{output}$ na saída do neurônio.
  Aliás, nós podemos aproximar $\Delta \mbox{output}$ para  
<a class="displaced_anchor" name="eqtn5"></a>\begin{eqnarray} 
  \Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
  \Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b,
\tag{5}\end{eqnarray}

  Onde a soma é de todos os pesos, $w_j$, e  $\partial \,\mbox{output} / \partial w_j$ e $\partial \, \mbox{output} /\partial
  b$ denota a derivada parcial da saída $\mbox{output}$ com respeito a $w_j$ e $b$, respectivamente. Não entre
  em pânico se você não está familiarizado com derivadas parciais! A expressão acima parece complicada, com as 
  derivadas parciais, no entanto essa expressão está dizendo algo bastante simples: $\Delta\mbox{output}$ é uma
  <em>função linear</em> das mudanças $\Delta w_j$ e $\Delta w_j$ nos pesos e bias. Essa linearidade torna mais
  fácil escolher as pequenas mudanças nos pesos e biases que causam as mudanças desejadas na saída. Portanto, mesmo
  os neurônios sigmoid tendo um comportamento muito parecido com perceptrons, eles conseguem tornar o trabalho de
  descobrir como as mudanças nos pesos e biases estão influenciando a saída muito mais fácil.
</p>

<p>
  Se é o formato de $\sigma$ que realmente importa, e não é exatamente sua forma, então porque usar essa forma
  em particular para $\sigma$ na equação 
   <span id="margin_301539119283_reveal" class="equation_link">(3)
</span>
<span id="margin_301539119283" class="marginequation" style="display: none;">
  <a href="chap1.html#eqtn3" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
    \begin{eqnarray} 
  \sigma(z) \equiv \frac{1}{1+e^{-z}} \nonumber\end{eqnarray}</a></span>
  <script>$('#margin_301539119283_reveal').click(function() {$('#margin_301539119283').toggle('slow', function() {});});
  </script>? Na verdade, no decorrer do livro nós vamos ocasionalmente considerar neurônios onde a saída é
$f(w \cdot x + b)$ para alguma outra <em>função de ativação</em> $f(\cdot)$. O principal aspecto que muda ao usar
uma função de ativação diferente é que os valores em particular das equações diferenciais 
 <span id="margin_244684310360_reveal" class="equation_link">(5)</span><span id="margin_244684310360" class="marginequation" style="display: none;"><a href="chap1.html#eqtn5" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta \mbox{output} \approx \sum_j \frac{\partial \, \mbox{output}}{\partial w_j}
  \Delta w_j + \frac{\partial \, \mbox{output}}{\partial b} \Delta b \nonumber\end{eqnarray}</a></span><script>$('#margin_244684310360_reveal').click(function() {$('#margin_244684310360').toggle('slow', function() {});});</script>
  mudam. Acontece que nós calculamos as derivadas parciais depois, usando $\sigma$ nós vamos simplificar a algebra,
  pois exponenciais tem lindas características quando diferenciadas. Nesse caso, $\sigma$ é vastamente usada em 
  trabalhos de rede neural, e é a função de ativação que mais iremos usar nesse livro.
</p>
<p>
  Como nós devemos interpretar a saída de um neurônio sigmoid? Obviamente, uma grande diferença entre perceptrons
  e sigmoids é que neurônios sigmoids não tem como saída apenas $0$ e $1$. Eles podem ter como saída qualquer número
  real entre $0$ e $1$, portanto valores como $0.173\ldots$ e $0.689\ldots$ são valores de saída legítmos.
  Essaa característica é bem útil. por exemplo, se nós queremos usar o valor de saída para representar a intensidade
  média dos pixels de uma imagem de entrada para uma rede neural. Mas as vezes pode ser incômodo. Suponha que 
  nós queremos que a saída da rede indique se "a a imagem de entrada é um 9" ou "se a imagem de entrada não é um 9". 
  Obviamente, seria bem mais fácil fazer isso se a saída fosse apenas $0$ e $1$, como é em um perceptron. Mas em prática
  nós podemos estabelecer uma convenção para lidar com isso, por exemplo, se decidirmos interpretar qualquer saída que seja
  ao menos $0.5$ como indicando um "9", e qualquer saída menor que $0.5$ como indicando "não é um 9". Eu sempre
  irei dizer quando estivermos usando convenções assim para não causar nenhuma confusão.
</p>
<p>
<h4><a name="exercises_191892"></a><a href="#exercises_191892">Exercícios</a></h4><ul>
<li>
  <strong>Neurônios sigmoid simulando perceptrons, parte I</strong> $\mbox{}$ <br/>
  Suponha que pegamos todos os pesos e biases de uma rede de perceptrons, multiplicamos por uma constante
  positiva, $c > 0$. Mostre que o comportamento da rede não irá mudar.
</p>
<p>
  <li><strong>Neurônios sigmoid simulando perceptrons, parte II<</strong> $\mbox{}$
  <br/>
  Suponha que nós temos o mesmo context do problema anterior - uma rede de perceptrons. Suponha também que 
  a entrada geral da rede de perceptrons já foi escolhida. Nós não iremos precisar do valor de entrada em si, 
  nós iremos apenas precisar que a entrada esteja fixada. Suponha que os pesos e biases são valores tais que
  $w \cdot x + b \neq 0$ para uma entrada $x$ para qualquer neurônio em particular. Agora substitua todos os
  perceptrons da rede por neurônios sigmoid, e multiplique os pesos e biases por uma constante positiva $c > 0$.  
  Mostre que no limite $c \rightarrow \infty$ o comportamento da rede de neurônios sigmoid é o mesmo da rede
  de perceptrons. Como isso poderia falhar quando $w \cdot x + b = 0$ para um dos perceptrons?
  </ul>
</p>
<p>
  <h3>
    <a name="the_architecture_of_neural_networks"></a><a href="#the_architecture_of_neural_networks">A arquitetura de redes neurais</a>
  </h3>
</p>
<p>
  Nessa próxima sessão eu irei introduzir uma rede neural que classifica digitos manuscritos. Em preparação para 
  isso, ajuda se nós olharmos um pouco da terminologia que permite nomear difetentes partes de uma rede. Suponha
  que temos a rede:
<center>
<img src="images/tikz10.png"/>
</center>
  Como mencionado anteriormente, a camada mais a esquerda dessa rede é chamada de camada de entrada, e os neurônios
  pertencentes a essa camada são chamados de <em>neurônios de entrada</em>. A camada mais a direita ou <em>camada
  de saída</em> contém os <em>neurônios de saída</em>, ou, nesse caso, um único neurônio de saída. A camada do meio
  é chamada <em>camada escondida</em>, já que os neurônios dessa camada não são nem de entrada ou saída. O termo
  "escondida" talvez soe um pouco misterioso - a primeira vez que eu escutei esse termo eu pensei que tivesse 
  algo profundamente filosófico ou matemático escondido nesses neurônios - mas na real não significa nada além de
  "não é nem entrada nem saída". A rede acima tem apenas uma camada escondida, mas em algumas redes nós temos multiplas
  camadas escondidas. Por exemplo, a seguinte rede de quatro camadas tem duas camadas escondidas:
<center>
<img src="images/tikz11.png"/>
</center>
  Um pouco confuso, e por razões históricas, essas redes de múltiplas camadas são chamadas <em>multilayer perceptrons</em>
  ou <em>perceptrons de múltiplas camadas</em> para abreviar <em>MLPs</em>, apesar de elas serem feitas de neurônios
  sigmoid, e não perceptrons. Eu não irei usar a terminologia das MLPs nesse livro, pois eu penso que é confuso,
  mas eu gostaria de alertar você da existência dessa terminologia.
</p>
<p>
  O design das camadas de entrada e saída das redes é na maioria das vezes bem direta. Por exemplo, suponha que
  nós estamos tentando determinar se uma imagem manuscrita é um "9" ou não. O modo mais natural de fazer essa rede
  é codificar as intensidades dos pixels da imagem para os neurônios de entrada. Se uma imagem tem dimensões $64$
  por $64$ e é preto e branca, então nós temos $4,096 = 64 \times 64$ neurônios de entrada com intensidades em escalas
  que estão entre $0$ e $1$. A camada de saída irá conter apenas um neurônio, com valores de saída menores do que
  $0.5$ indicando "a imagem de entrada não é um 9", e valores maiores do que $0.5$ indicando "a imagem de entrada
  é um 9".
</p>
<p>
</p>
<p>
</p>
<p>
  Enquanto o design das camadas de entrada e de saída de uma rede neural é na maioria das vezes bem direta,
  o design das camadas escondidas - <i>hidden layers</i> - por sua vez, tem aspectos que podem ser considerados 
  artísticos. Em particular, não é possível resumir o processo de fazer o design de hidden layers com uma simples
  regra ou método. Envés disso, pesquisadores de redes neurais desenvolveram diversos designs para as camadas escondidas,
  de modo que se possa conseguir o comportamento desejado para sua rede. Por exemplo, esses designs podem ser usados
  para determinar como decidir-se quanto a relação entre o tempo de treino de uma determinada rede e seu número de camadas.
  Nós iremos encontrar vários desses designs ao longo desse livro.
</p>

<p>
  Até agora, nós temos discutido redes neurais onde a saída de uma camada é usada serve como entrada da próxima camada.
  Essas redes são chamadas de <em>feedforward neural networks</em> ou <em>redes neurais feedfoward</em>. Isso significa
  que não a loop na rede - a informação é sempre passada para frente, nunca para trás. Se nós tivéssemos loops,
  nós acabaríamos em situações onde a entrada da função $\sigma$ depende da saída. E isso é díficil de se lidar,
  portanto nós não permitimos a existência desses loops.
</p>
<p>
  No entanto, existem outros modelos de redes de neurônios artificiais onde loops de feedback são possíveis.
  Esses modelos são chamados 
<a href="http://en.wikipedia.org/wiki/Recurrent_neural_network">
  redes neurais recorentes
  </a>. 
  A ideia desses modelos é ter neurônios que disparam em uma duração limitada de tempo, antes de ficarem em 
  repouso. Esse disparo pode estimular outros neurônios, que talvez disparem também um pouco depois, também por
  um tempo limitado. Isso faz ainda mais neurônios dispararem, e então com o tempo nós temos uma reação em cadeia
  de neurônios disparando. Loops não causam problemas em modelos como esse, já que a saída de um neurônio
  só afeta a sua entrada depois de um tempo, não instantaneamente. 
 </p>
 <p>
 </p>
 <p>
   Redes neurais recorentes tem sido menos influentes que redes feedfoward, em parte porque os algoritimos
   de aprendizado para redes recorentes são menos poderosas. Mas mesmo assim,redes recorentes são extremamente
   interessantes. Elas estão muito mais próximas do modo como o nosso cérebro realmente funciona se comparado
   com redes feedfoward. E em alguns casos, redes recorentes podem resolver de forma mais eficiente alguns 
   problemas do que redes feedfoward. No entanto, para limitar o nosso escopo, nesse livro nós iremos nos
   concentrar nas, amplamente mais utilizadas, redes feedfoward.
</p>
<p>
  <h3>
    <a name="a_simple_network_to_classify_handwritten_digits"></a>
    <a href="#a_simple_network_to_classify_handwritten_digits">
      Uma rede simples para classificar dígitos manuscritos
    </a>
  </h3>
</p>
  <p>
    Tendo definido o que são redes neurais, vamos retornar ao reconhecimento de digitos manuscritos.
    Nós podemos dividir o problema de reconhecer digitos em dois sub problemas. Primeiro, precisamos
    quebrar uma imagem contendo multiplos digitos em uma sequencia de imagens separadas contendo, cada
    uma, contendo apenas um dígito. Por exemplo, nós gostariamos de quebrar a imagem 
  </p>
  <p>
    <center>
      <img src="images/digits.png" width="300px">
    </center>
  </p>
  <p>
    em seis imagens separadas, 
  </p>
  <p>
    <center>
      <img src="images/digits_separate.png" width="440px">
    </center> 
  </p>
  <p>
    Nós humanos resolvemos esse <em>problema de segmentação</em> com facilidade, mas é desafiador para
    um programa de computador para quebrar uma imagem assim corretamente. Após a imagem ser segmentada,
    o programa então precisa classificar cada dígito individual. Então, por exemplo, nós gostariamos que
    o nosso programa fosse capaz de reconhecer o primeiro dígito acima,
  </p>
<p>
  <center>
    <img src="images/mnist_first_digit.png" width="64px">
  </center>
</p>
<p>
  é um 5.
</p>
<p>
  Nós iremos focar em escrever um programa para resolver o segundo problema, que é, classificar os
  dígitos individuais. Nós iremos fazer isso porque o problema de segmentação não é tão difícil de 
  resolver. Existem várias formas de abordar o problema de segmentação. Uma dessas abordagens é tentar
  várias diferentes formas de segmentar a imagem, usando um dígito individual para classificar os pontos
  de cada tentativa de segmentação. Uma tentativa de segmentação ganha uma pontuação alta se o dígito 
  individual de classificador está de acordo com sua classificação em todos os segmentos, e uma pontuação
  baixa se o classificador está tendo muitos problemas em um ou mais segmentos. A ideia é se o classificador
  está tendo problema em algum lugar, então é provável que esteja tendo esse problema porque a segmentação
  foi escolhida incorretamente. Essa ideia e outras variações podem ser usadas para resolver o problema da
  segmentação de forma satisfatória. Então envés de se preocupar com a segmentação nós iremos nos preocupar
  com um problema mais interessante e difícil, chamado, reconhecimento de dígitos manuscrítos individuais.

</p>
<p>
  Para reconhecer um dígito individual nós iremos usar uma rede neural de três camadas:
</p>
<p>
  <center>
    <img src="images/tikz12.png"/>
  </center>
</p>
<p>
  A camada de entrada da rede contém neurônios codificando os valores de entradas dos pixels de entrada.
  Como discutido na seção anterior, nossos dados de treino para a rede consiste de várias imagens de 
  $28$ por $28$ pixels de dígitos manuscritos escaneados, e portanto a camada de entrada contém $784 = 28
  \times 28$ neurônios. Por questão de simplicidade eu omiti grande parte dos $784$ neurônios de entrada no
  diagrama acima. Os pixels de entrada são preto e branco, com o valor $0.0$ representando brancho, e o valor
  de $1.0$ representando preto, e os valores entre, representam os diferentes tons de cinza.
</p>
<p>
  A segunda camada da rede é uma camada escondida. Nós denotamos o número de neurônios nessa camada escondida
  por $n$, e nós iremos experimentar com diferentes valores para $n$. O exemplo ilustra uma pequena camada
  escondida, contendo apenas $n = 15$ neurônios.
</p>
<p>
  A camada de saída da rede contém 10 neurônios. Se o primeiro neurônio dispara, i.e., tem a saída $\approx 1$,
  então isso indica que a rede acha que o dígito é um $0$. Se o segundo neurônio dispara então isso indica
  que a rede acha que o dígito é um $1$. E por aí vai. Sendo um pouvo mais preciso, nós numeramos os neurônios de 
  saída de $0$ a $9$, e vemos qual neurônio tem o maior valor de ativação. Se esse neurônio for o neurônio número
  $6$ por exemplo, então a rede acha que o dígito de entrada é um $6$. E a mesma coisa vale para os outros neurônios.

</p>
<p>
  Talvez você esteja se perguntando porque nós usamos $10$ neurônios de saída. Afinal,o objetivo da rede é dizer
  que dígito ($0, 1, 2, \ldots, 9$) corresponde a imagem de entrada. Um jeito natural de fazer isso é usar apenas
  $4$ neurônios de saída, tratando cada neurônio como se estivesse recebendo um valor binário, dependendo se a saída
  do neurônio é próxima de $0$ ou de $1$. Quatro neurônios são suficientes para codificar a resposta, já que 
  $2^4 = 16$ é mais do que 10 valores possíveis de entrada de dígitos. Porque usar uma rede que usa $10$ neurônios 
  então? Não seria ineficiente? A justificativa é empírica: nós podemos testar ambos os designs, mas acontece que,
  para esse problema em particular, a rede de $10$ neurônios de saída aprende a reconhecer dígitos melhor do que a
  rede de $4$ dígitos de saída. Mas isso deixa a dúvida, <em>porque</em> usar $10$ neurônios é melhor. Existe alguma
  heurística que poderia nos dizer adiantado se nós devemos usar $10$ neurônios de saída ou $4$?
</p>
<p>
  Para entender o porquê de nós fazermos isso, ajuda pensar sobre o que a rede neural está fazendo desde os
  primeiros princípios. Considere o primeiro caso onde nós usamos $10$ neurônios de saída. Vamos concentrar
  no primeiro neurônio de saída, o que está tentando decidir se o dígito é um ou não um $0$. Ele faz isso
  pesando as evidências fornecidas pela camada escondida de neurônios. E o que esses neurônios escondidos estão
  fazendo? Bem, apenas suponha em prol do argumento que que o primeiros neurônio na camada escondida detecta
  se uma imagem é ou não como essa:
</p>
<p>
  <center>
    <img src="images/mnist_top_left_feature.png" width="130px">
  </center>
</p>
<p>
  Ele faz isso pesando intensamente os pixels de entrada que sobrepõem com a imagem, e pesando de leve as 
  outras entradas. De maneira similar, vamos supor que em prol do argumento que o segundo, terceiro, e quarto
  neurônio na camada escondida detectam se as seguintes imagens estão presentes:
</p>
<p>
  <center>
    <img src="images/mnist_other_features.png" width="424px">
  </center>
</p>
<p>
  Como você já deve ter advinhado, essas quatro imagens juntas formam a imagem do $0$ que nós vimos na linha
  de dígitos mostrado <a href="#complete_zero">anteriormente</a>:
</p>
<p>
  <center>
    <img src="images/mnist_complete_zero.png" width="130px">
  </center>
</p>
<p>
  Portanto, se todos esses quatro neurônios escondidos estão disparando então podemos concluir que o dígito é
  um $0$. Claro, não são <em>apenas</em> esses tipos de evidências que nós podemos usar para concluir que
  a imagem é um $0$ - nós poderiamos classificar esse $0$ de diferentes outras formas (digamos, através 
  de tranlações das imagens acima, ou leves distorções). Mas parece ser mais seguro dizer que ao menos nesse caso
  nós concluímos que a saída era um $0$.
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
  Supondo que redes neurais funcionam desse modo, nós podemos dar uma explicação plausível para o porquê de ser
  melhor ter uma rede com $10$ saídas do que uma com $4$, então o primeiro neurônio de saída estaria tentando 
  decidir qual era o bit mais importante do dígito. E não tem jeito fácil de relacionar esse dígito mais importante
  com formas simples como as mostradas acima. É difícil imaginar que exista alguma boa razão histórica para que
  as formas que compõem o dígito sejam intimamente relacionadas (digamos) ao bit mais significante na saída. 
</p>
<p>
  Agora, com tudo isso dito, isso tudo é apenas uma heurística. Nada diz que essa rede neural de três camadas
  tem que operar dessa maneira descrita, com os neurônios escondidos (aqueles das camadas entre a saída e a entrada)
  detectando formas componentes simples. Talvez a algoritimo de aprendizado inteligente irá achar alguma atribuição
  de pesos que permita nós usarmos apenas $4$ neurônios de saída. Mas como uma heurística a maneira de pensar que eu
  descrevi funciona bem, e pode te salvar um bom tempo na hora de fazer o bons designs de rede neurais.
</p>
<p>
  <h4>
    <a name="exercise_513527"></a>
    <a href="#exercise_513527">Exercícios</a>
  </h4>
  <ul>
    <li>
      Existe uma forma de determinar a representação em bitwise de um dígito através da adição de uma camada extra
      na rede de três camadas cima. A camada extra converte a saída da camada anterior para uma representação binária,
      como ilustrado na figura abaixo. Encontre um conjunto de pesos e biases para a nova camada de saída. Assuma que
      as $3$ primeiras camadas de neurônios são tais que a saída correta na terceira camada (i.e., a antiga camada de 
      saída) tem uma ativação de pelo menos $0.99$, e as saídas incorretas tem ativação de menos que $0.01$.
  </ul>
</p>
<p>
  <center>
    <img src="images/tikz13.png"/>
  </center>
</p>
<p>
</p>
<p>
</p>
<p>
</p>
<p>
  <h3>
    <a name="learning_with_gradient_descent">
    </a>
    <a href="#learning_with_gradient_descent">
      Learning with gradient descent
    </a>
  </h3>
</p>
<p>
</p>
<p>
  Agora que nós temos um design para a nossa rede neural, como ela pode aprender a reconhecer dígitos? A primeira
  coisa que nós iremos precisar é um data set de onde aprender - um data set de treino. Nós iremos usar o 
   <a href="http://yann.lecun.com/exdb/mnist/">
    data set MNIST
   </a>, 
  que contém dezenas de milhares de imagens escaneadas de dígitos manuscritos, junto com com suas classificações
  corretas. O nome MNIST vem do fato que um um subset modificado de dois data sets coletados pelo 
  <a href="http://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology">NIST</a>,
  Instituto Nacional de Padrões e Tecnologia dos EUA. Aqui estão algumas imagens do MNIST:

</p>
<p>
  <center>
    <img src="images/digits_separate.png" width="420px">
  </center> 
</p>
<p>
  Como você pode ver, esse dígitos são na verdade os mesmos daqueles mostrados <a href="#complete_zero">no começo desse capítulo</a>
  como um desafio para reconhecer. Claro que, quando estivermos testando nossa rede, nós iremos pedir para ela reconhecer
  dígitos que não estão no set de treino!
</p>
 <p>
   O data set MNIST vem em duas partes. A primeira parte contém 60,000 imagens para serem usadas como dados de treino.
   Essas imagens são escaneadas de amostras manuscritas de 250 pessoas, das quais metade são funcionários 
   do Census Federal dos EUA, e a outra metade são estudantes do ensino médio. As imagens são em preto e branco de 
   28 por 28 pixels de tamanho. Nós iremos usar os dados de teste para avaliar o quão bem nossa rede neural aprendeu
   a reconhecer dígitos. Para fazer um bom teste de perfomance, os dados de teste foram coletados de pessoas <em>diferentes</em>
   daquelas 250 que forneceram os dados de treino. Isso ajuda a nós dar confiança de que o nosso sistema pode reconhecer
   dígitos de pessoas que ela nunca teve contato com a escrita.
.</p>
<p>
  Nós iremos usar a notação $x$ para denotar entrada de teste. Será conveniente considerar cada input de treino $x$ como um vetor de
  dimensão $28 \times 28 =784$. Cada entrada no vetor representa o valor cinza para um único pixel da imagem. Nós iremos denotar a saída
  desejada correspondente por $y = y(x)$, onde $y$ é um vetor de dimensão $10$. Por exemplo, se uma imagem de treino em particular, $x$
  representa um $6$, então $y(x) = (0, 0, 0, 0, 0, 0, 1, 0, 0, 0)^T$ é a saída desejada da rede. Note que, $T$ é a operação de transposição
  tornando o vetor linha em um vetor coluna.
</p>
<p>
  Oque nós gostariamos é um algoritmo que nos permita encontrar os pesos e biases de forma que a saída da nossa rede
  se aproxime de $y(x)$ para todos as entradas de treino $x$. Para quantificar o quão bem nós atingimos esse objetivo
  nós definimos uma <em>função custo</em>* 
  <span class="marginnote"> 
    *Algumas vezes nos referimos a ela como função <em>perda</em> ou <em>objetivo</em>. Nós usamos o termo função custo ao 
    longo desse livro, mas você deveria ter em mente essas outras terminologias, já que é usada com frequência em artigos
    de pesquisa e outras disscuções relacionadas a redes neurais. 
  </span>: 
<a class="displaced_anchor" name="eqtn6"></a>\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2.
\tag{6}\end{eqnarray}
Nesta equação, $w$ denota a coleção de todos os pesos na rede, $b$ todos os biases, $n$ é o número total de entradas de
treino, $a$ é o vetor de saídas da rede quando $x$ é a entrada, e a soma é sobre todos as entradas de treino, $x$. Claro,
a saída $a$ depende de $x$, $w$ e $b$, mas para manter a notação simples eu não explicitamente indiquei essa dependência.
A notação $\| v \|$ apenas denota o tamanho usual da função para um determinado vetor $v$. Nós iremos chamar $C$ de função
de custo <em>quadrática</em>; também é conhecida como o<em>erro médio ao quadrado</em> ou apenas <em>MSE(mean squared error)</em>.
Inspecionando a forma da função de custo quadrática, nós vemos que $C(w, b)$ é não negativo, já que todo termo da soma é não 
negativo. Além disso, o custo $C(w, b)$ se torna menor, i.e., $C(w, b) \approx 0$, exatamente quando $y(x)$ é aproximadamente
igual a saída, $a$, para todos os valores de entrada, $x$. Então nosso algoritmo de treino faz um bom trabalho se ele consegue
achar os pesos e biases de modo que $C(w,b) \appox 0$. Em contraste, ele não está fazendo um bom trabalho se $C(w, b)$ é grande
- isso significaria que $y(x)$ não está próximo da saída $a$ para uma grande parte das entradas. Então o objetivo do nosso algoritmo
de treino será minimizar a função custo $C(w, b)$ como um função em termos dos pesos e biases. Em outras palavras, nós queremos
achar o conjunto de pesos e biases que faça a função custo assumir o menor valor possível. Nós fazemos isso usando um algoritimo
chamado <em>gradiente descendente</em>.
</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>
<p>
  Porque introduzir a função quadrática? Afinal, não seria o interesse primário no número de imagens classificadas corretamente
  pela rede? Porque não tentar maximizar esse número diretamente, envés de minimizar um valor indireto como o custo quadrático?
  O problema com isso é que o número de imagens corretamente classificadas não é uma função suave dos pesos e biases da rede. Na
  maioria das vezes, fazer pequenas mudanças nos pesos e biases não irá causar nenhuma mudança no número de imagens de treino
  classificadas corretamente. Isso torna difícil descobrir como as mudanças nos pesos e biases estão afetando o desempenho da nossa
  rede, e portanto, fica difícil descobrir como nós podemos mudar esses pesos e biases de modo que melhore o desenpenho. Usando uma
  função suave, como a função custo quadrático, torna-se mais fácil o trabalho de descobrir como fazer pequenas mudanças nos pesos 
  e biases para melhorar o custo. Por conta disso que nós focamos primeiramente em minimizar o custo quadrático, e apenas depois nós
  examinamos a precisão de classificação.  
</p>
<p></p>
<p>
  Mesmo já definido que nós iremos usar uma função de custo suave, talvez você ainda se pergunte, porque nós escolhemos a função quadrática
  usada na equação
<span id="margin_368924667121_reveal" class="equation_link">(6)</span>
<span id="margin_368924667121" class="marginequation" style="display: none;">
  <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">
    \begin{eqnarray}  C(w,b) \equiv\frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}
  </a>
</span>
<script>$('#margin_368924667121_reveal').click(function() {$('#margin_368924667121').toggle('slow', function() {});});</script>.  
Não seria essa escolha <em>ad hoc</em>? Talvez, se escolhida uma função custo diferente nós teríamos um conjunto de pesos e biases minimizados
completamente diferente? Essa é uma preocupação válida, mais tarde no livro iremos revisitar a função custo, e faremos algumas modificações. 
No entanto, a função de custo quadrática da equação 
<span id="margin_77007455211_reveal" class="equation_link">
  (6)
</span>
<span id="margin_77007455211" class="marginequation" style="display: none;">
  <a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_77007455211_reveal').click(function() {$('#margin_77007455211').toggle('slow', function() {});});</script> 

funciona perfeitamente bem para entender os basicos de aprendizado em uma rede neural, tão bem que nós iremos nos ater a ela por enquanto.
</p>
<p>
  Recapitulando, nosso objetivo é treinar uma rede neural para encontrar os pesos e biases que minimizam a função de custo quadrático
  $C(w, b)$. Esse é um problema bem posto, mas existem muitas estruturas que podem causar distração na forma como o problema está posto 
  atualmente - a interpretação de $w$ e $b$ como pesos e biases, a função $\sigma$ sendo utilizada no background, a escolha da arquitetura
  da rede, MNIST, e assim vai. Acontece que nós podemos entender muito apenas ignorando boa parte dessa estrutura, e concentrando na parte
  da minimização. Nós iremos desenvolver uma técnica chamada <em>gradiente descendente</em> que nós podemos usar para resolver esses problemas. 
  Então iremos voltar para a função específica que queremos minimizar para redes neurais.
</p> 
<p>
  Certo, vamos supor que estamos tentando minimizar uma função, $C(v)$. Essa poderia ser qualquer função de valor real de muitas variáveis,
  #v = v_1, v_2, \ldots$. Note que eu coloquei a notação de $w$ e $b$ como $v$ para enfatizar que essa poderia ser qualquer função - nós não
  estamos mais pensando no contexto específico de redes neurais dessa vez. Para minimizar $C(v)$ ajuda se imaginarmos $C$ como uma função de 
  apenas duas variáveis, que nós iremos chamar $v_1$ e $v_2$:
</p> 
<p>
  <center>
    <img src="images/valley.png" width="542px">
  </center>
</p>
<p>
  O que nós gostaríamos de achar é onde $C$ atinge seu mínimo global. Agora, para a função que plotamos acima, nós podemos procurar a olho nu
  o mínimo da função. Nesse sentido, Talvez eu tenha mostrado essa função de maneira <em>muito</em> simples! Uma função geral, $C$, pode ser
  uma função complicada de muitas variáveis, e normalmente não será possível apenas achar o mínimo da função olhando pro gráfico a olho nu.  
</p>
<p>
  Uma maneira de abordar esse problema é usando cálculo para tentar achar o mínimo analiticamente. Nós poderíamos calcular as derivadas e então
  tentar usar elas para achar os lugares em $C$ que são extremos. Com um pouco e sorte talvez funcione quando $C$ é uma função de apenas uma ou 
  várias variáveis. Mas irá se tornar um pesadelo quando nós temos muitas variáveis. E para redes neurais quase sempre nós iremos trabalhar com
  <em>muitas</em> variáveis - a maior rede neural tem funções custo que dependem de bilhões de pesos e biases. Usando cálculo para minimizar essa
  função simplemente não funcionaria.
</p>
<p>
  (Após definido que nós iriamos ganhar entendimento se imaginassemos $C$ como uma fução de apenas duas variáveis, eu voltei atrás duas vezes
  em dois parágrafos e disse "ei, mas e se for uma função de mais de duas variáveis?" desculpa por isso. Por favor acredite em mim quando digo 
  que realmente ajuda se nós imaginarmos $C$ como uma função de duas variáveis. Só ocorre que algumas vezes essa abordagem quebra e nos dois 
  últimos parágrafos nós estamos lidando com isso. Um bom pensamento matemático muitas vezes envolve trabalhar com várias abordagens intuitivas,
  aprendendo quando é mais apropriado usar cada abordagem, e quando não é.)
</p>
<p>
  <a name="gradient_descent"></a>
</p>
<p>
  Certo, então cálculo não funciona. Felizmente, exite outra linda analogia que sugere um algoritimo que funciona muito bem. Nós começamos
  pensando na nossa função como se fosse um vale. Se você olhar bem um pouco para o plot acima, não deve ser tão difícil. Nossa experiência
  do dia a dia diz que uma bola vai eventualmente rolar para o fundo de um vale. Será que nós poderiamos usar essa ideia para achar o mínimo da
  função? Nós aleatóriamente escolhemos um ponto inicial para uma bola (imaginária), e então simulamos a movimentação da bola quando ela rola para
  o fundo do vale. Nós poderiamos fazer essa simulação simplesmente calculando as derivadas (e talvez algumas segundas derivadas) de $C$ - essas 
  derivadas que irão nos dizer tudo que nós precisamos saber sobre a "forma" de um determinado local desse vale, e portanto como nossa bola deve 
  rolar.
</p>
<p>
  Basseado no que eu acabei de escrever, você deve supor que nós iremos tentar escrever as equações de movimento de uma bola de Newton, considerando
  os efeitos de atrito, gravidade e etc. Na verdade, nós não iremos tomar a analogia da bola rolando tão sério assim - nós estamos desenvolvendo um 
  algoritmo para minimizar $C$, e não desenvolvendo uma simulação de leis da física! A visão da bola rolando é apenas um meio de estimular a sua 
  imaginação, e não limitar o seu pensamento. Então envés de entrar nos detalhes da física, vamos simplismente nós perguntar: se nós fossemos deus por
  um dia, e pudessemos fazer nossas próprias leis da física, ditando como a bola iria rolar, que lei ou leis do movimento nós poderiamos pegar que faria
  com que a bola movesse para o fundo do vale?
</p>
<p>
  Para tornar essa pergunta mais precisa, vamos pensar sobre o que acontece quando nós movemos a bola pequenas quantidades $\Delta v_1$ na direção $v_1$,
  e uma pequena quantidade $\Delta v_2$ na direção $v_2$. O cálculo nos di\ que $C$ muda da seguinte maneira:
<a class="displaced_anchor" name="eqtn7"></a>\begin{eqnarray} 
  \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
  \frac{\partial C}{\partial v_2} \Delta v_2.
\tag{7}\end{eqnarray}
Nós iremos encontrar uma maneria de escolher $\Delta v_1$ e $\Delta v_2$ de forma que faça $\Delta C$ negativo; i.e., nós iremos escolher eles de forma que a 
bola role para o fundo do vale. Para entender como fazer tal escolha ajuda se definirmos %\Delta v$ como sendo o vetor das mudanças em $v$, $\Delta v \equiv 
(\Delta v_1, \Delta v_2)^T$, onde $T$ novamente é o operador de transposição, tornando vetores linha em vetores coluna. Nós iremos definir também o <em>gradiente</em>
de $C$ como sendo um vetor das derivadas parciais, $\left(\frac{\partial C}{\partial v_1}, \frac{\partial C}{\partial v_2}\right)^T$. Denotamos o gradiente como sendo
$\nabla C$, i.e.:
<a class="displaced_anchor" name="eqtn8"></a>\begin{eqnarray} 
  \nabla C \equiv \left( \frac{\partial C}{\partial v_1}, 
  \frac{\partial C}{\partial v_2} \right)^T.
\tag{8}\end{eqnarray}

Daqui a pouco iremos rescrever a mudança $\Delta C$ em termos de $\Delta v$ e de do gradiente, $\nabla C$. Antes de fazermos isso, eu quero deixar claro uma coisa que as vezes
confunde as pessoas quanto ao gradiente. Quando as pessoas encontram a notação $\nabla C$ pela primeira vez, as pessoas as vezes se preguntam, o que $\nabla$ realmente significa?
Na verdade, é perfeitamente tranquilo de pensar em $\nabla C$ como sendo um objeto matemático singular - o vetor definido acima - que por acaso está sendo escrito usando dois simbolos.

In a moment we'll rewrite the change $\Delta C$ in terms of $\Delta v$
and the gradient, $\nabla C$.  Before getting to that, though, I want
to clarify something that sometimes gets people hung up on the
gradient.  When meeting the $\nabla C$ notation for the first time,
people sometimes wonder how they should think about the $\nabla$
symbol.  What, exactly, does $\nabla$ mean?  In fact, it's perfectly
fine to think of $\nabla C$ as a single mathematical object - the
vector defined above - which happens to be written using two
symbols.  In this point of view, $\nabla$ is just a piece of
notational flag-waving, telling you "hey, $\nabla C$ is a gradient
vector".  There are more advanced points of view where $\nabla$ can
be viewed as an independent mathematical entity in its own right (for
example, as a differential operator), but we won't need such points of
view.</p><p>With these definitions, the expression <span id="margin_60068869945_reveal" class="equation_link">(7)</span><span id="margin_60068869945" class="marginequation" style="display: none;"><a href="chap1.html#eqtn7" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \frac{\partial C}{\partial v_1} \Delta v_1 +
  \frac{\partial C}{\partial v_2} \Delta v_2 \nonumber\end{eqnarray}</a></span><script>$('#margin_60068869945_reveal').click(function() {$('#margin_60068869945').toggle('slow', function() {});});</script> for
$\Delta C$ can be rewritten as
<a class="displaced_anchor" name="eqtn9"></a>\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v.
\tag{9}\end{eqnarray}
This equation helps explain why $\nabla C$ is called the gradient
vector: $\nabla C$ relates changes in $v$ to changes in $C$, just as
we'd expect something called a gradient to do.  But what's really
exciting about the equation is that it lets us see how to choose
$\Delta v$ so as to make $\Delta C$ negative.  In particular, suppose
we choose
<a class="displaced_anchor" name="eqtn10"></a>\begin{eqnarray} 
  \Delta v = -\eta \nabla C,
\tag{10}\end{eqnarray}
where $\eta$ is a small, positive parameter (known as the
<em>learning rate</em>).
Then Equation <span id="margin_777394057862_reveal" class="equation_link">(9)</span><span id="margin_777394057862" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_777394057862_reveal').click(function() {$('#margin_777394057862').toggle('slow', function() {});});</script> tells us that $\Delta C \approx -\eta
\nabla C \cdot \nabla C = -\eta \|\nabla C\|^2$.  Because $\| \nabla C
\|^2 \geq 0$, this guarantees that $\Delta C \leq 0$, i.e., $C$ will
always decrease, never increase, if we change $v$ according to the
prescription in <span id="margin_387482875009_reveal" class="equation_link">(10)</span><span id="margin_387482875009" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_387482875009_reveal').click(function() {$('#margin_387482875009').toggle('slow', function() {});});</script>.  (Within, of course, the
limits of the approximation in Equation <span id="margin_602571566970_reveal" class="equation_link">(9)</span><span id="margin_602571566970" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_602571566970_reveal').click(function() {$('#margin_602571566970').toggle('slow', function() {});});</script>).  This is
exactly the property we wanted!  And so we'll take
Equation <span id="margin_129183303476_reveal" class="equation_link">(10)</span><span id="margin_129183303476" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_129183303476_reveal').click(function() {$('#margin_129183303476').toggle('slow', function() {});});</script> to define the "law of motion"
for the ball in our gradient descent algorithm.  That is, we'll use
Equation <span id="margin_734088671290_reveal" class="equation_link">(10)</span><span id="margin_734088671290" class="marginequation" style="display: none;"><a href="chap1.html#eqtn10" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta v = -\eta \nabla C \nonumber\end{eqnarray}</a></span><script>$('#margin_734088671290_reveal').click(function() {$('#margin_734088671290').toggle('slow', function() {});});</script> to compute a value for $\Delta
v$, then move the ball's position $v$ by that amount:
<a class="displaced_anchor" name="eqtn11"></a>\begin{eqnarray}
  v \rightarrow v' = v -\eta \nabla C.
\tag{11}\end{eqnarray}
Then we'll use this update rule again, to make another move.  If we
keep doing this, over and over, we'll keep decreasing $C$ until - we
hope - we reach a global minimum.</p><p>Summing up, the way the gradient descent algorithm works is to
repeatedly compute the gradient $\nabla C$, and then to move in the
<em>opposite</em> direction, "falling down" the slope of the valley.
We can visualize it like this:</p><p><center><img src="images/valley_with_ball.png" width="542px"></center></p><p>Notice that with this rule gradient descent doesn't reproduce real
physical motion.  In real life a ball has momentum, and that momentum
may allow it to roll across the slope, or even (momentarily) roll
uphill.  It's only after the effects of friction set in that the ball
is guaranteed to roll down into the valley.  By contrast, our rule for
choosing $\Delta v$ just says "go down, right now".  That's still a
pretty good rule for finding the minimum!</p><p>To make gradient descent work correctly, we need to choose the
learning rate $\eta$ to be small
enough that Equation <span id="margin_693595312216_reveal" class="equation_link">(9)</span><span id="margin_693595312216" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_693595312216_reveal').click(function() {$('#margin_693595312216').toggle('slow', function() {});});</script> is a good approximation.  If
we don't, we might end up with $\Delta C > 0$, which obviously would
not be good!  At the same time, we don't want $\eta$ to be too small,
since that will make the changes $\Delta v$ tiny, and thus the
gradient descent algorithm will work very slowly.  In practical
implementations, $\eta$ is often varied so that
Equation <span id="margin_763885870077_reveal" class="equation_link">(9)</span><span id="margin_763885870077" class="marginequation" style="display: none;"><a href="chap1.html#eqtn9" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_763885870077_reveal').click(function() {$('#margin_763885870077').toggle('slow', function() {});});</script> remains a good approximation, but the
algorithm isn't too slow.  We'll see later how this
works. </p><p>I've explained gradient descent when $C$ is a function of just two
variables.  But, in fact, everything works just as well even when $C$
is a function of many more variables.  Suppose in particular that $C$
is a function of $m$ variables, $v_1,\ldots,v_m$.  Then the change
$\Delta C$ in $C$ produced by a small change $\Delta v = (\Delta v_1,
\ldots, \Delta v_m)^T$ is
<a class="displaced_anchor" name="eqtn12"></a>\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v,
\tag{12}\end{eqnarray}
where the gradient $\nabla C$ is the vector 
<a class="displaced_anchor" name="eqtn13"></a>\begin{eqnarray}
  \nabla C \equiv \left(\frac{\partial C}{\partial v_1}, \ldots, 
  \frac{\partial C}{\partial v_m}\right)^T.
\tag{13}\end{eqnarray}
Just as for the two variable case, we can
choose
<a class="displaced_anchor" name="eqtn14"></a>\begin{eqnarray}
  \Delta v = -\eta \nabla C,
\tag{14}\end{eqnarray}
and we're guaranteed that our (approximate)
expression <span id="margin_796021234053_reveal" class="equation_link">(12)</span><span id="margin_796021234053" class="marginequation" style="display: none;"><a href="chap1.html#eqtn12" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \Delta C \approx \nabla C \cdot \Delta v \nonumber\end{eqnarray}</a></span><script>$('#margin_796021234053_reveal').click(function() {$('#margin_796021234053').toggle('slow', function() {});});</script> for $\Delta C$ will be negative.
This gives us a way of following the gradient to a minimum, even when
$C$ is a function of many variables, by repeatedly applying the update
rule
<a class="displaced_anchor" name="eqtn15"></a>\begin{eqnarray}
  v \rightarrow v' = v-\eta \nabla C.
\tag{15}\end{eqnarray}
You can think of this update rule as <em>defining</em> the gradient
descent algorithm.  It gives us a way of repeatedly changing the
position $v$ in order to find a minimum of the function $C$.  The rule
doesn't always work - several things can go wrong and prevent
gradient descent from finding the global minimum of $C$, a point we'll
return to explore in later chapters.  But, in practice gradient
descent often works extremely well, and in neural networks we'll find
that it's a powerful way of minimizing the cost function, and so
helping the net learn.</p><p></p><p></p><p>Indeed, there's even a sense in which gradient descent is the optimal
strategy for searching for a minimum.  Let's suppose that we're trying
to make a move $\Delta v$ in position so as to decrease $C$ as much as
possible.  This is equivalent to minimizing $\Delta C \approx \nabla C
\cdot \Delta v$.  We'll constrain the size of the move so that $\|
\Delta v \| = \epsilon$ for some small fixed $\epsilon > 0$.  In other
words, we want a move that is a small step of a fixed size, and we're
trying to find the movement direction which decreases $C$ as much as
possible.  It can be proved that the choice of $\Delta v$ which
minimizes $\nabla C \cdot \Delta v$ is $\Delta v = - \eta \nabla C$,
where $\eta = \epsilon / \|\nabla C\|$ is determined by the size
constraint $\|\Delta v\| = \epsilon$.  So gradient descent can be
viewed as a way of taking small steps in the direction which does the
most to immediately decrease $C$.</p><p><h4><a name="exercises_647181"></a><a href="#exercises_647181">Exercises</a></h4><ul>
<li> Prove the assertion of the last paragraph.  <em>Hint:</em> If
    you're not already familiar with the
    <a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Schwarz_inequality">Cauchy-Schwarz
      inequality</a>, you may find it helpful to familiarize yourself
    with it.</p><p><li> I explained gradient descent when $C$ is a function of two
  variables, and when it's a function of more than two variables.
  What happens when $C$ is a function of just one variable?  Can you
  provide a geometric interpretation of what gradient descent is doing
  in the one-dimensional case?
</ul></p><p></p><p>People have investigated many variations of gradient descent,
including variations that more closely mimic a real physical ball.
These ball-mimicking variations have some advantages, but also have a
major disadvantage: it turns out to be necessary to compute second
partial derivatives of $C$, and this can be quite costly.  To see why
it's costly, suppose we want to compute all the second partial
derivatives $\partial^2 C/ \partial v_j \partial v_k$.  If there are a
million such $v_j$ variables then we'd need to compute something like
a trillion (i.e., a million squared) second partial
derivatives*<span class="marginnote">
*Actually, more like half a trillion, since
  $\partial^2 C/ \partial v_j \partial v_k = \partial^2 C/ \partial
  v_k \partial v_j$.  Still, you get the point.</span>!  That's going to be
computationally costly.  With that said, there are tricks for avoiding
this kind of problem, and finding alternatives to gradient descent is
an active area of investigation.  But in this book we'll use gradient
descent (and variations) as our main approach to learning in neural
networks.</p><p>How can we apply gradient descent to learn in a neural network?  The
idea is to use gradient descent to find the weights $w_k$ and biases
$b_l$ which minimize the cost in
Equation <span id="margin_552678515184_reveal" class="equation_link">(6)</span><span id="margin_552678515184" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_552678515184_reveal').click(function() {$('#margin_552678515184').toggle('slow', function() {});});</script>.  To see how this works, let's
restate the gradient descent update rule, with the weights and biases
replacing the variables $v_j$.  In other words, our "position" now
has components $w_k$ and $b_l$, and the gradient vector $\nabla C$ has
corresponding components $\partial C / \partial w_k$ and $\partial C
/ \partial b_l$.  Writing out the gradient descent update rule in
terms of components, we have
<a class="displaced_anchor" name="eqtn16"></a><a class="displaced_anchor" name="eqtn17"></a>\begin{eqnarray}
  w_k & \rightarrow & w_k' = w_k-\eta \frac{\partial C}{\partial w_k} \tag{16}\\
  b_l & \rightarrow & b_l' = b_l-\eta \frac{\partial C}{\partial b_l}.
\tag{17}\end{eqnarray}
By repeatedly applying this update rule we can "roll down the hill",
and hopefully find a minimum of the cost function.  In other words,
this is a rule which can be used to learn in a neural network.</p><p>There are a number of challenges in applying the gradient descent
rule.  We'll look into those in depth in later chapters.  But for now
I just want to mention one problem.  To understand what the problem
is, let's look back at the quadratic cost in
Equation <span id="margin_636312544623_reveal" class="equation_link">(6)</span><span id="margin_636312544623" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_636312544623_reveal').click(function() {$('#margin_636312544623').toggle('slow', function() {});});</script>.  Notice that this cost
function has the form $C = \frac{1}{n} \sum_x C_x$, that is, it's an
average over costs $C_x \equiv \frac{\|y(x)-a\|^2}{2}$ for individual
training examples.  In practice, to compute the gradient $\nabla C$ we
need to compute the gradients $\nabla C_x$ separately for each
training input, $x$, and then average them, $\nabla C = \frac{1}{n}
\sum_x \nabla C_x$.  Unfortunately, when the number of training inputs
is very large this can take a long time, and learning thus occurs
slowly.</p><p>An idea called <em>stochastic gradient descent</em> can be used to speed
up learning.  The idea is to estimate the gradient $\nabla C$ by
computing $\nabla C_x$ for a small sample of randomly chosen training
inputs.  By averaging over this small sample it turns out that we can
quickly get a good estimate of the true gradient $\nabla C$, and this
helps speed up gradient descent, and thus learning.</p><p>To make these ideas more precise, stochastic gradient descent works by
randomly picking out a small number $m$ of randomly chosen training
inputs.  We'll label those random training inputs $X_1, X_2, \ldots,
X_m$, and refer to them as a <em>mini-batch</em>.  Provided the sample
size $m$ is large enough we expect that the average value of the
$\nabla C_{X_j}$ will be roughly equal to the average over all $\nabla
C_x$, that is,
<a class="displaced_anchor" name="eqtn18"></a>\begin{eqnarray}
  \frac{\sum_{j=1}^m \nabla C_{X_{j}}}{m} \approx \frac{\sum_x \nabla C_x}{n} = \nabla C,
\tag{18}\end{eqnarray}
where the second sum is over the entire set of training data.
Swapping sides we get
<a class="displaced_anchor" name="eqtn19"></a>\begin{eqnarray}
  \nabla C \approx \frac{1}{m} \sum_{j=1}^m \nabla C_{X_{j}},
\tag{19}\end{eqnarray}
confirming that we can estimate the overall gradient by computing
gradients just for the randomly chosen mini-batch. </p><p>To connect this explicitly to learning in neural networks, suppose
$w_k$ and $b_l$ denote the weights and biases in our neural network.
Then stochastic gradient descent works by picking out a randomly
chosen mini-batch of training inputs, and training with those,
<a class="displaced_anchor" name="eqtn20"></a><a class="displaced_anchor" name="eqtn21"></a>\begin{eqnarray} 
  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial w_k} \tag{20}\\
  
  b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial b_l},
\tag{21}\end{eqnarray}
where the sums are over all the training examples $X_j$ in the current
mini-batch.  Then we pick out another randomly chosen mini-batch and
train with those.  And so on, until we've exhausted the training
inputs, which is said to complete an
<em>epoch</em> of training.  At that point
we start over with a new training epoch.</p><p>Incidentally, it's worth noting that conventions vary about scaling of
the cost function and of mini-batch updates to the weights and biases.
In Equation <span id="margin_28961100271_reveal" class="equation_link">(6)</span><span id="margin_28961100271" class="marginequation" style="display: none;"><a href="chap1.html#eqtn6" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  C(w,b) \equiv
  \frac{1}{2n} \sum_x \| y(x) - a\|^2 \nonumber\end{eqnarray}</a></span><script>$('#margin_28961100271_reveal').click(function() {$('#margin_28961100271').toggle('slow', function() {});});</script> we scaled the overall cost
function by a factor $\frac{1}{n}$.  People sometimes omit the
$\frac{1}{n}$, summing over the costs of individual training examples
instead of averaging.  This is particularly useful when the total
number of training examples isn't known in advance.  This can occur if
more training data is being generated in real time, for instance.
And, in a similar way, the mini-batch update rules <span id="margin_38667351831_reveal" class="equation_link">(20)</span><span id="margin_38667351831" class="marginequation" style="display: none;"><a href="chap1.html#eqtn20" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  w_k & \rightarrow & w_k' = w_k-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial w_k}  \nonumber\end{eqnarray}</a></span><script>$('#margin_38667351831_reveal').click(function() {$('#margin_38667351831').toggle('slow', function() {});});</script>
and <span id="margin_667554963539_reveal" class="equation_link">(21)</span><span id="margin_667554963539" class="marginequation" style="display: none;"><a href="chap1.html#eqtn21" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray}  
  b_l & \rightarrow & b_l' = b_l-\frac{\eta}{m}
  \sum_j \frac{\partial C_{X_j}}{\partial b_l} \nonumber\end{eqnarray}</a></span><script>$('#margin_667554963539_reveal').click(function() {$('#margin_667554963539').toggle('slow', function() {});});</script> sometimes omit the $\frac{1}{m}$ term out the
front of the sums.  Conceptually this makes little difference, since
it's equivalent to rescaling the learning rate $\eta$.  But when doing
detailed comparisons of different work it's worth watching out for.</p><p>We can think of stochastic gradient descent as being like political
polling: it's much easier to sample a small mini-batch than it is to
apply gradient descent to the full batch, just as carrying out a poll
is easier than running a full election.  For example, if we have a
training set of size $n = 60,000$, as in MNIST, and choose a
mini-batch size of (say) $m = 10$, this means we'll get a factor of
$6,000$ speedup in estimating the gradient!  Of course, the estimate
won't be perfect - there will be statistical fluctuations - but it
doesn't need to be perfect: all we really care about is moving in a
general direction that will help decrease $C$, and that means we don't
need an exact computation of the gradient.  In practice, stochastic
gradient descent is a commonly used and powerful technique for
learning in neural networks, and it's the basis for most of the
learning techniques we'll develop in this book.</p><p></p><p></p><p></p><p></p><p></p><p><h4><a name="exercise_263792"></a><a href="#exercise_263792">Exercise</a></h4><ul>
<li> An extreme version of gradient descent is to use a mini-batch
  size of just 1.  That is, given a training input, $x$, we update our
  weights and biases according to the rules $w_k \rightarrow w_k' =
  w_k - \eta \partial C_x / \partial w_k$ and $b_l \rightarrow b_l' =
  b_l - \eta \partial C_x / \partial b_l$.  Then we choose another
  training input, and update the weights and biases again.  And so on,
  repeatedly.  This procedure is known as <em>online</em>,
  <em>on-line</em>, or <em>incremental</em> learning.  In online learning,
  a neural network learns from just one training input at a time (just
  as human beings do).  Name one advantage and one disadvantage of
  online learning, compared to stochastic gradient descent with a
  mini-batch size of, say, $20$.
</ul></p><p>Let me conclude this section by discussing a point that sometimes bugs
people new to gradient descent.  In neural networks the cost $C$ is,
of course, a function of many variables - all the weights and biases
- and so in some sense defines a surface in a very high-dimensional
space.  Some people get hung up thinking: "Hey, I have to be able to
visualize all these extra dimensions".  And they may start to worry:
"I can't think in four dimensions, let alone five (or five
million)".  Is there some special ability they're missing, some
ability that "real" supermathematicians have?  Of course, the answer
is no.  Even most professional mathematicians can't visualize four
dimensions especially well, if at all.  The trick they use, instead,
is to develop other ways of representing what's going on.  That's
exactly what we did above: we used an algebraic (rather than visual)
representation of $\Delta C$ to figure out how to move so as to
decrease $C$.  People who are good at thinking in high dimensions have
a mental library containing many different techniques along these
lines; our algebraic trick is just one example.  Those techniques may
not have the simplicity we're accustomed to when visualizing three
dimensions, but once you build up a library of such techniques, you
can get pretty good at thinking in high dimensions.  I won't go into
more detail here, but if you're interested then you may enjoy reading
<a href="http://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking">this
  discussion</a> of some of the techniques professional mathematicians
use to think in high dimensions.  While some of the techniques
discussed are quite complex, much of the best content is intuitive and
accessible, and could be mastered by anyone.</p><p></p><p>
<h3><a name="implementing_our_network_to_classify_digits"></a><a href="#implementing_our_network_to_classify_digits">Implementing our network to classify digits</a></h3></p><p>Alright, let's write a program that learns how to recognize
handwritten digits, using stochastic gradient descent and the MNIST
training data.  We'll do this with a short Python (2.7) program, just
74 lines of code!  The first thing we need is to get the MNIST data.
If you're a <tt>git</tt> user then you can obtain the data by cloning
the code repository for this book,</p><p><div class="highlight"><pre><span></span>git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git
</pre></div>
</p><p>If you don't use <tt>git</tt> then you can download the data and code
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip">here</a>.</p><p>Incidentally, when I described the MNIST data earlier, I said it was
split into 60,000 training images, and 10,000 test images.  That's the
official MNIST description.  Actually, we're going to split the data a
little differently.  We'll leave the test images as is, but split the
60,000-image MNIST training set into two parts: a set of 50,000
images, which we'll use to train our neural network, and a separate
10,000 image <em>validation set</em>.  We won't
use the validation data in this chapter, but later in the book we'll
find it useful in figuring out how to set certain
<em>hyper-parameters</em> of the neural network - things like the
learning rate, and so on, which aren't directly selected by our
learning algorithm.  Although the validation data isn't part of the
original MNIST specification, many people use MNIST in this fashion,
and the use of validation data is common in neural networks.  When I
refer to the "MNIST training data" from now on, I'll be referring to
our 50,000 image data set, not the original 60,000 image data
set*<span class="marginnote">
*As noted earlier, the MNIST data set is based on two data
  sets collected by NIST, the United States' National Institute of
  Standards and Technology.  To construct MNIST the NIST data sets
  were stripped down and put into a more convenient format by Yann
  LeCun, Corinna Cortes, and Christopher J. C. Burges.  See
  <a href="http://yann.lecun.com/exdb/mnist/">this link</a> for more
  details.  The data set in my repository is in a form that makes it
  easy to load and manipulate the MNIST data in Python.  I obtained
  this particular form of the data from the LISA machine learning
  laboratory at the University of Montreal
  (<a href="http://www.deeplearning.net/tutorial/gettingstarted.html">link</a>).</span>.</p><p></p><p>Apart from the MNIST data we also need a Python library called
<a href="http://numpy.org">Numpy</a>, for doing fast linear algebra.  If you
don't already have Numpy installed, you can get it
<a href="http://www.scipy.org/install.html">here</a>.</p><p>Let me explain the core features of the neural networks code, before
giving a full listing, below.  The centerpiece is a <tt>Network</tt>
class, which we use to represent a neural network.  Here's the code we
use to initialize a <tt>Network</tt> object:</p><p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> 
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
</pre></div>
</p><p>In this code, the list <tt>sizes</tt> contains the number of neurons in
the respective layers.  So, for example, if we want to create a
<tt>Network</tt> object with 2 neurons in the first layer, 3 neurons in
the second layer, and 1 neuron in the final layer, we'd do this with
the code:
<div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Network</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

<a name="weight_initialization"></a> The biases
and weights in the <tt>Network</tt> object are all initialized randomly,
using the Numpy <tt>np.random.randn</tt> function to generate Gaussian
distributions with mean $0$ and standard deviation $1$.  This random
initialization gives our stochastic gradient descent algorithm a place
to start from.  In later chapters we'll find better ways of
initializing the weights and biases, but this will do for now.  Note
that the <tt>Network</tt> initialization code assumes that the first
layer of neurons is an input layer, and omits to set any biases for
those neurons, since biases are only ever used in computing the
outputs from later layers.</p><p>Note also that the biases and weights are stored as lists of Numpy
matrices.  So, for example <tt>net.weights[1]</tt> is a Numpy matrix
storing the weights connecting the second and third layers of neurons.
(It's not the first and second layers, since Python's list indexing
starts at <tt>0</tt>.)  Since <tt>net.weights[1]</tt> is rather verbose,
let's just denote that matrix $w$.  It's a matrix such that $w_{jk}$
is the weight for the connection between the $k^{\rm th}$ neuron in the
second layer, and the $j^{\rm th}$ neuron in the third layer.  This ordering
of the $j$ and $k$ indices may seem strange - surely it'd make more
sense to swap the $j$ and $k$ indices around?  The big advantage of
using this ordering is that it means that the vector of activations of
the third layer of neurons is:
<a class="displaced_anchor" name="eqtn22"></a>\begin{eqnarray} 
  a' = \sigma(w a + b).
\tag{22}\end{eqnarray}
There's quite a bit going on in this equation, so let's unpack it
piece by piece.  $a$ is the vector of activations of the second layer
of neurons. To obtain $a'$ we multiply $a$ by the weight matrix $w$,
and add the vector $b$ of biases.  We then apply the function $\sigma$
elementwise to every entry in the vector $w a +b$.  (This is called
<em>vectorizing</em> the function
$\sigma$.) It's easy to verify that
Equation <span id="margin_469346701810_reveal" class="equation_link">(22)</span><span id="margin_469346701810" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_469346701810_reveal').click(function() {$('#margin_469346701810').toggle('slow', function() {});});</script> gives the same result as our
earlier rule, Equation <span id="margin_803037168757_reveal" class="equation_link">(4)</span><span id="margin_803037168757" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_803037168757_reveal').click(function() {$('#margin_803037168757').toggle('slow', function() {});});</script>, for
computing the output of a sigmoid neuron.</p><p><h4><a name="exercise_717502"></a><a href="#exercise_717502">Exercise</a></h4><ul>
<li> Write out Equation <span id="margin_585248828587_reveal" class="equation_link">(22)</span><span id="margin_585248828587" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_585248828587_reveal').click(function() {$('#margin_585248828587').toggle('slow', function() {});});</script> in component
  form, and verify that it gives the same result as the
  rule <span id="margin_208193369319_reveal" class="equation_link">(4)</span><span id="margin_208193369319" class="marginequation" style="display: none;"><a href="chap1.html#eqtn4" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  \frac{1}{1+\exp(-\sum_j w_j x_j-b)} \nonumber\end{eqnarray}</a></span><script>$('#margin_208193369319_reveal').click(function() {$('#margin_208193369319').toggle('slow', function() {});});</script> for computing the output
  of a sigmoid neuron.
</ul></p><p>With all this in mind, it's easy to write code computing the output
from a <tt>Network</tt> instance.  We begin by defining the sigmoid
function:
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>

Note that when the input <tt>z</tt> is a vector or Numpy array, Numpy
automatically applies the function <tt>sigmoid</tt> elementwise, that
is, in vectorized form.</p><p>We then add a <tt>feedforward</tt> method to the <tt>Network</tt> class,
which, given an input <tt>a</tt> for the network, returns the
corresponding output*<span class="marginnote">
*It is assumed that the input <tt>a</tt> is
  an <tt>(n, 1)</tt> Numpy ndarray, not a <tt>(n,)</tt> vector.  Here,
  <tt>n</tt> is the number of inputs to the network.  If you try to use
  an <tt>(n,)</tt> vector as input you'll get strange results.  Although
  using an <tt>(n,)</tt> vector appears the more natural choice, using
  an <tt>(n, 1)</tt> ndarray makes it particularly easy to modify the
  code to feedforward multiple inputs at once, and that is sometimes
  convenient. </span>.  All the method does is applies
Equation <span id="margin_436898280460_reveal" class="equation_link">(22)</span><span id="margin_436898280460" class="marginequation" style="display: none;"><a href="chap1.html#eqtn22" style="padding-bottom: 5px;" onMouseOver="this.style.borderBottom='1px solid #2A6EA6';" onMouseOut="this.style.borderBottom='0px';">\begin{eqnarray} 
  a' = \sigma(w a + b) \nonumber\end{eqnarray}</a></span><script>$('#margin_436898280460_reveal').click(function() {$('#margin_436898280460').toggle('slow', function() {});});</script> for each layer:
<div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if &quot;a&quot; is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>
</pre></div>
</p><p>Of course, the main thing we want our <tt>Network</tt> objects to do is
to learn.  To that end we'll give them an <tt>SGD</tt> method which
implements stochastic gradient descent.  Here's the code.  It's a
little mysterious in a few places, but I'll break it down below, after
the listing.</p><p><div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The &quot;training_data&quot; is a list of tuples</span>
<span class="sd">        &quot;(x, y)&quot; representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If &quot;test_data&quot; is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
</pre></div>
</p><p>The <tt>training_data</tt> is a list of tuples <tt>(x, y)</tt>
representing the training inputs and corresponding desired outputs.
The variables <tt>epochs</tt> and <tt>mini_batch_size</tt> are what you'd
expect - the number of epochs to train for, and the size of the
mini-batches to use when sampling.  <tt>eta</tt> is the learning rate,
$\eta$.  If the optional argument <tt>test_data</tt> is supplied, then
the program will evaluate the network after each epoch of training,
and print out partial progress.  This is useful for tracking progress,
but slows things down substantially.</p><p>The code works as follows.  In each epoch, it starts by randomly
shuffling the training data, and then partitions it into mini-batches
of the appropriate size.  This is an easy way of sampling randomly
from the training data.  Then for each <tt>mini_batch</tt> we apply a
single step of gradient descent.  This is done by the code
<tt>self.update_mini_batch(mini_batch, eta)</tt>, which updates the
network weights and biases according to a single iteration of gradient
descent, using just the training data in <tt>mini_batch</tt>.  Here's
the code for the <tt>update_mini_batch</tt> method:
<div class="highlight"><pre><span></span>    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The &quot;mini_batch&quot; is a list of tuples &quot;(x, y)&quot;, and &quot;eta&quot;</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span> 
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span> 
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>
</pre></div>

Most of the work is done by the line
<div class="highlight"><pre><span></span>            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

This invokes something called the <em>backpropagation</em> algorithm,
which is a fast way of computing the gradient of the cost function.
So <tt>update_mini_batch</tt> works simply by computing these gradients
for every training example in the <tt>mini_batch</tt>, and then updating
<tt>self.weights</tt> and <tt>self.biases</tt> appropriately.</p><p>I'm not going to show the code for <tt>self.backprop</tt> right now.
We'll study how backpropagation works in the next chapter, including
the code for <tt>self.backprop</tt>.  For now, just assume that it
behaves as claimed, returning the appropriate gradient for the cost
associated to the training example <tt>x</tt>.</p><p>Let's look at the full program, including the documentation strings,
which I omitted above.  Apart from <tt>self.backprop</tt> the program is
self-explanatory - all the heavy lifting is done in <tt>self.SGD</tt>
and <tt>self.update_mini_batch</tt>, which we've already discussed.  The
<tt>self.backprop</tt> method makes use of a few extra functions to help
in computing the gradient, namely <tt>sigmoid_prime</tt>, which computes
the derivative of the $\sigma$ function, and
<tt>self.cost_derivative</tt>, which I won't describe here.  You can get
the gist of these (and perhaps the details) just by looking at the
code and documentation strings.  We'll look at them in detail in the
next chapter. 
Note that while the program appears lengthy, much of the code is
documentation strings intended to make the code easy to understand.
In fact, the program contains just 74 lines of non-whitespace,
non-comment code.  All the code may be found on GitHub
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network.py">here</a>.</p><p></p><p><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">network.py</span>
<span class="sd">~~~~~~~~~~</span>

<span class="sd">A module to implement the stochastic gradient descent learning</span>
<span class="sd">algorithm for a feedforward neural network.  Gradients are calculated</span>
<span class="sd">using backpropagation.  Note that I have focused on making the code</span>
<span class="sd">simple, easily readable, and easily modifiable.  It is not optimized,</span>
<span class="sd">and omits many desirable features.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">#### Libraries</span>
<span class="c1"># Standard library</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The list ``sizes`` contains the number of neurons in the</span>
<span class="sd">        respective layers of the network.  For example, if the list</span>
<span class="sd">        was [2, 3, 1] then it would be a three-layer network, with the</span>
<span class="sd">        first layer containing 2 neurons, the second layer 3 neurons,</span>
<span class="sd">        and the third layer 1 neuron.  The biases and weights for the</span>
<span class="sd">        network are initialized randomly, using a Gaussian</span>
<span class="sd">        distribution with mean 0, and variance 1.  Note that the first</span>
<span class="sd">        layer is assumed to be an input layer, and by convention we</span>
<span class="sd">        won&#39;t set any biases for those neurons, since biases are only</span>
<span class="sd">        ever used in computing the outputs from later layers.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sizes</span> <span class="o">=</span> <span class="n">sizes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>

    <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the output of the network if ``a`` is input.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">a</span>

    <span class="k">def</span> <span class="nf">SGD</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">eta</span><span class="p">,</span>
            <span class="n">test_data</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Train the neural network using mini-batch stochastic</span>
<span class="sd">        gradient descent.  The ``training_data`` is a list of tuples</span>
<span class="sd">        ``(x, y)`` representing the training inputs and the desired</span>
<span class="sd">        outputs.  The other non-optional parameters are</span>
<span class="sd">        self-explanatory.  If ``test_data`` is provided then the</span>
<span class="sd">        network will be evaluated against the test data after each</span>
<span class="sd">        epoch, and partial progress printed out.  This is useful for</span>
<span class="sd">        tracking progress, but slows things down substantially.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
            <span class="n">mini_batches</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">training_data</span><span class="p">[</span><span class="n">k</span><span class="p">:</span><span class="n">k</span><span class="o">+</span><span class="n">mini_batch_size</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">mini_batch</span> <span class="ow">in</span> <span class="n">mini_batches</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">update_mini_batch</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test_data</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0}: {1} / {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">j</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="n">n_test</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">print</span> <span class="s2">&quot;Epoch {0} complete&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_mini_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mini_batch</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update the network&#39;s weights and biases by applying</span>
<span class="sd">        gradient descent using backpropagation to a single mini batch.</span>
<span class="sd">        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``</span>
<span class="sd">        is the learning rate.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">mini_batch</span><span class="p">:</span>
            <span class="n">delta_nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_w</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backprop</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">nb</span><span class="o">+</span><span class="n">dnb</span> <span class="k">for</span> <span class="n">nb</span><span class="p">,</span> <span class="n">dnb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">delta_nabla_b</span><span class="p">)]</span>
            <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">nw</span><span class="o">+</span><span class="n">dnw</span> <span class="k">for</span> <span class="n">nw</span><span class="p">,</span> <span class="n">dnw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nabla_w</span><span class="p">,</span> <span class="n">delta_nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nw</span>
                        <span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">nw</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">-</span><span class="p">(</span><span class="n">eta</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mini_batch</span><span class="p">))</span><span class="o">*</span><span class="n">nb</span>
                       <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">nb</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="n">nabla_b</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">backprop</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a tuple ``(nabla_b, nabla_w)`` representing the</span>
<span class="sd">        gradient for the cost function C_x.  ``nabla_b`` and</span>
<span class="sd">        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar</span>
<span class="sd">        to ``self.biases`` and ``self.weights``.&quot;&quot;&quot;</span>
        <span class="n">nabla_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">]</span>
        <span class="n">nabla_w</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">]</span>
        <span class="c1"># feedforward</span>
        <span class="n">activation</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="c1"># list to store all the activations, layer by layer</span>
        <span class="n">zs</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># list to store all the z vectors, layer by layer</span>
        <span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">biases</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
            <span class="n">zs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activation</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">activations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
        <span class="c1"># backward pass</span>
        <span class="n">delta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cost_derivative</span><span class="p">(</span><span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> \
            <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
        <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="c1"># Note that the variable l in the loop below is used a little</span>
        <span class="c1"># differently to the notation in Chapter 2 of the book.  Here,</span>
        <span class="c1"># l = 1 means the last layer of neurons, l = 2 is the</span>
        <span class="c1"># second-last layer, and so on.  It&#39;s a renumbering of the</span>
        <span class="c1"># scheme in the book, used here to take advantage of the fact</span>
        <span class="c1"># that Python can use negative indices in lists.</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">zs</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span>
            <span class="n">sp</span> <span class="o">=</span> <span class="n">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(),</span> <span class="n">delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">sp</span>
            <span class="n">nabla_b</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta</span>
            <span class="n">nabla_w</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">delta</span><span class="p">,</span> <span class="n">activations</span><span class="p">[</span><span class="o">-</span><span class="n">l</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">nabla_b</span><span class="p">,</span> <span class="n">nabla_w</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the number of test inputs for which the neural</span>
<span class="sd">        network outputs the correct result. Note that the neural</span>
<span class="sd">        network&#39;s output is assumed to be the index of whichever</span>
<span class="sd">        neuron in the final layer has the highest activation.&quot;&quot;&quot;</span>
        <span class="n">test_results</span> <span class="o">=</span> <span class="p">[(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">y</span><span class="p">)</span>
                        <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_data</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="n">test_results</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cost_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_activations</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the vector of partial derivatives \partial C_x /</span>
<span class="sd">        \partial a for the output activations.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">output_activations</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>

<span class="c1">#### Miscellaneous functions</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sigmoid_prime</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Derivative of the sigmoid function.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</p><p>How well does the program recognize handwritten digits?  Well, let's
start by loading in the MNIST data.  I'll do this using a little
helper program, <tt>mnist_loader.py</tt>, to be described below.  We
execute the following commands in a Python shell,</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">mnist_loader</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> \
<span class="o">...</span> <span class="n">mnist_loader</span><span class="o">.</span><span class="n">load_data_wrapper</span><span class="p">()</span>
</pre></div>
</p><p>Of course, this could also be done in a separate Python program, but
if you're following along it's probably easiest to do in a Python
shell.  </p><p>After loading the MNIST data, we'll set up a <tt>Network</tt> with $30$
hidden neurons.  We do this after importing the Python program listed
above, which is named <tt>network</tt>,</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">network</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
</pre></div>
</p><p>Finally, we'll use stochastic gradient descent to learn from the MNIST
<tt>training_data</tt> over 30 epochs, with a mini-batch size of 10, and a
learning rate of $\eta = 3.0$, </p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Note that if you're running the code as you read along, it will take
some time to execute - for a typical machine (as of 2015) it will
likely take a few minutes to run.  I suggest you set things running,
continue to read, and periodically check the output from the code.  If
you're in a rush you can speed things up by decreasing the number of
epochs, by decreasing the number of hidden neurons, or by using only
part of the training data.  Note that production code would be much,
much faster: these Python scripts are intended to help you understand
how neural nets work, not to be high-performance code!  And, of
course, once we've trained a network it can be run very quickly
indeed, on almost any computing platform. For example, once we've
learned a good set of weights and biases for a network, it can easily
be ported to run in Javascript in a web browser, or as a native app on
a mobile device.  In any case, here is a partial transcript of the
output of one training run of the neural network.  The transcript
shows the number of test images correctly recognized by the neural
network after each epoch of training.  As you can see, after just a
single epoch this has reached 9,129 out of 10,000, and the number
continues to grow,</p><p><div class="highlight"><pre><span></span>Epoch 0: 9129 / 10000
Epoch 1: 9295 / 10000
Epoch 2: 9348 / 10000
...
Epoch 27: 9528 / 10000
Epoch 28: 9542 / 10000
Epoch 29: 9534 / 10000
</pre></div>
</p><p>That is, the trained network gives us a classification rate of about
$95$ percent - $95.42$ percent at its peak ("Epoch 28")!  That's
quite encouraging as a first attempt.  I should warn you, however,
that if you run the code then your results are not necessarily going
to be quite the same as mine, since we'll be initializing our network
using (different) random weights and biases.  To generate results in
this chapter I've taken best-of-three runs.</p><p>Let's rerun the above experiment, changing the number of hidden
neurons to $100$.  As was the case earlier, if you're running the code
as you read along, you should be warned that it takes quite a while to
execute (on my machine this experiment takes tens of seconds for each
training epoch), so it's wise to continue reading in parallel while
the code executes.</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>Sure enough, this improves the results to $96.59$ percent.  At least
in this case, using more hidden neurons helps us get better
results*<span class="marginnote">
*Reader feedback indicates quite some variation in
  results for this experiment, and some training runs give results
  quite a bit worse.  Using the techniques introduced in chapter 3
  will greatly reduce the variation in performance across different
  training runs for our networks.</span>.</p><p>Of course, to obtain these accuracies I had to make specific choices
for the number of epochs of training, the mini-batch size, and the
learning rate, $\eta$.  As I mentioned above, these are known as
hyper-parameters for our neural network, in order to distinguish them
from the parameters (weights and biases) learnt by our learning
algorithm.  If we choose our hyper-parameters poorly, we can get bad
results.  Suppose, for example, that we'd chosen the learning rate to
be $\eta = 0.001$,</p><p><div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>
</p><p>The results are much less encouraging,
<div class="highlight"><pre><span></span>Epoch 0: 1139 / 10000
Epoch 1: 1136 / 10000
Epoch 2: 1135 / 10000
...
Epoch 27: 2101 / 10000
Epoch 28: 2123 / 10000
Epoch 29: 2142 / 10000
</pre></div>

However, you can see that the performance of the network is getting
slowly better over time.  That suggests increasing the learning rate,
say to $\eta = 0.01$.  If we do that, we get better results, which
suggests increasing the learning rate again.  (If making a change
improves things, try doing more!)  If we do that several times over,
we'll end up with a learning rate of something like $\eta = 1.0$ (and
perhaps fine tune to $3.0$), which is close to our earlier
experiments.  So even though we initially made a poor choice of
hyper-parameters, we at least got enough information to help us
improve our choice of hyper-parameters.</p><p>In general, debugging a neural network can be challenging.  This is
especially true when the initial choice of hyper-parameters produces
results no better than random noise.  Suppose we try the successful 30
hidden neuron network architecture from earlier, but with the learning
rate changed to $\eta = 100.0$:
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="n">net</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">Network</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">net</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">,</span> <span class="n">test_data</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
</pre></div>

At this point we've actually gone too far, and the learning rate is
too high:
<div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">2</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">3</span><span class="p">:</span> <span class="mi">1009</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="o">...</span>
<span class="n">Epoch</span> <span class="mi">27</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">28</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
<span class="n">Epoch</span> <span class="mi">29</span><span class="p">:</span> <span class="mi">982</span> <span class="o">/</span> <span class="mi">10000</span>
</pre></div>

Now imagine that we were coming to this problem for the first time.
Of course, we <em>know</em> from our earlier experiments that the right
thing to do is to decrease the learning rate.  But if we were coming
to this problem for the first time then there wouldn't be much in the
output to guide us on what to do.  We might worry not only about the
learning rate, but about every other aspect of our neural network.  We
might wonder if we've initialized the weights and biases in a way that
makes it hard for the network to learn?  Or maybe we don't have enough
training data to get meaningful learning?  Perhaps we haven't run for
enough epochs?  Or maybe it's impossible for a neural network with
this architecture to learn to recognize handwritten digits?  Maybe the
learning rate is too <em>low</em>?  Or, maybe, the learning rate is too
high?  When you're coming to a problem for the first time, you're not
always sure.</p><p>The lesson to take away from this is that debugging a neural network
is not trivial, and, just as for ordinary programming, there is an art
to it.  You need to learn that art of debugging in order to get good
results from neural networks.  More generally, we need to develop
heuristics for choosing good hyper-parameters and a good architecture.
We'll discuss all these at length through the book, including how I
chose the hyper-parameters above.</p><p>
<h4><a name="exercise_420023"></a><a href="#exercise_420023">Exercise</a></h4><ul></p><p><li> Try creating a network with just two layers - an input and an
  output layer, no hidden layer - with 784 and 10 neurons,
  respectively.  Train the network using stochastic gradient descent.
  What classification accuracy can you achieve?
</ul></p><p></p><p>Earlier, I skipped over the details of how the MNIST data is loaded.
It's pretty straightforward.  For completeness, here's the code.  The
data structures used to store the MNIST data are described in the
documentation strings - it's straightforward stuff, tuples and lists
of Numpy <tt>ndarray</tt> objects (think of them as vectors if you're
not familiar with <tt>ndarray</tt>s):</p><p><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">mnist_loader</span>
<span class="sd">~~~~~~~~~~~~</span>

<span class="sd">A library to load the MNIST image data.  For details of the data</span>
<span class="sd">structures that are returned, see the doc strings for ``load_data``</span>
<span class="sd">and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the</span>
<span class="sd">function usually called by our neural network code.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1">#### Libraries</span>
<span class="c1"># Standard library</span>
<span class="kn">import</span> <span class="nn">cPickle</span>
<span class="kn">import</span> <span class="nn">gzip</span>

<span class="c1"># Third-party libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">load_data</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return the MNIST data as a tuple containing the training data,</span>
<span class="sd">    the validation data, and the test data.</span>

<span class="sd">    The ``training_data`` is returned as a tuple with two entries.</span>
<span class="sd">    The first entry contains the actual training images.  This is a</span>
<span class="sd">    numpy ndarray with 50,000 entries.  Each entry is, in turn, a</span>
<span class="sd">    numpy ndarray with 784 values, representing the 28 * 28 = 784</span>
<span class="sd">    pixels in a single MNIST image.</span>

<span class="sd">    The second entry in the ``training_data`` tuple is a numpy ndarray</span>
<span class="sd">    containing 50,000 entries.  Those entries are just the digit</span>
<span class="sd">    values (0...9) for the corresponding images contained in the first</span>
<span class="sd">    entry of the tuple.</span>

<span class="sd">    The ``validation_data`` and ``test_data`` are similar, except</span>
<span class="sd">    each contains only 10,000 images.</span>

<span class="sd">    This is a nice data format, but for use in neural networks it&#39;s</span>
<span class="sd">    helpful to modify the format of the ``training_data`` a little.</span>
<span class="sd">    That&#39;s done in the wrapper function ``load_data_wrapper()``, see</span>
<span class="sd">    below.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;../data/mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
    <span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_data_wrapper</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;Return a tuple containing ``(training_data, validation_data,</span>
<span class="sd">    test_data)``. Based on ``load_data``, but the format is more</span>
<span class="sd">    convenient for use in our implementation of neural networks.</span>

<span class="sd">    In particular, ``training_data`` is a list containing 50,000</span>
<span class="sd">    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray</span>
<span class="sd">    containing the input image.  ``y`` is a 10-dimensional</span>
<span class="sd">    numpy.ndarray representing the unit vector corresponding to the</span>
<span class="sd">    correct digit for ``x``.</span>

<span class="sd">    ``validation_data`` and ``test_data`` are lists containing 10,000</span>
<span class="sd">    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional</span>
<span class="sd">    numpy.ndarry containing the input image, and ``y`` is the</span>
<span class="sd">    corresponding classification, i.e., the digit values (integers)</span>
<span class="sd">    corresponding to ``x``.</span>

<span class="sd">    Obviously, this means we&#39;re using slightly different formats for</span>
<span class="sd">    the training data and the validation / test data.  These formats</span>
<span class="sd">    turn out to be the most convenient for use in our neural network</span>
<span class="sd">    code.&quot;&quot;&quot;</span>
    <span class="n">tr_d</span><span class="p">,</span> <span class="n">va_d</span><span class="p">,</span> <span class="n">te_d</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>
    <span class="n">training_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">training_results</span> <span class="o">=</span> <span class="p">[</span><span class="n">vectorized_result</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tr_d</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">training_inputs</span><span class="p">,</span> <span class="n">training_results</span><span class="p">)</span>
    <span class="n">validation_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">validation_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">validation_inputs</span><span class="p">,</span> <span class="n">va_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">test_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_inputs</span><span class="p">,</span> <span class="n">te_d</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">validation_data</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">vectorized_result</span><span class="p">(</span><span class="n">j</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a 10-dimensional unit vector with a 1.0 in the jth</span>
<span class="sd">    position and zeroes elsewhere.  This is used to convert a digit</span>
<span class="sd">    (0...9) into a corresponding desired output from the neural</span>
<span class="sd">    network.&quot;&quot;&quot;</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">e</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">e</span>
</pre></div>
</p><p>I said above that our program gets pretty good results.  What does
that mean?  Good compared to what?  It's informative to have some
simple (non-neural-network) baseline tests to compare against, to
understand what it means to perform well.  The simplest baseline of
all, of course, is to randomly guess the digit.  That'll be right
about ten percent of the time.  We're doing much better than that!</p><p>What about a less trivial baseline?  Let's try an extremely simple
idea: we'll look at how <em>dark</em> an image is.  For instance, an
image of a $2$ will typically be quite a bit darker than an image of a
$1$, just because more pixels are blackened out, as the following
examples illustrate:</p><p><center><img src="images/mnist_2_and_1.png" width="256px"></center></p><p>This suggests using the training data to compute average darknesses
for each digit, $0, 1, 2,\ldots, 9$.  When presented with a new image,
we compute how dark the image is, and then guess that it's whichever
digit has the closest average darkness.  This is a simple procedure,
and is easy to code up, so I won't explicitly write out the code -
if you're interested it's in the
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_average_darkness.py">GitHub
  repository</a>.  But it's a big improvement over random guessing,
getting $2,225$ of the $10,000$ test images correct, i.e., $22.25$
percent accuracy.</p><p><a name="SVM"></a></p><p>It's not difficult to find other ideas which achieve accuracies in the
$20$ to $50$ percent range.  If you work a bit harder you can get up
over $50$ percent.  But to get much higher accuracies it helps to use
established machine learning algorithms.  Let's try using one of the
best known algorithms, the <em>support vector
  machine</em>
or <em>SVM</em>.  If you're not
familiar with SVMs, not to worry, we're not going to need to
understand the details of how SVMs work.  Instead, we'll use a Python
library called
<a href="http://scikit-learn.org/stable/">scikit-learn</a>,
which provides a simple Python interface to a fast C-based library for
SVMs known as
<a href="http://www.csie.ntu.edu.tw/&#126;cjlin/libsvm/">LIBSVM</a>.</p><p>If we run scikit-learn's SVM classifier using the default settings,
then it gets 9,435 of 10,000 test images correct.  (The code is
available
<a href="https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/mnist_svm.py">here</a>.)
That's a big improvement over our naive approach of classifying an
image based on how dark it is.  Indeed, it means that the SVM is
performing roughly as well as our neural networks, just a little
worse.  In later chapters we'll introduce new techniques that enable
us to improve our neural networks so that they perform much better
than the SVM.</p><p>That's not the end of the story, however.  The 9,435 of 10,000 result
is for scikit-learn's default settings for SVMs.  SVMs have a number
of tunable parameters, and it's possible to search for parameters
which improve this out-of-the-box performance.  I won't explicitly do
this search, but instead refer you to
<a href="http://peekaboo-vision.blogspot.de/2010/09/mnist-for-ever.html">this
  blog post</a> by <a href="http://peekaboo-vision.blogspot.ca/">Andreas
  Mueller</a> if you'd like to know more.  Mueller shows that with some
work optimizing the SVM's parameters it's possible to get the
performance up above 98.5 percent accuracy.  In other words, a
well-tuned SVM only makes an error on about one digit in 70.  That's
pretty good!  Can neural networks do better?</p><p>In fact, they can.  At present, well-designed neural networks
outperform every other technique for solving MNIST, including SVMs.
The current (2013) record is classifying 9,979 of 10,000 images
correctly.  This was done by <a href="http://www.cs.nyu.edu/&#126;wanli/">Li
  Wan</a>, <a href="http://www.matthewzeiler.com/">Matthew Zeiler</a>, Sixin
Zhang, <a href="http://yann.lecun.com/">Yann LeCun</a>, and
<a href="http://cs.nyu.edu/&#126;fergus/pmwiki/pmwiki.php">Rob Fergus</a>.
We'll see most of the techniques they used later in the book.  At that
level the performance is close to human-equivalent, and is arguably
better, since quite a few of the MNIST images are difficult even for
humans to recognize with confidence, for example:</p><p><center><img src="images/mnist_really_bad_images.png" width="560px"></center></p><p>I trust you'll agree that those are tough to classify!  With images
like these in the MNIST data set it's remarkable that neural networks
can accurately classify all but 21 of the 10,000 test images.
Usually, when programming we believe that solving a complicated
problem like recognizing the MNIST digits requires a sophisticated
algorithm.  But even the neural networks in the Wan <em>et al</em> paper
just mentioned involve quite simple algorithms, variations on the
algorithm we've seen in this chapter.  All the complexity is learned,
automatically, from the training data. In some sense, the moral of
both our results and those in more sophisticated papers, is that for
some problems:
<center>
  sophisticated algorithm $\leq$ simple learning algorithm + good
  training data.
</center></p><p><h3><a name="toward_deep_learning"></a><a href="#toward_deep_learning">Toward deep learning</a></h3></p><p>While our neural network gives impressive performance, that
performance is somewhat mysterious.  The weights and biases in the
network were discovered automatically.  And that means we don't
immediately have an explanation of how the network does what it does.
Can we find some way to understand the principles by which our network
is classifying handwritten digits?  And, given such principles, can we
do better?</p><p>To put these questions more starkly, suppose that a few decades hence
neural networks lead to artificial intelligence (AI).  Will we
understand how such intelligent networks work?  Perhaps the networks
will be opaque to us, with weights and biases we don't understand,
because they've been learned automatically.  In the early days of AI
research people hoped that the effort to build an AI would also help
us understand the principles behind intelligence and, maybe, the
functioning of the human brain.  But perhaps the outcome will be that
we end up understanding neither the brain nor how artificial
intelligence works!</p><p>To address these questions, let's think back to the interpretation of
artificial neurons that I gave at the start of the chapter, as a means
of weighing evidence.  Suppose we want to determine whether an image
shows a human face or not:</p><p> </p><p>  <span class="marginnote">Credits: 1. <a
  href="http://commons.wikimedia.org/wiki/User:ST">Ester Inbar</a>. 2.
  Unknown. 3. NASA, ESA, G. Illingworth, D. Magee, and P. Oesch
  (University of California, Santa Cruz), R. Bouwens (Leiden
  University), and the HUDF09 Team.  Click on the images for more
  details.</span></p><p>  <a
  href="http://commons.wikimedia.org/wiki/File:Kangaroo_ST_03.JPG"><img
  src="images/Kangaroo.JPG" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:Albert_Einstein_at_the_age_of_three_(1882).jpg"><img
  src="images/Einstein_crop.jpg" height="190px"/></a> <a
  href="http://commons.wikimedia.org/wiki/File:The_Hubble_eXtreme_Deep_Field.jpg"><img
  src="images/hubble.jpg" height="190px"/></a> </p><p>We could attack this problem the same way we attacked handwriting
recognition - by using the pixels in the image as input to a neural
network, with the output from the network a single neuron indicating
either "Yes, it's a face" or "No, it's not a face".</p><p>Let's suppose we do this, but that we're not using a learning
algorithm.  Instead, we're going to try to design a network by hand,
choosing appropriate weights and biases.  How might we go about it?
Forgetting neural networks entirely for the moment, a heuristic we
could use is to decompose the problem into sub-problems: does the
image have an eye in the top left?  Does it have an eye in the top
right?  Does it have a nose in the middle?  Does it have a mouth in
the bottom middle?  Is there hair on top?  And so on.</p><p>If the answers to several of these questions are "yes", or even just
"probably yes", then we'd conclude that the image is likely to be a
face.  Conversely, if the answers to most of the questions are "no",
then the image probably isn't a face.</p><p>Of course, this is just a rough heuristic, and it suffers from many
deficiencies.  Maybe the person is bald, so they have no hair.  Maybe
we can only see part of the face, or the face is at an angle, so some
of the facial features are obscured.  Still, the heuristic suggests
that if we can solve the sub-problems using neural networks, then
perhaps we can build a neural network for face-detection, by combining
the networks for the sub-problems.  Here's a possible architecture,
with rectangles denoting the sub-networks.  Note that this isn't
intended as a realistic approach to solving the face-detection
problem; rather, it's to help us build intuition about how networks
function.  Here's the architecture:</p><p><center>
<img src="images/tikz14.png"/>
</center></p><p>It's also plausible that the sub-networks can be decomposed.  Suppose
we're considering the question: "Is there an eye in the top left?"
This can be decomposed into questions such as: "Is there an
eyebrow?"; "Are there eyelashes?"; "Is there an iris?"; and so
on.  Of course, these questions should really include positional
information, as well - "Is the eyebrow in the top left, and above
the iris?", that kind of thing - but let's keep it simple.  The
network to answer the question "Is there an eye in the top left?"
can now be decomposed:</p><p><center>
<img src="images/tikz15.png"/>
</center></p><p>Those questions too can be broken down, further and further through
multiple layers.  Ultimately, we'll be working with sub-networks that
answer questions so simple they can easily be answered at the level of
single pixels.  Those questions might, for example, be about the
presence or absence of very simple shapes at particular points in the
image.  Such questions can be answered by single neurons connected to
the raw pixels in the image.</p><p>The end result is a network which breaks down a very complicated
question - does this image show a face or not - into very simple
questions answerable at the level of single pixels.  It does this
through a series of many layers, with early layers answering very
simple and specific questions about the input image, and later layers
building up a hierarchy of ever more complex and abstract concepts.
Networks with this kind of many-layer structure - two or more hidden
layers - are called <em>deep neural networks</em>.</p><p></p><p></p><p>
Of course, I haven't said how to do this recursive decomposition into
sub-networks.  It certainly isn't practical to hand-design the weights
and biases in the network.  Instead, we'd like to use learning
algorithms so that the network can automatically learn the weights and
biases - and thus, the hierarchy of concepts - from training data.
Researchers in the 1980s and 1990s tried using stochastic gradient
descent and backpropagation to train deep networks.  Unfortunately,
except for a few special architectures, they didn't have much luck.
The networks would learn, but very slowly, and in practice often too
slowly to be useful.</p><p>Since 2006, a set of techniques has been developed that enable
learning in deep neural nets.  These deep learning techniques are
based on stochastic gradient descent and backpropagation, but also
introduce new ideas.  These techniques have enabled much deeper (and
larger) networks to be trained - people now routinely train networks
with 5 to 10 hidden layers.  And, it turns out that these perform far
better on many problems than shallow neural networks, i.e., networks
with just a single hidden layer.  The reason, of course, is the
ability of deep nets to build up a complex hierarchy of concepts.
It's a bit like the way conventional programming languages use modular
design and ideas about abstraction to enable the creation of complex
computer programs.  Comparing a deep network to a shallow network is a
bit like comparing a programming language with the ability to make
function calls to a stripped down language with no ability to make
such calls.  Abstraction takes a different form in neural networks
than it does in conventional programming, but it's just as important.</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p>
</div><div class="footer"> <span class="left_footer"> In academic work,
please cite this book as: Michael A. Nielsen, "Neural Networks and
Deep Learning", Determination Press, 2015

<br/>
<br/>

This work is licensed under a <a rel="license"
href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"
style="color: #eee;">Creative Commons Attribution-NonCommercial 3.0
Unported License</a>.  This means you're free to copy, share, and
build on this book, but not to sell it.  If you're interested in
commercial use, please <a
href="mailto:mn@michaelnielsen.org">contact me</a>.
</span>
<span class="right_footer">
Last update: Thu Dec 26 15:26:33 2019
<br/>
<br/>
<br/>
<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.en_GB"><img alt="Creative Commons Licence" style="border-width:0" src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png" /></a>
</span>
</div>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44208967-1', 'neuralnetworksanddeeplearning.com');
  ga('send', 'pageview');

</script>
</body>
</html>